#!/usr/bin/env python3
"""
Tokenç®¡ç†å™¨ - æ™ºèƒ½æ¶ˆæ¯æˆªæ–­å’Œå‹ç¼©
åŸºäºLinusç†å¿µï¼šå¥½çš„æ•°æ®ç»“æ„æ¶ˆé™¤å¤æ‚æ€§
"""

import json
import re
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass

# å¯¼å…¥ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
from core.utils.logging_init import get_logger
logger = get_logger("default")


@dataclass
class TokenUsage:
    """Tokenä½¿ç”¨ç»Ÿè®¡"""
    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0
    estimated_tokens: int = 0  # æœ¬åœ°ä¼°ç®—


class TokenManager:
    """
    Tokenç®¡ç†å™¨ - Linuså¼ç®€æ´è®¾è®¡
    
    æ ¸å¿ƒç†å¿µï¼š
    1. å¥½å“å‘³ï¼šé€šè¿‡æ•°æ®ç»“æ„æ¶ˆé™¤ç‰¹æ®Šæƒ…å†µ
    2. å®ç”¨ä¸»ä¹‰ï¼šè§£å†³çœŸå®çš„tokené™åˆ¶é—®é¢˜
    3. é›¶ç ´åï¼šä¸å½±å“ç°æœ‰åŠŸèƒ½
    """
    
    def __init__(self, max_tokens: int = 32768):
        """
        åˆå§‹åŒ–Tokenç®¡ç†å™¨
        
        Args:
            max_tokens: æœ€å¤§tokené™åˆ¶
        """
        self.max_tokens = max_tokens
        self.safety_buffer = 2048  # å®‰å…¨ç¼“å†²åŒº
        self.effective_limit = max_tokens - self.safety_buffer
        
        # ğŸ”§ Linuså¼æ•°æ®ç»“æ„ï¼šæ¶ˆé™¤ç‰¹æ®Šæƒ…å†µçš„å‹ç¼©è§„åˆ™
        self.compression_rules = {
            'system': {
                'priority': 10,  # æœ€é«˜ä¼˜å…ˆçº§ï¼Œä¸åˆ é™¤
                'max_length': -1,  # ä¸é™åˆ¶é•¿åº¦
                'compress_func': None
            },
            'tool': {
                'priority': 8,   # é«˜ä¼˜å…ˆçº§
                'max_length': 800,  # å·¥å…·ç»“æœé™åˆ¶800å­—ç¬¦
                'compress_func': self._compress_tool_result
            },
            'assistant': {
                'priority': 6,   # ä¸­ä¼˜å…ˆçº§
                'max_length': 1200,  # åŠ©æ‰‹æ¶ˆæ¯é™åˆ¶1200å­—ç¬¦
                'compress_func': self._compress_assistant_message
            },
            'user': {
                'priority': 9,   # ç”¨æˆ·æ¶ˆæ¯é«˜ä¼˜å…ˆçº§
                'max_length': 2000,  # ç”¨æˆ·æ¶ˆæ¯é™åˆ¶2000å­—ç¬¦
                'compress_func': self._compress_user_message
            },
            'function': {
                'priority': 7,   # å‡½æ•°è°ƒç”¨ä¸­ç­‰ä¼˜å…ˆçº§
                'max_length': 600,  # å‡½æ•°è°ƒç”¨é™åˆ¶600å­—ç¬¦
                'compress_func': self._compress_function_call
            }
        }
        
        logger.debug(f"ğŸ¯ [TokenManager] åˆå§‹åŒ–å®Œæˆ - é™åˆ¶: {max_tokens}, æœ‰æ•ˆ: {self.effective_limit}")
    
    def estimate_tokens(self, text: str) -> int:
        """
        ä¼°ç®—æ–‡æœ¬tokenæ•°é‡
        ç²—ç•¥ä¼°ç®—ï¼š1 token â‰ˆ 4å­—ç¬¦ï¼ˆè‹±æ–‡ï¼‰æˆ– 1.5ä¸ªä¸­æ–‡å­—ç¬¦
        """
        if not text:
            return 0
        
        # ç®€å•ä¼°ç®—ï¼šè‹±æ–‡4:1ï¼Œä¸­æ–‡1.5:1
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        english_chars = len(text) - chinese_chars
        
        estimated = int(english_chars / 4 + chinese_chars / 1.5)
        return max(estimated, len(text.split()) // 2)  # è‡³å°‘æ˜¯å•è¯æ•°çš„ä¸€åŠ
    
    def estimate_messages_tokens(self, messages: List[Any]) -> int:
        """ä¼°ç®—æ¶ˆæ¯åˆ—è¡¨çš„æ€»tokenæ•°é‡"""
        total = 0
        for message in messages:
            # ä¼°ç®—æ¶ˆæ¯ç»“æ„å¼€é”€
            total += 10  # æ¯ä¸ªæ¶ˆæ¯çš„ç»“æ„å¼€é”€
            
            # ğŸ›  Linuså¼ä¿®å¤ï¼šç»Ÿä¸€å¤„ç†å­—å…¸å’ŒLangChainæ¶ˆæ¯å¯¹è±¡
            if hasattr(message, 'content'):
                # LangChainæ¶ˆæ¯å¯¹è±¡ï¼ˆHumanMessage, AIMessageç­‰ï¼‰
                content = message.content
            elif isinstance(message, dict) and 'content' in message:
                # å­—å…¸æ ¼å¼æ¶ˆæ¯
                content = message['content']
            else:
                # å…¶ä»–æ ¼å¼ï¼Œè½¬ä¸ºå­—ç¬¦ä¸²
                content = str(message)
            
            # ä¼°ç®—å†…å®¹tokenæ•°
            if isinstance(content, str):
                total += self.estimate_tokens(content)
            elif isinstance(content, list):
                # å¤„ç†å¤šæ¨¡æ€æ¶ˆæ¯
                for content_item in content:
                    if isinstance(content_item, dict) and 'text' in content_item:
                        total += self.estimate_tokens(content_item['text'])
            
            # å·¥å…·è°ƒç”¨å¼€é”€ï¼ˆå…¼å®¹å­—å…¸å’Œå¯¹è±¡æ ¼å¼ï¼‰
            tool_calls = None
            if hasattr(message, 'tool_calls'):
                tool_calls = message.tool_calls
            elif isinstance(message, dict) and 'tool_calls' in message:
                tool_calls = message['tool_calls']
                
            if tool_calls:
                total += len(tool_calls) * 50  # æ¯ä¸ªå·¥å…·è°ƒç”¨50tokenå¼€é”€
        
        return total
    
    def _compress_tool_result(self, content: str) -> str:
        """å‹ç¼©å·¥å…·ç»“æœ - ä¿ç•™å…³é”®ä¿¡æ¯"""
        if len(content) <= 800:
            return content
        
        try:
            # å°è¯•è§£æJSONç»“æœ
            if content.startswith('{') or content.startswith('['):
                data = json.loads(content)
                return self._compress_json_data(data, max_items=5)
        except:
            pass
        
        # æ–‡æœ¬å‹ç¼©ï¼šä¿ç•™å¼€å¤´å’Œé‡è¦ä¿¡æ¯
        lines = content.split('\n')
        if len(lines) > 10:
            important_lines = []
            for line in lines[:5]:  # å‰5è¡Œ
                important_lines.append(line)
            important_lines.append('...[æ•°æ®å·²å‹ç¼©]...')
            for line in lines[-3:]:  # å3è¡Œ
                important_lines.append(line)
            content = '\n'.join(important_lines)
        
        return content[:800] + '...' if len(content) > 800 else content
    
    def _compress_json_data(self, data: Any, max_items: int = 5) -> str:
        """å‹ç¼©JSONæ•°æ®"""
        if isinstance(data, dict):
            # ä¿ç•™æœ€é‡è¦çš„é”®
            important_keys = ['error', 'status', 'symbol', 'name', 'price', 'change', 'data']
            compressed = {}
            
            for key in important_keys:
                if key in data:
                    compressed[key] = data[key]
            
            # å¦‚æœè¿˜æœ‰ç©ºé—´ï¼Œæ·»åŠ å…¶ä»–é”®ï¼ˆé™åˆ¶æ•°é‡ï¼‰
            other_keys = [k for k in data.keys() if k not in important_keys][:max_items-len(compressed)]
            for key in other_keys:
                compressed[key] = data[key]
                
            return json.dumps(compressed, ensure_ascii=False)
            
        elif isinstance(data, list):
            # åˆ—è¡¨åªä¿ç•™å‰å‡ é¡¹
            return json.dumps(data[:max_items], ensure_ascii=False)
        
        return json.dumps(data, ensure_ascii=False)
    
    def _compress_assistant_message(self, content: str) -> str:
        """å‹ç¼©åŠ©æ‰‹æ¶ˆæ¯ - ä¿ç•™æ ¸å¿ƒåˆ†æ"""
        if len(content) <= 1200:
            return content
        
        # ä¿ç•™åˆ†æç»“è®ºå’Œé‡è¦æ®µè½
        lines = content.split('\n')
        important_lines = []
        
        for line in lines:
            # ä¿ç•™æ ‡é¢˜ã€ç»“è®ºã€é‡è¦å…³é”®è¯
            if any(keyword in line for keyword in ['##', '###', 'ç»“è®º', 'å»ºè®®', 'é£é™©', 'æœºä¼š', 'æ€»ç»“']):
                important_lines.append(line)
            elif len(important_lines) < 15:  # å‰15è¡Œå†…å®¹
                important_lines.append(line)
        
        compressed = '\n'.join(important_lines)
        return compressed[:1200] + '...[åˆ†æå·²å‹ç¼©]' if len(compressed) > 1200 else compressed
    
    def _compress_user_message(self, content: str) -> str:
        """å‹ç¼©ç”¨æˆ·æ¶ˆæ¯ - ä¿ç•™å®Œæ•´æ„å›¾"""
        if len(content) <= 2000:
            return content
        
        # ç”¨æˆ·æ¶ˆæ¯ä¼˜å…ˆçº§é«˜ï¼Œå°½é‡ä¿ç•™å®Œæ•´
        return content[:2000] + '...[æ¶ˆæ¯å·²æˆªæ–­]'
    
    def _compress_function_call(self, content: str) -> str:
        """å‹ç¼©å‡½æ•°è°ƒç”¨ - ä¿ç•™å‡½æ•°åå’Œå…³é”®å‚æ•°"""
        if len(content) <= 600:
            return content
        
        try:
            # è§£æå‡½æ•°è°ƒç”¨
            data = json.loads(content)
            if 'name' in data:
                compressed = {'name': data['name']}
                if 'arguments' in data:
                    args = json.loads(data['arguments']) if isinstance(data['arguments'], str) else data['arguments']
                    # åªä¿ç•™æœ€é‡è¦çš„å‚æ•°
                    important_params = ['symbol', 'query', 'timeframe', 'limit', 'type']
                    filtered_args = {k: v for k, v in args.items() if k in important_params}
                    compressed['arguments'] = filtered_args
                return json.dumps(compressed, ensure_ascii=False)
        except:
            pass
        
        return content[:600] + '...'
    
    def compress_messages(self, messages: List[Any]) -> Tuple[List[Any], TokenUsage]:
        """
        æ™ºèƒ½å‹ç¼©æ¶ˆæ¯åˆ—è¡¨
        
        Returns:
            Tuple[å‹ç¼©åçš„æ¶ˆæ¯åˆ—è¡¨, Tokenä½¿ç”¨ç»Ÿè®¡]
        """
        if not messages:
            return messages, TokenUsage()
        
        # ä¼°ç®—å½“å‰tokenä½¿ç”¨é‡
        current_tokens = self.estimate_messages_tokens(messages)
        logger.debug(f"ğŸ” [TokenManager] å½“å‰ä¼°ç®—tokens: {current_tokens}/{self.effective_limit}")
        
        if current_tokens <= self.effective_limit:
            return messages, TokenUsage(estimated_tokens=current_tokens)
        
        # éœ€è¦å‹ç¼©
        logger.info(f"ğŸ“¦ [TokenManager] å¼€å§‹æ¶ˆæ¯å‹ç¼© - è¶…å‡ºé™åˆ¶: {current_tokens - self.effective_limit} tokens")
        
        compressed_messages = []
        token_budget = self.effective_limit
        
        # ğŸ›  Linuså¼è§£å†³æ–¹æ¡ˆï¼šç»Ÿä¸€æ¶ˆæ¯æ ¼å¼å¤„ç†
        def _get_message_role(msg):
            """è·å–æ¶ˆæ¯è§’è‰²ï¼Œå…¼å®¹å­—å…¸å’ŒLangChainå¯¹è±¡"""
            if hasattr(msg, '__class__'):
                # LangChainæ¶ˆæ¯å¯¹è±¡
                class_name = msg.__class__.__name__
                if 'HumanMessage' in class_name:
                    return 'user'
                elif 'AIMessage' in class_name:
                    return 'assistant'
                elif 'SystemMessage' in class_name:
                    return 'system'
                elif 'FunctionMessage' in class_name or 'ToolMessage' in class_name:
                    return 'function'
                else:
                    return 'user'  # é»˜è®¤
            elif isinstance(msg, dict) and 'role' in msg:
                return msg['role']
            else:
                return 'user'  # é»˜è®¤

        def _get_message_content(msg):
            """è·å–æ¶ˆæ¯å†…å®¹ï¼Œå…¼å®¹å­—å…¸å’ŒLangChainå¯¹è±¡"""
            if hasattr(msg, 'content'):
                return msg.content
            elif isinstance(msg, dict) and 'content' in msg:
                return msg['content']
            else:
                return str(msg)
        
        # 1. æŒ‰è§’è‰²åˆ†ç±»æ¶ˆæ¯
        system_messages = [msg for msg in messages if _get_message_role(msg) == 'system']
        other_messages = [msg for msg in messages if _get_message_role(msg) != 'system']
        
        # 2. ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        for msg in system_messages:
            compressed_messages.append(msg)
            content = _get_message_content(msg)
            token_budget -= self.estimate_tokens(str(content))
        
        # 3. å€’åºå¤„ç†å…¶ä»–æ¶ˆæ¯ï¼ˆä¿ç•™æœ€æ–°çš„ï¼‰
        for msg in reversed(other_messages):
            if token_budget <= 0:
                break
                
            role = _get_message_role(msg)
            content = _get_message_content(msg)
            
            # åº”ç”¨å‹ç¼©è§„åˆ™
            rule = self.compression_rules.get(role, self.compression_rules['user'])
            
            if rule['compress_func'] and isinstance(content, str):
                compressed_content = rule['compress_func'](content)
            else:
                compressed_content = content
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰tokené¢„ç®—
            msg_tokens = self.estimate_tokens(str(compressed_content))
            if msg_tokens <= token_budget:
                # ğŸ›  ä¿æŒåŸå§‹æ¶ˆæ¯æ ¼å¼ï¼ˆLangChainå¯¹è±¡æˆ–å­—å…¸ï¼‰
                if hasattr(msg, 'content'):
                    # LangChainæ¶ˆæ¯å¯¹è±¡ - åˆ›å»ºæ–°å¯¹è±¡ä»¥é¿å…ä¿®æ”¹åŸå¯¹è±¡
                    if 'HumanMessage' in msg.__class__.__name__:
                        from langchain_core.messages import HumanMessage
                        compressed_msg = HumanMessage(content=compressed_content)
                    elif 'AIMessage' in msg.__class__.__name__:
                        from langchain_core.messages import AIMessage  
                        compressed_msg = AIMessage(content=compressed_content)
                    elif 'SystemMessage' in msg.__class__.__name__:
                        from langchain_core.messages import SystemMessage
                        compressed_msg = SystemMessage(content=compressed_content)
                    else:
                        # å…¶ä»–ç±»å‹ï¼Œå°è¯•å¤åˆ¶
                        compressed_msg = msg.__class__(content=compressed_content)
                elif isinstance(msg, dict):
                    # å­—å…¸æ ¼å¼ - å¤åˆ¶å¹¶æ›´æ–°å†…å®¹
                    compressed_msg = msg.copy()
                    compressed_msg['content'] = compressed_content
                else:
                    # å…¶ä»–æ ¼å¼ï¼Œä¿æŒåŸæ ·
                    compressed_msg = msg
                
                compressed_messages.insert(-len(system_messages) if system_messages else 0, compressed_msg)
                token_budget -= msg_tokens
            else:
                logger.debug(f"â­ï¸ [TokenManager] è·³è¿‡æ¶ˆæ¯ - è¶…å‡ºé¢„ç®—: {msg_tokens} > {token_budget}")
        
        final_tokens = self.estimate_messages_tokens(compressed_messages)
        logger.info(f"âœ… [TokenManager] å‹ç¼©å®Œæˆ - æ¶ˆæ¯æ•°: {len(messages)} -> {len(compressed_messages)}, tokens: {current_tokens} -> {final_tokens}")
        
        return compressed_messages, TokenUsage(
            estimated_tokens=final_tokens,
            total_tokens=final_tokens
        )
    
    def should_compress(self, messages: List[Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©"""
        estimated = self.estimate_messages_tokens(messages)
        return estimated > self.effective_limit


# å…¨å±€å®ä¾‹
_token_manager = None

def get_token_manager(max_tokens: int = 32768) -> TokenManager:
    """è·å–Tokenç®¡ç†å™¨å•ä¾‹"""
    global _token_manager
    if _token_manager is None or _token_manager.max_tokens != max_tokens:
        _token_manager = TokenManager(max_tokens)
    return _token_manager


def compress_messages_smart(messages: List[Any], max_tokens: int = 32768) -> Tuple[List[Any], TokenUsage]:
    """
    æ™ºèƒ½æ¶ˆæ¯å‹ç¼©çš„ä¾¿æ·å‡½æ•°
    
    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        max_tokens: æœ€å¤§tokené™åˆ¶
        
    Returns:
        Tuple[å‹ç¼©åçš„æ¶ˆæ¯åˆ—è¡¨, Tokenä½¿ç”¨ç»Ÿè®¡]
    """
    manager = get_token_manager(max_tokens)
    return manager.compress_messages(messages)