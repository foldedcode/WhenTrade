"""
APIè¯·æ±‚é™æµå™¨

ä¸ºå¤–éƒ¨APIè°ƒç”¨æä¾›é€Ÿç‡é™åˆ¶å’Œç¼“å­˜åŠŸèƒ½ï¼Œé˜²æ­¢è§¦å‘APIæœåŠ¡å•†çš„é™åˆ¶ã€‚
"""
import asyncio
import time
from functools import wraps
from typing import Dict, Any, Optional, Callable, Tuple
from collections import defaultdict
import logging
import hashlib
import json

logger = logging.getLogger(__name__)


class RateLimiter:
    """é€Ÿç‡é™åˆ¶å™¨"""
    
    def __init__(self, max_calls: int, time_window: int = 60):
        """
        åˆå§‹åŒ–é€Ÿç‡é™åˆ¶å™¨
        
        Args:
            max_calls: æ—¶é—´çª—å£å†…æœ€å¤§è°ƒç”¨æ¬¡æ•°
            time_window: æ—¶é—´çª—å£ï¼ˆç§’ï¼‰
        """
        self.max_calls = max_calls
        self.time_window = time_window
        self.calls = defaultdict(list)
        self.locks = defaultdict(asyncio.Lock)
    
    async def acquire(self, key: str = "default") -> bool:
        """
        è·å–è°ƒç”¨è®¸å¯
        
        Args:
            key: é™æµé”®ï¼ˆç”¨äºåŒºåˆ†ä¸åŒçš„APIï¼‰
            
        Returns:
            æ˜¯å¦è·å¾—è®¸å¯
        """
        async with self.locks[key]:
            now = time.time()
            # æ¸…ç†è¿‡æœŸè®°å½•
            self.calls[key] = [call_time for call_time in self.calls[key] 
                             if now - call_time < self.time_window]
            
            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºé™åˆ¶
            if len(self.calls[key]) >= self.max_calls:
                oldest_call = min(self.calls[key])
                wait_time = self.time_window - (now - oldest_call)
                if wait_time > 0:
                    logger.warning(f"â±ï¸ é€Ÿç‡é™åˆ¶ï¼š{key} éœ€è¦ç­‰å¾… {wait_time:.1f} ç§’")
                    await asyncio.sleep(wait_time + 0.1)  # é¢å¤–0.1ç§’ç¼“å†²
            
            # è®°å½•æœ¬æ¬¡è°ƒç”¨
            self.calls[key].append(time.time())
            return True


class APICache:
    """APIç»“æœç¼“å­˜"""
    
    def __init__(self, ttl: int = 300):
        """
        åˆå§‹åŒ–ç¼“å­˜
        
        Args:
            ttl: ç¼“å­˜ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.ttl = ttl
        self.cache: Dict[str, Tuple[Any, float]] = {}
    
    def _make_key(self, func_name: str, args: tuple, kwargs: dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # å°†å‚æ•°åºåˆ—åŒ–ä¸ºç¨³å®šçš„å­—ç¬¦ä¸²
        key_data = {
            'function': func_name,
            'args': args,
            'kwargs': {k: v for k, v in sorted(kwargs.items())}
        }
        key_str = json.dumps(key_data, sort_keys=True, default=str)
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def get(self, func_name: str, args: tuple, kwargs: dict) -> Optional[Any]:
        """è·å–ç¼“å­˜ç»“æœ"""
        key = self._make_key(func_name, args, kwargs)
        if key in self.cache:
            result, timestamp = self.cache[key]
            if time.time() - timestamp < self.ttl:
                logger.debug(f"ğŸ“‹ ç¼“å­˜å‘½ä¸­: {func_name}")
                return result
            else:
                # æ¸…ç†è¿‡æœŸç¼“å­˜
                del self.cache[key]
        return None
    
    def set(self, func_name: str, args: tuple, kwargs: dict, result: Any):
        """è®¾ç½®ç¼“å­˜ç»“æœ"""
        key = self._make_key(func_name, args, kwargs)
        self.cache[key] = (result, time.time())
        logger.debug(f"ğŸ’¾ ç¼“å­˜ä¿å­˜: {func_name}")
    
    def clear(self):
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜"""
        self.cache.clear()
        logger.info("ğŸ—‘ï¸ å·²æ¸…ç†æ‰€æœ‰APIç¼“å­˜")


# å…¨å±€å®ä¾‹
_rate_limiters = {
    'coingecko': RateLimiter(max_calls=10, time_window=60),  # CoinGecko å…è´¹ç‰ˆ: 10æ¬¡/åˆ†é’Ÿ
    'yfinance': RateLimiter(max_calls=48, time_window=60),   # YFinance: çº¦48æ¬¡/åˆ†é’Ÿ
    'finnhub': RateLimiter(max_calls=60, time_window=60),    # Finnhub: 60æ¬¡/åˆ†é’Ÿ
    'reddit': RateLimiter(max_calls=60, time_window=60),     # Reddit API: 60æ¬¡/åˆ†é’Ÿ
    'default': RateLimiter(max_calls=30, time_window=60)     # é»˜è®¤é™åˆ¶
}

_api_cache = APICache(ttl=300)  # 5åˆ†é’Ÿç¼“å­˜


def rate_limit(api_name: str = 'default', use_cache: bool = True):
    """
    APIé€Ÿç‡é™åˆ¶è£…é¥°å™¨
    
    Args:
        api_name: APIåç§°ï¼Œç”¨äºé€‰æ‹©å¯¹åº”çš„é™æµå™¨
        use_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            # æ£€æŸ¥ç¼“å­˜
            if use_cache:
                cached_result = _api_cache.get(func.__name__, args, kwargs)
                if cached_result is not None:
                    return cached_result
            
            # è·å–é€Ÿç‡é™åˆ¶è®¸å¯
            limiter = _rate_limiters.get(api_name, _rate_limiters['default'])
            await limiter.acquire(api_name)
            
            # æ‰§è¡Œå‡½æ•°
            try:
                result = await func(*args, **kwargs) if asyncio.iscoroutinefunction(func) else func(*args, **kwargs)
                
                # ç¼“å­˜æˆåŠŸç»“æœ
                if use_cache and isinstance(result, dict) and 'error' not in result:
                    _api_cache.set(func.__name__, args, kwargs, result)
                
                return result
                
            except Exception as e:
                logger.error(f"âŒ APIè°ƒç”¨å¤±è´¥ {func.__name__}: {e}")
                return {"error": str(e), "api_name": api_name}
        
        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            # å¯¹äºåŒæ­¥å‡½æ•°ï¼Œä½¿ç”¨ç®€åŒ–çš„é™æµé€»è¾‘
            if use_cache:
                cached_result = _api_cache.get(func.__name__, args, kwargs)
                if cached_result is not None:
                    return cached_result
            
            # åŒæ­¥ç‰ˆæœ¬çš„ç®€å•é™æµ
            limiter = _rate_limiters.get(api_name, _rate_limiters['default'])
            now = time.time()
            
            # ç®€åŒ–çš„åŒæ­¥é™æµæ£€æŸ¥
            key = api_name
            limiter.calls[key] = [call_time for call_time in limiter.calls[key] 
                                if now - call_time < limiter.time_window]
            
            if len(limiter.calls[key]) >= limiter.max_calls:
                oldest_call = min(limiter.calls[key]) if limiter.calls[key] else now
                wait_time = limiter.time_window - (now - oldest_call)
                if wait_time > 0:
                    logger.warning(f"â±ï¸ åŒæ­¥é€Ÿç‡é™åˆ¶ï¼š{key} ç­‰å¾… {wait_time:.1f} ç§’")
                    time.sleep(wait_time + 0.1)
            
            limiter.calls[key].append(now)
            
            # æ‰§è¡Œå‡½æ•°
            try:
                result = func(*args, **kwargs)
                
                # ç¼“å­˜æˆåŠŸç»“æœ
                if use_cache and isinstance(result, dict) and 'error' not in result:
                    _api_cache.set(func.__name__, args, kwargs, result)
                
                return result
                
            except Exception as e:
                logger.error(f"âŒ APIè°ƒç”¨å¤±è´¥ {func.__name__}: {e}")
                return {"error": str(e), "api_name": api_name}
        
        # æ ¹æ®å‡½æ•°ç±»å‹è¿”å›å¯¹åº”çš„åŒ…è£…å™¨
        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
    
    return decorator


def clear_cache():
    """æ¸…ç†æ‰€æœ‰APIç¼“å­˜"""
    _api_cache.clear()


def get_rate_limit_stats() -> Dict[str, Dict[str, Any]]:
    """è·å–é€Ÿç‡é™åˆ¶ç»Ÿè®¡ä¿¡æ¯"""
    stats = {}
    now = time.time()
    
    for api_name, limiter in _rate_limiters.items():
        # æ¸…ç†è¿‡æœŸè®°å½•
        for key in limiter.calls:
            limiter.calls[key] = [call_time for call_time in limiter.calls[key] 
                                if now - call_time < limiter.time_window]
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_calls = sum(len(calls) for calls in limiter.calls.values())
        stats[api_name] = {
            'max_calls': limiter.max_calls,
            'time_window': limiter.time_window,
            'current_calls': total_calls,
            'remaining_calls': max(0, limiter.max_calls - total_calls),
            'keys': list(limiter.calls.keys())
        }
    
    # ç¼“å­˜ç»Ÿè®¡
    stats['cache'] = {
        'total_entries': len(_api_cache.cache),
        'ttl': _api_cache.ttl
    }
    
    return stats