"""
åŠ å¯†è´§å¸Swarmé£æ ¼æ–°é—»æœåŠ¡
ä½¿ç”¨DuckDuckGoä½œä¸ºå”¯ä¸€æ•°æ®æºçš„å¤šä»£ç†æ–°é—»èšåˆç³»ç»Ÿ
"""

import json
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from duckduckgo_search import DDGS
import logging
import time
import random

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from core.utils.logging_manager import get_logger
logger = get_logger('crypto_swarm')


class NewsSearchAgent:
    """æ–°é—»æœç´¢ä»£ç† - è´Ÿè´£ä»DuckDuckGoè·å–åŠ å¯†è´§å¸æ–°é—»"""
    
    def __init__(self):
        self.ddgs = DDGS()
        self.crypto_keywords = {
            'BTC': ['Bitcoin', 'BTC', 'æ¯”ç‰¹å¸'],
            'ETH': ['Ethereum', 'ETH', 'ä»¥å¤ªåŠ'],
            'SOL': ['Solana', 'SOL'],
            'BNB': ['Binance', 'BNB', 'å¸å®‰å¸'],
            'XRP': ['Ripple', 'XRP', 'ç‘æ³¢å¸'],
            'ADA': ['Cardano', 'ADA'],
            'DOGE': ['Dogecoin', 'DOGE', 'ç‹—ç‹—å¸'],
            'DOT': ['Polkadot', 'DOT']
        }
    
    def search(self, symbol: str, max_results: int = 10) -> List[Dict[str, Any]]:
        """
        æœç´¢æŒ‡å®šåŠ å¯†è´§å¸çš„æ–°é—»
        
        Args:
            symbol: åŠ å¯†è´§å¸ç¬¦å· (å¦‚ BTC, ETH)
            max_results: æœ€å¤§ç»“æœæ•°
            
        Returns:
            æ–°é—»åˆ—è¡¨
        """
        try:
            # è·å–æœç´¢å…³é”®è¯
            keywords = self.crypto_keywords.get(symbol.upper(), [symbol])
            primary_keyword = keywords[0] if keywords else symbol
            
            # æ„å»ºæœç´¢æŸ¥è¯¢
            queries = [
                f"{primary_keyword} cryptocurrency news",
                f"{primary_keyword} price analysis",
                f"{primary_keyword} market update"
            ]
            
            all_news = []
            seen_urls = set()
            
            for query in queries:
                try:
                    # ä½¿ç”¨DuckDuckGoæœç´¢æ–°é—»
                    results = self.ddgs.news(
                        keywords=query,
                        region='wt-wt',  # å…¨çƒ
                        safesearch='off',
                        max_results=max_results
                    )
                    
                    for result in results:
                        # å»é‡
                        if result.get('url') in seen_urls:
                            continue
                        seen_urls.add(result.get('url'))
                        
                        # æ ¼å¼åŒ–ç»“æœ
                        news_item = {
                            'title': result.get('title', ''),
                            'url': result.get('url', ''),
                            'body': result.get('body', ''),
                            'date': result.get('date', ''),
                            'source': result.get('source', ''),
                            'image': result.get('image', ''),
                            'symbol': symbol,
                            'query': query
                        }
                        all_news.append(news_item)
                        
                        if len(all_news) >= max_results:
                            break
                    
                    if len(all_news) >= max_results:
                        break
                        
                    # é¿å…è¯·æ±‚è¿‡å¿«
                    time.sleep(random.uniform(0.5, 1.5))
                    
                except Exception as e:
                    logger.warning(f"æœç´¢å¤±è´¥ for query '{query}': {e}")
                    continue
            
            logger.info(f"æœç´¢åˆ° {len(all_news)} æ¡å…³äº {symbol} çš„æ–°é—»")
            return all_news[:max_results]
            
        except Exception as e:
            logger.error(f"æ–°é—»æœç´¢å¤±è´¥: {e}")
            return []


class NewsAnalyzerAgent:
    """æ–°é—»åˆ†æä»£ç† - åˆ†ææ–°é—»å†…å®¹å¹¶æå–å…³é”®ä¿¡æ¯"""
    
    def __init__(self):
        self.sentiment_keywords = {
            'positive': [
                'bullish', 'surge', 'rally', 'gain', 'rise', 'soar', 'jump',
                'breakthrough', 'record', 'high', 'boom', 'growth', 'adoption',
                'upgrade', 'partnership', 'integration', 'institutional'
            ],
            'negative': [
                'bearish', 'crash', 'fall', 'drop', 'plunge', 'decline', 'slump',
                'concern', 'warning', 'risk', 'hack', 'exploit', 'regulation',
                'ban', 'restriction', 'lawsuit', 'investigation', 'sell-off'
            ],
            'neutral': [
                'stable', 'steady', 'consolidate', 'range', 'sideways', 'unchanged',
                'update', 'announce', 'report', 'discuss', 'consider', 'review'
            ]
        }
    
    def analyze(self, news_items: List[Dict[str, Any]], symbol: str) -> Dict[str, Any]:
        """
        åˆ†ææ–°é—»åˆ—è¡¨å¹¶æå–å…³é”®ä¿¡æ¯
        
        Args:
            news_items: æ–°é—»åˆ—è¡¨
            symbol: åŠ å¯†è´§å¸ç¬¦å·
            
        Returns:
            åˆ†æç»“æœ
        """
        try:
            if not news_items:
                return {
                    'symbol': symbol,
                    'total_news': 0,
                    'sentiment': 'neutral',
                    'key_topics': [],
                    'price_mentions': [],
                    'major_events': [],
                    'analyzed_news': []
                }
            
            analyzed_news = []
            sentiments = []
            key_topics = set()
            price_mentions = []
            major_events = []
            
            for news in news_items:
                # åˆ†æå•æ¡æ–°é—»
                analysis = self._analyze_single_news(news)
                analyzed_news.append(analysis)
                
                # æ”¶é›†æƒ…æ„Ÿ
                sentiments.append(analysis['sentiment'])
                
                # æ”¶é›†ä¸»é¢˜
                key_topics.update(analysis['topics'])
                
                # æ”¶é›†ä»·æ ¼æåŠ
                if analysis['price_mention']:
                    price_mentions.append(analysis['price_mention'])
                
                # æ”¶é›†é‡å¤§äº‹ä»¶
                if analysis['is_major_event']:
                    major_events.append({
                        'title': news['title'],
                        'date': news['date'],
                        'type': analysis['event_type']
                    })
            
            # è®¡ç®—æ•´ä½“æƒ…æ„Ÿ
            overall_sentiment = self._calculate_overall_sentiment(sentiments)
            
            return {
                'symbol': symbol,
                'total_news': len(news_items),
                'sentiment': overall_sentiment,
                'sentiment_distribution': self._get_sentiment_distribution(sentiments),
                'key_topics': list(key_topics)[:10],  # å‰10ä¸ªä¸»é¢˜
                'price_mentions': price_mentions[:5],  # å‰5ä¸ªä»·æ ¼æåŠ
                'major_events': major_events[:3],  # å‰3ä¸ªé‡å¤§äº‹ä»¶
                'analyzed_news': analyzed_news[:5],  # å‰5æ¡åˆ†æç»“æœ
                'analysis_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"æ–°é—»åˆ†æå¤±è´¥: {e}")
            return {
                'symbol': symbol,
                'total_news': len(news_items) if news_items else 0,
                'sentiment': 'neutral',
                'error': str(e)
            }
    
    def _analyze_single_news(self, news: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå•æ¡æ–°é—»"""
        text = f"{news.get('title', '')} {news.get('body', '')}".lower()
        
        # æƒ…æ„Ÿåˆ†æ
        sentiment_scores = {
            'positive': sum(1 for word in self.sentiment_keywords['positive'] if word in text),
            'negative': sum(1 for word in self.sentiment_keywords['negative'] if word in text),
            'neutral': sum(1 for word in self.sentiment_keywords['neutral'] if word in text)
        }
        
        sentiment = max(sentiment_scores.items(), key=lambda x: x[1])[0]
        if sentiment_scores[sentiment] == 0:
            sentiment = 'neutral'
        
        # æå–ä¸»é¢˜
        topics = self._extract_topics(text)
        
        # æ£€æŸ¥ä»·æ ¼æåŠ
        price_mention = self._extract_price_mention(text)
        
        # åˆ¤æ–­æ˜¯å¦é‡å¤§äº‹ä»¶
        is_major_event = self._is_major_event(text)
        event_type = self._get_event_type(text) if is_major_event else None
        
        return {
            'title': news.get('title', ''),
            'sentiment': sentiment,
            'sentiment_score': sentiment_scores[sentiment],
            'topics': topics,
            'price_mention': price_mention,
            'is_major_event': is_major_event,
            'event_type': event_type,
            'source': news.get('source', ''),
            'date': news.get('date', '')
        }
    
    def _extract_topics(self, text: str) -> List[str]:
        """æå–å…³é”®ä¸»é¢˜"""
        topics = []
        topic_keywords = {
            'price_action': ['price', 'trading', 'chart', 'technical', 'support', 'resistance'],
            'regulation': ['regulation', 'sec', 'government', 'law', 'compliance', 'legal'],
            'adoption': ['adoption', 'institutional', 'company', 'accept', 'integrate', 'use'],
            'technology': ['upgrade', 'development', 'protocol', 'network', 'blockchain', 'defi'],
            'market': ['market', 'volume', 'liquidity', 'exchange', 'trading'],
            'partnership': ['partner', 'collaboration', 'alliance', 'deal', 'agreement'],
            'competition': ['competitor', 'versus', 'compare', 'alternative', 'rival']
        }
        
        for topic, keywords in topic_keywords.items():
            if any(word in text for word in keywords):
                topics.append(topic)
        
        return topics
    
    def _extract_price_mention(self, text: str) -> Optional[str]:
        """æå–ä»·æ ¼æåŠ"""
        import re
        
        # æŸ¥æ‰¾ä»·æ ¼æ¨¡å¼ (å¦‚ $50,000 æˆ– 50k)
        price_patterns = [
            r'\$[\d,]+\.?\d*',  # $50,000.00
            r'[\d,]+\.?\d*\s*(?:usd|dollar)',  # 50000 usd
            r'[\d,]+k',  # 50k
        ]
        
        for pattern in price_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group()
        
        return None
    
    def _is_major_event(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºé‡å¤§äº‹ä»¶"""
        major_keywords = [
            'breaking', 'major', 'significant', 'milestone', 'record',
            'announce', 'launch', 'release', 'partnership', 'acquisition',
            'hack', 'exploit', 'crash', 'surge', 'regulation', 'ban'
        ]
        return any(word in text for word in major_keywords)
    
    def _get_event_type(self, text: str) -> str:
        """è·å–äº‹ä»¶ç±»å‹"""
        if any(word in text for word in ['hack', 'exploit', 'breach', 'attack']):
            return 'security'
        elif any(word in text for word in ['regulation', 'sec', 'law', 'ban']):
            return 'regulatory'
        elif any(word in text for word in ['partner', 'collaboration', 'deal']):
            return 'partnership'
        elif any(word in text for word in ['launch', 'release', 'upgrade']):
            return 'product'
        elif any(word in text for word in ['surge', 'rally', 'crash', 'plunge']):
            return 'price_movement'
        else:
            return 'other'
    
    def _calculate_overall_sentiment(self, sentiments: List[str]) -> str:
        """è®¡ç®—æ•´ä½“æƒ…æ„Ÿ"""
        if not sentiments:
            return 'neutral'
        
        sentiment_counts = {
            'positive': sentiments.count('positive'),
            'negative': sentiments.count('negative'),
            'neutral': sentiments.count('neutral')
        }
        
        # åŠ æƒè®¡ç®—
        score = sentiment_counts['positive'] - sentiment_counts['negative']
        
        if score > len(sentiments) * 0.2:
            return 'positive'
        elif score < -len(sentiments) * 0.2:
            return 'negative'
        else:
            return 'neutral'
    
    def _get_sentiment_distribution(self, sentiments: List[str]) -> Dict[str, float]:
        """è·å–æƒ…æ„Ÿåˆ†å¸ƒ"""
        if not sentiments:
            return {'positive': 0, 'negative': 0, 'neutral': 0}
        
        total = len(sentiments)
        return {
            'positive': round(sentiments.count('positive') / total, 2),
            'negative': round(sentiments.count('negative') / total, 2),
            'neutral': round(sentiments.count('neutral') / total, 2)
        }


class NewsSummarizerAgent:
    """æ–°é—»æ€»ç»“ä»£ç† - ç”Ÿæˆç»“æ„åŒ–çš„æ–°é—»åˆ†ææŠ¥å‘Š"""
    
    def summarize(self, analysis: Dict[str, Any], symbol: str) -> str:
        """
        ç”Ÿæˆæ–°é—»åˆ†ææ€»ç»“æŠ¥å‘Š
        
        Args:
            analysis: åˆ†æç»“æœ
            symbol: åŠ å¯†è´§å¸ç¬¦å·
            
        Returns:
            æ ¼å¼åŒ–çš„æ€»ç»“æŠ¥å‘Š
        """
        try:
            if not analysis or analysis.get('total_news', 0) == 0:
                return self._generate_no_news_report(symbol)
            
            # ç”ŸæˆæŠ¥å‘Šå„éƒ¨åˆ†
            header = self._generate_header(symbol, analysis)
            sentiment_section = self._generate_sentiment_section(analysis)
            topics_section = self._generate_topics_section(analysis)
            events_section = self._generate_events_section(analysis)
            price_section = self._generate_price_section(analysis)
            summary = self._generate_summary(analysis)
            
            # ç»„åˆæŠ¥å‘Š
            report = f"""
{header}

{sentiment_section}

{topics_section}

{events_section}

{price_section}

{summary}
"""
            
            return report.strip()
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")
            return f"ã€{symbol} æ–°é—»åˆ†æã€‘\nåˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
    
    def _generate_no_news_report(self, symbol: str) -> str:
        """ç”Ÿæˆæ— æ–°é—»æ—¶çš„æŠ¥å‘Š"""
        return f"""
ã€{symbol} å¸‚åœºæƒ…ç»ªåˆ†æã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š æ•°æ®çŠ¶æ€ï¼šæš‚æ— æœ€æ–°æ–°é—»æ•°æ®

å½“å‰æœªèƒ½è·å–åˆ°å…³äº {symbol} çš„æœ€æ–°æ–°é—»ä¿¡æ¯ã€‚è¿™å¯èƒ½è¡¨æ˜ï¼š
â€¢ å¸‚åœºå¤„äºç›¸å¯¹å¹³é™æœŸï¼Œæ— é‡å¤§äº‹ä»¶å‘ç”Ÿ
â€¢ æŠ•èµ„è€…æƒ…ç»ªç¨³å®šï¼Œç¼ºä¹æ˜æ˜¾æ–¹å‘æ€§
â€¢ å»ºè®®å…³æ³¨æŠ€æœ¯é¢æŒ‡æ ‡å’Œé“¾ä¸Šæ•°æ®ä½œä¸ºè¡¥å……

å»ºè®®æ“ä½œï¼š
â€¢ ä¿æŒè§‚æœ›ï¼Œç­‰å¾…æ›´å¤šå¸‚åœºä¿¡å·
â€¢ å…³æ³¨å…¶ä»–æ•°æ®æºå¦‚é“¾ä¸Šæ´»åŠ¨å’ŒæŠ€æœ¯æŒ‡æ ‡
â€¢ ç•™æ„å³å°†å‘å¸ƒçš„é‡è¦å…¬å‘Šæˆ–äº‹ä»¶
"""
    
    def _generate_header(self, symbol: str, analysis: Dict[str, Any]) -> str:
        """ç”ŸæˆæŠ¥å‘Šå¤´éƒ¨"""
        return f"""
ã€{symbol} å¸‚åœºæƒ…ç»ªåˆ†æã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“… åˆ†ææ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}
ğŸ“° æ–°é—»æ•°é‡ï¼š{analysis['total_news']} æ¡
"""
    
    def _generate_sentiment_section(self, analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆæƒ…æ„Ÿåˆ†æéƒ¨åˆ†"""
        sentiment = analysis.get('sentiment', 'neutral')
        distribution = analysis.get('sentiment_distribution', {})
        
        # æƒ…æ„Ÿå›¾æ ‡
        sentiment_icons = {
            'positive': 'ğŸŸ¢ çœ‹æ¶¨',
            'negative': 'ğŸ”´ çœ‹è·Œ',
            'neutral': 'ğŸŸ¡ ä¸­æ€§'
        }
        
        # ç”Ÿæˆæƒ…æ„Ÿæ¡å½¢å›¾
        pos_bar = 'â–ˆ' * int(distribution.get('positive', 0) * 10)
        neg_bar = 'â–ˆ' * int(distribution.get('negative', 0) * 10)
        neu_bar = 'â–ˆ' * int(distribution.get('neutral', 0) * 10)
        
        return f"""
ğŸ“ˆ å¸‚åœºæƒ…ç»ªï¼š{sentiment_icons.get(sentiment, 'ğŸŸ¡ ä¸­æ€§')}
â”œâ”€ ç§¯æ {distribution.get('positive', 0)*100:.0f}% {pos_bar}
â”œâ”€ æ¶ˆæ {distribution.get('negative', 0)*100:.0f}% {neg_bar}
â””â”€ ä¸­æ€§ {distribution.get('neutral', 0)*100:.0f}% {neu_bar}
"""
    
    def _generate_topics_section(self, analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¸»é¢˜åˆ†æéƒ¨åˆ†"""
        topics = analysis.get('key_topics', [])
        
        if not topics:
            return "ğŸ·ï¸ å…³é”®ä¸»é¢˜ï¼šæš‚æ— æ˜æ˜¾ä¸»é¢˜"
        
        # ä¸»é¢˜æ˜ å°„åˆ°ä¸­æ–‡
        topic_names = {
            'price_action': 'ä»·æ ¼èµ°åŠ¿',
            'regulation': 'ç›‘ç®¡åŠ¨æ€',
            'adoption': 'é‡‡ç”¨è¿›å±•',
            'technology': 'æŠ€æœ¯å‘å±•',
            'market': 'å¸‚åœºåŠ¨æ€',
            'partnership': 'åˆä½œä¼™ä¼´',
            'competition': 'ç«äº‰æ ¼å±€'
        }
        
        topic_list = [topic_names.get(t, t) for t in topics[:5]]
        
        return f"""
ğŸ·ï¸ å…³é”®ä¸»é¢˜ï¼š
{' | '.join(f'#{topic}' for topic in topic_list)}
"""
    
    def _generate_events_section(self, analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆé‡å¤§äº‹ä»¶éƒ¨åˆ†"""
        events = analysis.get('major_events', [])
        
        if not events:
            return "âš¡ é‡å¤§äº‹ä»¶ï¼šè¿‘æœŸæ— é‡å¤§äº‹ä»¶"
        
        event_type_names = {
            'security': 'ğŸ”’ å®‰å…¨äº‹ä»¶',
            'regulatory': 'âš–ï¸ ç›‘ç®¡äº‹ä»¶',
            'partnership': 'ğŸ¤ åˆä½œäº‹ä»¶',
            'product': 'ğŸš€ äº§å“å‘å¸ƒ',
            'price_movement': 'ğŸ“Š ä»·æ ¼å¼‚åŠ¨',
            'other': 'ğŸ“Œ å…¶ä»–äº‹ä»¶'
        }
        
        events_text = []
        for event in events[:3]:
            type_name = event_type_names.get(event.get('type', 'other'), 'ğŸ“Œ å…¶ä»–')
            title = event.get('title', '')[:50]  # é™åˆ¶æ ‡é¢˜é•¿åº¦
            events_text.append(f"â€¢ {type_name}: {title}")
        
        return f"""
âš¡ é‡å¤§äº‹ä»¶ï¼š
{chr(10).join(events_text)}
"""
    
    def _generate_price_section(self, analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆä»·æ ¼æåŠéƒ¨åˆ†"""
        price_mentions = analysis.get('price_mentions', [])
        
        if not price_mentions:
            return ""
        
        return f"""
ğŸ’° ä»·æ ¼å…³æ³¨ç‚¹ï¼š
{' / '.join(price_mentions[:3])}
"""
    
    def _generate_summary(self, analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ€»ç»“å»ºè®®"""
        sentiment = analysis.get('sentiment', 'neutral')
        total_news = analysis.get('total_news', 0)
        
        if sentiment == 'positive':
            summary = """
ğŸ“Š ç»¼åˆè¯„ä¼°ï¼š
å¸‚åœºæƒ…ç»ªåå‘ä¹è§‚ï¼Œå¤šæ•°æ–°é—»ä¼ é€’ç§¯æä¿¡å·ã€‚çŸ­æœŸå¯èƒ½å­˜åœ¨ä¸Šæ¶¨åŠ¨åŠ›ï¼Œ
ä½†éœ€å…³æ³¨æ˜¯å¦å­˜åœ¨è¿‡åº¦ä¹è§‚æƒ…ç»ªã€‚å»ºè®®ï¼š
â€¢ é€‚åº¦å‚ä¸ï¼Œä½†ä¿æŒé£é™©æ„è¯†
â€¢ å…³æ³¨æ”¯æ’‘ä½å’Œé˜»åŠ›ä½
â€¢ ç•™æ„è·åˆ©å›åå‹åŠ›
"""
        elif sentiment == 'negative':
            summary = """
ğŸ“Š ç»¼åˆè¯„ä¼°ï¼š
å¸‚åœºæƒ…ç»ªåå‘æ‚²è§‚ï¼Œè´Ÿé¢æ¶ˆæ¯å ä¸»å¯¼ã€‚çŸ­æœŸå¯èƒ½é¢ä¸´ä¸‹è¡Œå‹åŠ›ï¼Œ
éœ€è¦è°¨æ…å¯¹å¾…ã€‚å»ºè®®ï¼š
â€¢ æ§åˆ¶ä»“ä½ï¼Œé™ä½é£é™©æ•å£
â€¢ ç­‰å¾…ä¼ç¨³ä¿¡å·
â€¢ å…³æ³¨æ½œåœ¨æ”¯æ’‘ä½
"""
        else:
            summary = """
ğŸ“Š ç»¼åˆè¯„ä¼°ï¼š
å¸‚åœºæƒ…ç»ªç›¸å¯¹å¹³è¡¡ï¼Œå¤šç©ºåŒæ–¹æš‚æ—¶åƒµæŒã€‚å¸‚åœºå¯èƒ½å¤„äºç›˜æ•´é˜¶æ®µï¼Œ
æ–¹å‘å°šä¸æ˜ç¡®ã€‚å»ºè®®ï¼š
â€¢ ä¿æŒè§‚æœ›æˆ–å°ä»“ä½è¯•æ¢
â€¢ ç­‰å¾…æ˜ç¡®çªç ´ä¿¡å·
â€¢ å…³æ³¨æˆäº¤é‡å˜åŒ–
"""
        
        return summary


class CryptoSwarmNewsService:
    """
    åŠ å¯†è´§å¸Swarmæ–°é—»æœåŠ¡ä¸»ç±»
    åè°ƒä¸‰ä¸ªä»£ç†å®Œæˆæ–°é—»é‡‡é›†ã€åˆ†æå’Œæ€»ç»“
    """
    
    def __init__(self):
        self.search_agent = NewsSearchAgent()
        self.analyzer_agent = NewsAnalyzerAgent()
        self.summarizer_agent = NewsSummarizerAgent()
        logger.info("CryptoSwarmNewsService åˆå§‹åŒ–å®Œæˆ")
    
    def get_crypto_news_analysis(self, symbol: str, max_news: int = 10) -> str:
        """
        è·å–åŠ å¯†è´§å¸æ–°é—»åˆ†ææŠ¥å‘Š
        
        Args:
            symbol: åŠ å¯†è´§å¸ç¬¦å·
            max_news: æœ€å¤§æ–°é—»æ•°é‡
            
        Returns:
            æ ¼å¼åŒ–çš„åˆ†ææŠ¥å‘Š
        """
        try:
            logger.info(f"å¼€å§‹è·å– {symbol} çš„æ–°é—»åˆ†æï¼Œæœ€å¤§æ•°é‡: {max_news}")
            
            # Step 1: æœç´¢ä»£ç†è·å–æ–°é—»
            logger.info(f"Step 1: æœç´¢ä»£ç†å¼€å§‹å·¥ä½œ")
            raw_news = self.search_agent.search(symbol, max_news)
            
            if not raw_news:
                logger.warning(f"æœªæ‰¾åˆ°å…³äº {symbol} çš„æ–°é—»")
                return self.summarizer_agent._generate_no_news_report(symbol)
            
            # Step 2: åˆ†æä»£ç†å¤„ç†æ–°é—»
            logger.info(f"Step 2: åˆ†æä»£ç†å¼€å§‹å·¥ä½œï¼Œå¤„ç† {len(raw_news)} æ¡æ–°é—»")
            analyzed_data = self.analyzer_agent.analyze(raw_news, symbol)
            
            # Step 3: æ€»ç»“ä»£ç†ç”ŸæˆæŠ¥å‘Š
            logger.info(f"Step 3: æ€»ç»“ä»£ç†ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
            final_report = self.summarizer_agent.summarize(analyzed_data, symbol)
            
            logger.info(f"æˆåŠŸç”Ÿæˆ {symbol} çš„æ–°é—»åˆ†ææŠ¥å‘Š")
            return final_report
            
        except Exception as e:
            logger.error(f"è·å–åŠ å¯†è´§å¸æ–°é—»åˆ†æå¤±è´¥: {e}")
            return f"è·å– {symbol} æ–°é—»åˆ†ææ—¶å‡ºé”™: {str(e)}"
    
    def test_connection(self) -> bool:
        """æµ‹è¯•DuckDuckGoè¿æ¥"""
        try:
            test_agent = NewsSearchAgent()
            results = test_agent.search("BTC", max_results=1)
            return len(results) > 0
        except Exception as e:
            logger.error(f"è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False


# å¯¼å‡ºä¸»æœåŠ¡ç±»
__all__ = ['CryptoSwarmNewsService']