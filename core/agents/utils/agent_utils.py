from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage, AIMessage
from typing import List, Dict, Any, Callable
from typing import Annotated
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import RemoveMessage
from langchain_core.tools import tool
from datetime import date, timedelta, datetime
import functools
import pandas as pd
import os
from dateutil.relativedelta import relativedelta
from langchain_openai import ChatOpenAI
import core.dataflows.interface as interface
from core.default_config import WHENTRADE_CONFIG
from langchain_core.messages import HumanMessage

# å¯¼å…¥ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿå’Œå·¥å…·æ—¥å¿—è£…é¥°å™¨
from core.utils.tool_logging import log_tool_call, log_analysis_step

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from core.utils.logging_manager import get_logger
logger = get_logger('agents')


def timeframe_to_days(timeframe: str) -> int:
    """Convert timeframe string to number of days for data fetching"""
    timeframe_mapping = {
        '1h': 1,    # 1 hour = 1 day of data
        '4h': 1,    # 4 hours = 1 day of data  
        '1d': 7,    # 1 day = 1 week of data
        '1w': 30,   # 1 week = 1 month of data
        '1M': 180,  # 1 month = 6 months of data
    }
    return timeframe_mapping.get(timeframe, 7)  # Default to 7 days


def timeframe_to_reddit_time(timeframe: str) -> str:
    """Convert timeframe to Reddit API time parameter"""
    timeframe_mapping = {
        '1h': 'day',
        '4h': 'day',
        '1d': 'week', 
        '1w': 'month',
        '1M': 'year'
    }
    return timeframe_mapping.get(timeframe, 'week')  # Default to week


def create_msg_delete():
    def delete_messages(state):
        """Clear messages properly without adding garbage (Linus: if you don't need it, don't create it)"""
        # å¯¼å…¥æ—¥å¿—ç³»ç»Ÿ
        from core.utils.logging_init import get_logger
        logger = get_logger("default")
        
        # ğŸ”§ æ·»åŠ è°ƒè¯•ä¿¡æ¯ç¡®è®¤Msg ClearèŠ‚ç‚¹æ‰§è¡Œ
        logger.info(f"ğŸ§¹ [Msg Clear] æ­£åœ¨æ¸…ç†æ¶ˆæ¯ï¼Œå½“å‰çŠ¶æ€åŒ…å«å­—æ®µ: {list(state.keys())}")
        if "phase_1_complete" in state:
            logger.info(f"ğŸ§¹ [Msg Clear] æ£€æµ‹åˆ°Phase 1å®Œæˆæ ‡è®°: {state['phase_1_complete']}")
        if "ready_for_phase_2" in state:
            logger.info(f"ğŸ§¹ [Msg Clear] æ£€æµ‹åˆ°Phase 2å‡†å¤‡æ ‡è®°: {state['ready_for_phase_2']}")
        
        messages = state["messages"]
        logger.info(f"ğŸ§¹ [Msg Clear] å³å°†åˆ é™¤ {len(messages)} æ¡æ¶ˆæ¯")
        
        # Remove all messages
        removal_operations = [RemoveMessage(id=m.id) for m in messages]
        
        # Return clean state - no garbage placeholder
        # Sequence lock should be released by the analyst node after LLM analysis
        logger.info(f"ğŸ§¹ [Msg Clear] æ¶ˆæ¯æ¸…ç†å®Œæˆï¼Œå³å°†è½¬åˆ°ä¸‹ä¸€èŠ‚ç‚¹")
        return {"messages": removal_operations}
    
    return delete_messages


def execute_tools_directly(
    tools: List[Callable],
    ticker: str,
    llm: Any,
    system_message: str,
    state: Dict[str, Any]
) -> AIMessage:
    """
    ç›´æ¥æ‰§è¡Œå·¥å…·å¹¶ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆç”¨äºä¸æ”¯æŒå·¥å…·è°ƒç”¨çš„LLMï¼‰
    
    Args:
        tools: å·¥å…·å‡½æ•°åˆ—è¡¨
        ticker: è‚¡ç¥¨ä»£ç 
        llm: LLMå®ä¾‹
        system_message: ç³»ç»Ÿæ¶ˆæ¯
        state: AgentçŠ¶æ€
    
    Returns:
        AIMessage: åŒ…å«åˆ†æç»“æœçš„æ¶ˆæ¯
    """
    logger.info(f"ğŸ”§ [ç›´æ¥æ‰§è¡Œæ¨¡å¼] å¼€å§‹æ‰§è¡Œ{len(tools)}ä¸ªå·¥å…·")
    
    # ç›´æ¥æ‰§è¡Œæ‰€æœ‰å·¥å…·
    tool_results = []
    for tool in tools:
        try:
            tool_name = tool.__name__ if hasattr(tool, '__name__') else str(tool)
            logger.info(f"ğŸ¯ [ç›´æ¥æ‰§è¡Œ] æ­£åœ¨æ‰§è¡Œå·¥å…·: {tool_name}")
            
            # æ‰§è¡Œå·¥å…·
            if hasattr(tool, '__call__'):
                result_data = tool(ticker)
                tool_results.append({
                    "tool": tool_name,
                    "result": str(result_data)
                })
                logger.info(f"âœ… [ç›´æ¥æ‰§è¡Œ] å·¥å…·{tool_name}æ‰§è¡ŒæˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ [ç›´æ¥æ‰§è¡Œ] å·¥å…·{tool_name}æ‰§è¡Œå¤±è´¥: {str(e)}")
            tool_results.append({
                "tool": tool_name,
                "result": f"é”™è¯¯: {str(e)}"
            })
    
    # æ„å»ºå·¥å…·ç»“æœæ–‡æœ¬
    tool_results_text = "\n\n".join([
        f"## {r['tool']}\n{r['result']}" for r in tool_results
    ])
    
    # ä½¿ç”¨LLMåˆ†æå·¥å…·ç»“æœ
    analysis_prompt = ChatPromptTemplate.from_messages([
        ("system", 
         "åŸºäºä»¥ä¸‹å·¥å…·è·å–çš„æ•°æ®è¿›è¡Œåˆ†æã€‚\n\n"
         "å·¥å…·æ•°æ®ï¼š\n{tool_results}\n\n"
         "{system_message}\n\n"
         "è¯·åŸºäºä»¥ä¸Šæ•°æ®è¿›è¡Œç»¼åˆåˆ†æï¼Œå¹¶æä¾›æ˜ç¡®çš„æŠ•èµ„å»ºè®®ã€‚"),
        MessagesPlaceholder(variable_name="messages")
    ])
    
    analysis_prompt = analysis_prompt.partial(tool_results=tool_results_text)
    analysis_prompt = analysis_prompt.partial(system_message=system_message)
    
    analysis_chain = analysis_prompt | llm
    result = analysis_chain.invoke(state["messages"])
    
    return result


class Toolkit:
    _config = WHENTRADE_CONFIG.copy()
    _current_timeframe = "1d"  # Default timeframe

    @classmethod
    def update_config(cls, config):
        """Update the class-level configuration."""
        cls._config.update(config)
    
    @classmethod
    def set_timeframe(cls, timeframe: str):
        """Set the current timeframe for all tools"""
        cls._current_timeframe = timeframe

    @property
    def config(self):
        """Access the configuration."""
        return self._config

    def __init__(self, config=None, selected_tools=None, selected_data_sources=None, stop_event=None, websocket=None):
        if config:
            self.update_config(config)
        
        # Phase 2: å­˜å‚¨ç”¨æˆ·é€‰æ‹©çš„å·¥å…·é…ç½®
        self.selected_tools = selected_tools or []
        self.selected_data_sources = selected_data_sources or []
        
        # æ·»åŠ WebSocketé€šçŸ¥æ”¯æŒ
        self.stop_event = stop_event
        self.websocket = websocket
        
        # å¦‚æœæœ‰é€‰æ‹©çš„å·¥å…·ï¼Œè®°å½•ä¸€ä¸‹
        if self.selected_tools:
            logger.info(f"ğŸ”§ [Toolkit] åˆå§‹åŒ–ï¼ŒåŒ…å«ç”¨æˆ·é€‰æ‹©çš„ {len(self.selected_tools)} ä¸ªå·¥å…·")
            logger.debug(f"   å·¥å…·åˆ—è¡¨: {self.selected_tools}")
        
        # åŠ¨æ€æ³¨å†Œç”¨æˆ·é€‰æ‹©çš„å·¥å…·
        self._register_selected_tools()
    
    def _send_tool_status_sync(self, tool_name: str, status: str, **kwargs):
        """åŒæ­¥å‘é€å·¥å…·çŠ¶æ€é€šçŸ¥ï¼ˆå…¼å®¹åŒæ­¥å·¥å…·æ–¹æ³•ï¼‰"""
        if self.websocket:
            import asyncio
            import json
            
            message = {
                "type": "tool.status",
                "data": {
                    "tool_name": tool_name,
                    "status": status,
                    **kwargs
                }
            }
            
            try:
                # æ£€æŸ¥æ˜¯å¦åœ¨å¼‚æ­¥ç¯å¢ƒä¸­
                try:
                    loop = asyncio.get_event_loop()
                    if loop.is_running():
                        # åœ¨è¿è¡Œçš„äº‹ä»¶å¾ªç¯ä¸­ä½¿ç”¨create_task
                        asyncio.create_task(self.websocket.send_text(json.dumps(message)))
                    else:
                        # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
                        asyncio.run(self.websocket.send_text(json.dumps(message)))
                except RuntimeError:
                    # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
                    asyncio.run(self.websocket.send_text(json.dumps(message)))
            except Exception as e:
                logger.debug(f"WebSocketé€šçŸ¥å‘é€å¤±è´¥: {e}")
    
    def _register_selected_tools(self):
        """Phase 2: æ ¹æ®ç”¨æˆ·é€‰æ‹©åŠ¨æ€æ³¨å†Œå·¥å…·"""
        if not self.selected_tools:
            logger.debug("ğŸ”§ [Toolkit] æ²¡æœ‰ç”¨æˆ·é€‰æ‹©çš„å·¥å…·ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·é›†")
            return
        
        logger.info(f"ğŸ” [Toolkit] å¼€å§‹æ³¨å†Œå·¥å…·ï¼Œselected_tools = {self.selected_tools}")
        
        # å¯¼å…¥å·¥å…·æ³¨å†Œè¡¨å’Œå®é™…å·¥å…·
        from core.services.tools.tool_registry import ToolRegistry
        from core.services.tools.technical_tools import TechnicalAnalysisTools
        from core.services.tools.coingecko_tools import CoinGeckoTools
        from core.services.tools.sentiment_tools import SentimentAnalysisTools
        
        # å·¥å…·IDåˆ°å®é™…æ–¹æ³•çš„æ˜ å°„
        tool_method_mapping = {
            # æŠ€æœ¯åˆ†æå·¥å…·
            'crypto_price': TechnicalAnalysisTools.get_crypto_price_data,
            'indicators': TechnicalAnalysisTools.calculate_technical_indicators,
            'market_data': CoinGeckoTools.get_coin_market_data,
            'historical_data': CoinGeckoTools.get_historical_prices,
            
            # æƒ…ç»ªåˆ†æå·¥å…·
            'finnhub_news': SentimentAnalysisTools.get_finnhub_crypto_news,
            'reddit_sentiment': SentimentAnalysisTools.get_crypto_reddit_sentiment,
            'sentiment_batch': SentimentAnalysisTools.analyze_sentiment_batch,
            'fear_greed': CoinGeckoTools.get_fear_greed_index,
        }
        
        # éå†æ‰€æœ‰é€‰æ‹©çš„å·¥å…·å¹¶æ³¨å†Œ
        registered_count = 0
        for tool_id in self.selected_tools:
            logger.debug(f"ğŸ” [Toolkit] æŸ¥æ‰¾å·¥å…·: {tool_id}")
            # åœ¨æ‰€æœ‰åˆ†ç±»ä¸­æŸ¥æ‰¾å·¥å…·
            found = False
            for category, tools in ToolRegistry.TOOL_REGISTRY.items():
                logger.debug(f"ğŸ” [Toolkit] æ£€æŸ¥åˆ†ç±» {category}ï¼ŒåŒ…å«å·¥å…·: {list(tools.keys())[:5]}...")
                if tool_id in tools:
                    tool_info = tools[tool_id]
                    logger.info(f"âœ… [Toolkit] æ³¨å†Œå·¥å…·: {tool_id} ({tool_info.get('display_name', tool_info['name'])})")
                    
                    # è·å–å®é™…çš„å·¥å…·æ–¹æ³•
                    tool_method = tool_method_mapping.get(tool_id, tool_info['function'])
                    logger.debug(f"ğŸ” [Toolkit] å·¥å…·æ–¹æ³•: {tool_method}")
                    
                    # åŠ¨æ€åˆ›å»ºå·¥å…·æ–¹æ³•å¹¶ç»‘å®šåˆ°self
                    # ä½¿ç”¨tool_idä½œä¸ºå±æ€§åï¼Œè¿™æ ·market_analystå¯ä»¥é€šè¿‡getattrè·å–
                    setattr(self, tool_id, tool_method)
                    
                    # ä¹Ÿåˆ›å»ºtool_å‰ç¼€çš„ç‰ˆæœ¬ä»¥ä¿æŒå…¼å®¹æ€§
                    setattr(self, f"tool_{tool_id}", tool_method)
                    
                    registered_count += 1
                    found = True
                    break
            
            if not found:
                logger.warning(f"âš ï¸ [Toolkit] æœªæ‰¾åˆ°å·¥å…·: {tool_id}")
        
        logger.info(f"ğŸ¯ [Toolkit] å·¥å…·æ³¨å†Œå®Œæˆï¼ŒæˆåŠŸæ³¨å†Œ {registered_count}/{len(self.selected_tools)} ä¸ªå·¥å…·")

    @staticmethod
    @tool
    def get_reddit_news(
        curr_date: Annotated[str, "Date you want to get news for in yyyy-mm-dd format"],
    ) -> str:
        """
        Retrieve global news from Reddit within a specified time frame.
        Args:
            curr_date (str): Date you want to get news for in yyyy-mm-dd format
        Returns:
            str: A formatted dataframe containing the latest global news from Reddit in the specified time frame.
        """
        
        global_news_result = interface.get_reddit_global_news(curr_date, 7, 5)

        return global_news_result

    @staticmethod
    @tool
    def get_finnhub_news(
        ticker: Annotated[
            str,
            "Search query of a company, e.g. 'AAPL, TSM, etc.",
        ],
        start_date: Annotated[str, "Start date in yyyy-mm-dd format"],
        end_date: Annotated[str, "End date in yyyy-mm-dd format"],
    ):
        """
        Retrieve the latest news about a given stock from Finnhub within a date range
        Args:
            ticker (str): Ticker of a company. e.g. AAPL, TSM
            start_date (str): Start date in yyyy-mm-dd format
            end_date (str): End date in yyyy-mm-dd format
        Returns:
            str: A formatted dataframe containing news about the company within the date range from start_date to end_date
        """

        end_date_str = end_date

        end_date = datetime.strptime(end_date, "%Y-%m-%d")
        start_date = datetime.strptime(start_date, "%Y-%m-%d")
        look_back_days = (end_date - start_date).days

        finnhub_news_result = interface.get_finnhub_news(
            ticker, end_date_str, look_back_days
        )

        return finnhub_news_result

    @staticmethod
    @tool
    def get_reddit_stock_info(
        ticker: Annotated[
            str,
            "Ticker of a company. e.g. AAPL, TSM",
        ],
        curr_date: Annotated[str, "Current date you want to get news for"],
    ) -> str:
        """
        Retrieve the latest Reddit sentiment about a given stock using Reddit public API.
        Args:
            ticker (str): Ticker of a company. e.g. AAPL, TSM
            curr_date (str): current date in yyyy-mm-dd format to get news for
        Returns:
            str: Formatted Reddit sentiment analysis data
        """
        import requests
        import json
        from datetime import datetime, timedelta
        
        try:
            # æ ¹æ®è‚¡ç¥¨ç±»å‹é€‰æ‹©ç›¸å…³subreddit
            if ticker.upper() in ['BTC', 'BITCOIN']:
                subreddits = ['Bitcoin', 'CryptoCurrency', 'btc']
                search_terms = ['BTC', 'Bitcoin', 'bitcoin']
            elif ticker.upper() in ['ETH', 'ETHEREUM']:
                subreddits = ['ethereum', 'CryptoCurrency', 'ethfinance']
                search_terms = ['ETH', 'Ethereum', 'ethereum']
            else:
                subreddits = ['wallstreetbets', 'stocks', 'investing']
                search_terms = [ticker.upper(), ticker.lower()]
            
            sentiment_data = {
                'total_posts': 0,
                'total_score': 0,
                'total_comments': 0,
                'positive_posts': 0,
                'negative_posts': 0,
                'neutral_posts': 0,
                'top_posts': []
            }
            
            headers = {'User-Agent': 'WhenTrade-Analysis/1.0'}
            
            # æœç´¢æ¯ä¸ªsubreddit
            for subreddit in subreddits:
                for search_term in search_terms:
                    try:
                        url = f"https://www.reddit.com/r/{subreddit}/search.json"
                        params = {
                            'q': search_term,
                            'sort': 'relevance',
                            'time': timeframe_to_reddit_time(Toolkit._current_timeframe),
                            'limit': 15,
                            'restrict_sr': 'true'
                        }
                        
                        response = requests.get(url, params=params, headers=headers, timeout=10)
                        if response.status_code == 200:
                            data = response.json()
                            if 'data' in data and 'children' in data['data']:
                                posts = data['data']['children']
                                
                                for post in posts:
                                    if 'data' not in post:
                                        continue
                                        
                                    post_data = post['data']
                                    score = post_data.get('score', 0)
                                    title = post_data.get('title', '').lower()
                                    num_comments = post_data.get('num_comments', 0)
                                    
                                    sentiment_data['total_posts'] += 1
                                    sentiment_data['total_score'] += score
                                    sentiment_data['total_comments'] += num_comments
                                    
                                    # ä¿å­˜é«˜åˆ†å¸–å­
                                    if score > 50:
                                        sentiment_data['top_posts'].append({
                                            'title': post_data.get('title', ''),
                                            'score': score,
                                            'comments': num_comments,
                                            'subreddit': subreddit
                                        })
                                    
                                    # ç®€å•æƒ…ç»ªåˆ†æ
                                    positive_keywords = ['bullish', 'moon', 'buy', 'long', 'pump', 'hodl', 'rally', 'breakout']
                                    negative_keywords = ['bearish', 'crash', 'sell', 'short', 'dump', 'drop', 'fall', 'dip']
                                    
                                    if any(word in title for word in positive_keywords) or score > 100:
                                        sentiment_data['positive_posts'] += 1
                                    elif any(word in title for word in negative_keywords) or score < 0:
                                        sentiment_data['negative_posts'] += 1
                                    else:
                                        sentiment_data['neutral_posts'] += 1
                                        
                    except requests.RequestException as req_e:
                        logger.warning(f"âš ï¸ Redditè¯·æ±‚å¤±è´¥ ({subreddit}): {req_e}")
                        continue
                    except Exception as parse_e:
                        logger.warning(f"âš ï¸ Redditæ•°æ®è§£æå¤±è´¥: {parse_e}")
                        continue
            
            # è®¡ç®—æƒ…ç»ªæŒ‡æ ‡
            total_posts = sentiment_data['total_posts']
            if total_posts == 0:
                return f"## {ticker} Redditæƒ…ç»ªåˆ†æ\n\næš‚æ— æ‰¾åˆ°ç›¸å…³è®¨è®ºæ•°æ®"
            
            avg_score = sentiment_data['total_score'] / total_posts if total_posts > 0 else 0
            sentiment_score = (sentiment_data['positive_posts'] - sentiment_data['negative_posts']) / total_posts * 100
            
            # æ ¼å¼åŒ–ç»“æœ
            result_lines = [
                f"## {ticker} Redditæƒ…ç»ªåˆ†æ",
                f"**åˆ†æå¸–å­æ•°**: {total_posts}",
                f"**å¹³å‡å¾—åˆ†**: {avg_score:.1f}",
                f"**æ€»è¯„è®ºæ•°**: {sentiment_data['total_comments']}",
                f"**æ­£é¢å¸–å­**: {sentiment_data['positive_posts']} ({sentiment_data['positive_posts']/total_posts*100:.1f}%)",
                f"**è´Ÿé¢å¸–å­**: {sentiment_data['negative_posts']} ({sentiment_data['negative_posts']/total_posts*100:.1f}%)",
                f"**ä¸­æ€§å¸–å­**: {sentiment_data['neutral_posts']} ({sentiment_data['neutral_posts']/total_posts*100:.1f}%)",
                f"**æƒ…ç»ªè¯„åˆ†**: {sentiment_score:.1f}% ({'ç§¯æ' if sentiment_score > 10 else 'æ¶ˆæ' if sentiment_score < -10 else 'ä¸­æ€§'})",
            ]
            
            # æ·»åŠ çƒ­é—¨è®¨è®º
            if sentiment_data['top_posts']:
                result_lines.append(f"\n### çƒ­é—¨è®¨è®º")
                top_posts = sorted(sentiment_data['top_posts'], key=lambda x: x['score'], reverse=True)[:3]
                for i, post in enumerate(top_posts, 1):
                    result_lines.append(f"{i}. **{post['title'][:80]}...** ({post['score']} ğŸ‘, {post['comments']} ğŸ’¬)")
            
            result_lines.append(f"\n*æ•°æ®æ¥æº: Redditå…¬å¼€API, åˆ†ææ—¶é—´: {curr_date}*")
            
            return "\n".join(result_lines)
            
        except Exception as e:
            logger.error(f"âŒ Redditæƒ…ç»ªè·å–å¤±è´¥: {e}")
            return f"## {ticker} Redditæƒ…ç»ªåˆ†æ\n\nRedditæƒ…ç»ªåˆ†ææš‚æ—¶ä¸å¯ç”¨: {str(e)}\n\n*å»ºè®®ï¼šè¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥*"

    @staticmethod
    @tool
    def get_chinese_social_sentiment(
        ticker: Annotated[str, "Ticker of a company. e.g. AAPL, TSM"],
        curr_date: Annotated[str, "Current date in yyyy-mm-dd format"],
    ) -> str:
        """
        è·å–ä¸­å›½ç¤¾äº¤åª’ä½“å’Œè´¢ç»å¹³å°ä¸Šå…³äºç‰¹å®šè‚¡ç¥¨çš„æƒ…ç»ªåˆ†æå’Œè®¨è®ºçƒ­åº¦ã€‚
        æ•´åˆé›ªçƒã€ä¸œæ–¹è´¢å¯Œè‚¡å§ã€æ–°æµªè´¢ç»ç­‰ä¸­å›½æœ¬åœŸå¹³å°çš„æ•°æ®ã€‚
        Args:
            ticker (str): è‚¡ç¥¨ä»£ç ï¼Œå¦‚ AAPL, TSM
            curr_date (str): å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸º yyyy-mm-dd
        Returns:
            str: åŒ…å«ä¸­å›½æŠ•èµ„è€…æƒ…ç»ªåˆ†æã€è®¨è®ºçƒ­åº¦ã€å…³é”®è§‚ç‚¹çš„æ ¼å¼åŒ–æŠ¥å‘Š
        """
        try:
            # è¿™é‡Œå¯ä»¥é›†æˆå¤šä¸ªä¸­å›½å¹³å°çš„æ•°æ®
            chinese_sentiment_results = interface.get_chinese_social_sentiment(ticker, curr_date)
            return chinese_sentiment_results
        except Exception as e:
            # å¦‚æœä¸­å›½å¹³å°æ•°æ®è·å–å¤±è´¥ï¼Œå›é€€åˆ°åŸæœ‰çš„Redditæ•°æ®
            return interface.get_reddit_company_news(ticker, curr_date, 7, 5)

    @staticmethod
    # @tool  # å·²ç§»é™¤ï¼šè¯·ä½¿ç”¨ get_stock_fundamentals_unified æˆ– get_stock_market_data_unified
    def get_china_stock_data(
        stock_code: Annotated[str, "ä¸­å›½è‚¡ç¥¨ä»£ç ï¼Œå¦‚ 000001(å¹³å®‰é“¶è¡Œ), 600519(è´µå·èŒ…å°)"],
        start_date: Annotated[str, "å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ yyyy-mm-dd"],
        end_date: Annotated[str, "ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ yyyy-mm-dd"],
    ) -> str:
        """
        è·å–ä¸­å›½Aè‚¡å®æ—¶å’Œå†å²æ•°æ®ï¼Œé€šè¿‡Tushareç­‰é«˜è´¨é‡æ•°æ®æºæä¾›ä¸“ä¸šçš„è‚¡ç¥¨æ•°æ®ã€‚
        æ”¯æŒå®æ—¶è¡Œæƒ…ã€å†å²Kçº¿ã€æŠ€æœ¯æŒ‡æ ‡ç­‰å…¨é¢æ•°æ®ï¼Œè‡ªåŠ¨ä½¿ç”¨æœ€ä½³æ•°æ®æºã€‚
        Args:
            stock_code (str): ä¸­å›½è‚¡ç¥¨ä»£ç ï¼Œå¦‚ 000001(å¹³å®‰é“¶è¡Œ), 600519(è´µå·èŒ…å°)
            start_date (str): å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ yyyy-mm-dd
            end_date (str): ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ yyyy-mm-dd
        Returns:
            str: åŒ…å«å®æ—¶è¡Œæƒ…ã€å†å²æ•°æ®ã€æŠ€æœ¯æŒ‡æ ‡çš„å®Œæ•´è‚¡ç¥¨åˆ†ææŠ¥å‘Š
        """
        try:
            logger.debug(f"ğŸ“Š [DEBUG] ===== agent_utils.get_china_stock_data å¼€å§‹è°ƒç”¨ =====")
            logger.debug(f"ğŸ“Š [DEBUG] å‚æ•°: stock_code={stock_code}, start_date={start_date}, end_date={end_date}")

            from core.dataflows.interface import get_china_stock_data_unified
            logger.debug(f"ğŸ“Š [DEBUG] æˆåŠŸå¯¼å…¥ç»Ÿä¸€æ•°æ®æºæ¥å£")

            logger.debug(f"ğŸ“Š [DEBUG] æ­£åœ¨è°ƒç”¨ç»Ÿä¸€æ•°æ®æºæ¥å£...")
            result = get_china_stock_data_unified(stock_code, start_date, end_date)

            logger.debug(f"ğŸ“Š [DEBUG] ç»Ÿä¸€æ•°æ®æºæ¥å£è°ƒç”¨å®Œæˆ")
            logger.debug(f"ğŸ“Š [DEBUG] è¿”å›ç»“æœç±»å‹: {type(result)}")
            logger.debug(f"ğŸ“Š [DEBUG] è¿”å›ç»“æœé•¿åº¦: {len(result) if result else 0}")
            logger.debug(f"ğŸ“Š [DEBUG] è¿”å›ç»“æœå‰200å­—ç¬¦: {str(result)[:200]}...")
            logger.debug(f"ğŸ“Š [DEBUG] ===== agent_utils.get_china_stock_data è°ƒç”¨ç»“æŸ =====")

            return result
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            logger.error(f"âŒ [DEBUG] ===== agent_utils.get_china_stock_data å¼‚å¸¸ =====")
            logger.error(f"âŒ [DEBUG] é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"âŒ [DEBUG] é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error(f"âŒ [DEBUG] è¯¦ç»†å †æ ˆ:")
            print(error_details)
            logger.error(f"âŒ [DEBUG] ===== å¼‚å¸¸å¤„ç†ç»“æŸ =====")
            return f"ä¸­å›½è‚¡ç¥¨æ•°æ®è·å–å¤±è´¥: {str(e)}ã€‚å»ºè®®å®‰è£…pytdxåº“: pip install pytdx"

    @staticmethod
    @tool
    def get_china_market_overview(
        curr_date: Annotated[str, "å½“å‰æ—¥æœŸï¼Œæ ¼å¼ yyyy-mm-dd"],
    ) -> str:
        """
        è·å–ä¸­å›½è‚¡å¸‚æ•´ä½“æ¦‚è§ˆï¼ŒåŒ…æ‹¬ä¸»è¦æŒ‡æ•°çš„å®æ—¶è¡Œæƒ…ã€‚
        æ¶µç›–ä¸Šè¯æŒ‡æ•°ã€æ·±è¯æˆæŒ‡ã€åˆ›ä¸šæ¿æŒ‡ã€ç§‘åˆ›50ç­‰ä¸»è¦æŒ‡æ•°ã€‚
        Args:
            curr_date (str): å½“å‰æ—¥æœŸï¼Œæ ¼å¼ yyyy-mm-dd
        Returns:
            str: åŒ…å«ä¸»è¦æŒ‡æ•°å®æ—¶è¡Œæƒ…çš„å¸‚åœºæ¦‚è§ˆæŠ¥å‘Š
        """
        try:
            # ä½¿ç”¨Tushareè·å–ä¸»è¦æŒ‡æ•°æ•°æ®
            from core.dataflows.tushare_adapter import get_tushare_adapter

            adapter = get_tushare_adapter()
            if not adapter.provider or not adapter.provider.connected:
                # å¦‚æœTushareä¸å¯ç”¨ï¼Œå›é€€åˆ°TDX
                logger.warning(f"âš ï¸ Tushareä¸å¯ç”¨ï¼Œå›é€€åˆ°TDXè·å–å¸‚åœºæ¦‚è§ˆ")
                from core.dataflows.tdx_utils import get_china_market_overview
                return get_china_market_overview()

            # ä½¿ç”¨Tushareè·å–ä¸»è¦æŒ‡æ•°ä¿¡æ¯
            # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºè·å–å…·ä½“çš„æŒ‡æ•°æ•°æ®
            return f"""# ä¸­å›½è‚¡å¸‚æ¦‚è§ˆ - {curr_date}

## ğŸ“Š ä¸»è¦æŒ‡æ•°
- ä¸Šè¯æŒ‡æ•°: æ•°æ®è·å–ä¸­...
- æ·±è¯æˆæŒ‡: æ•°æ®è·å–ä¸­...
- åˆ›ä¸šæ¿æŒ‡: æ•°æ®è·å–ä¸­...
- ç§‘åˆ›50: æ•°æ®è·å–ä¸­...

## ğŸ’¡ è¯´æ˜
å¸‚åœºæ¦‚è§ˆåŠŸèƒ½æ­£åœ¨ä»TDXè¿ç§»åˆ°Tushareï¼Œå®Œæ•´åŠŸèƒ½å³å°†æ¨å‡ºã€‚
å½“å‰å¯ä»¥ä½¿ç”¨è‚¡ç¥¨æ•°æ®è·å–åŠŸèƒ½åˆ†æä¸ªè‚¡ã€‚

æ•°æ®æ¥æº: Tushareä¸“ä¸šæ•°æ®æº
æ›´æ–°æ—¶é—´: {curr_date}
"""

        except Exception as e:
            return f"ä¸­å›½å¸‚åœºæ¦‚è§ˆè·å–å¤±è´¥: {str(e)}ã€‚æ­£åœ¨ä»TDXè¿ç§»åˆ°Tushareæ•°æ®æºã€‚"

    @tool
    def get_YFin_data(
        self,
        symbol: Annotated[str, "ticker symbol of the company"],
        start_date: Annotated[str, "Start date in yyyy-mm-dd format"],
        end_date: Annotated[str, "End date in yyyy-mm-dd format"],
    ) -> str:
        """
        Retrieve the stock price data for a given ticker symbol from Yahoo Finance.
        Args:
            symbol (str): Ticker symbol of the company, e.g. AAPL, TSM
            start_date (str): Start date in yyyy-mm-dd format
            end_date (str): End date in yyyy-mm-dd format
        Returns:
            str: A formatted dataframe containing the stock price data for the specified ticker symbol in the specified date range.
        """
        logger.info(f"ğŸ“Š [YFinå·¥å…·] è·å–è‚¡ç¥¨æ•°æ®: {symbol}")
        
        # å‘é€å¼€å§‹é€šçŸ¥
        self._send_tool_status_sync(
            tool_name="get_YFin_data",
            status="starting",
            symbol=symbol,
            message=f"å¼€å§‹è·å– {symbol} Yahoo Financeæ•°æ®"
        )
        
        try:
            result_data = interface.get_YFin_data(symbol, start_date, end_date)
            
            # å‘é€æˆåŠŸé€šçŸ¥
            self._send_tool_status_sync(
                tool_name="get_YFin_data",
                status="completed",
                symbol=symbol,
                message=f"æˆåŠŸè·å– {symbol} Yahoo Financeæ•°æ®"
            )
            
            logger.info(f"âœ… [YFinå·¥å…·] æ•°æ®è·å–æˆåŠŸ: {symbol}")
            return result_data
            
        except Exception as e:
            error_msg = f"Yahoo Financeæ•°æ®è·å–å¤±è´¥: {str(e)}"
            logger.error(f"âŒ [YFinå·¥å…·] {error_msg}")
            
            # å‘é€é”™è¯¯é€šçŸ¥
            self._send_tool_status_sync(
                tool_name="get_YFin_data",
                status="failed",
                symbol=symbol,
                message=error_msg
            )
            
            return error_msg

    @staticmethod
    @tool
    def get_YFin_data_online(
        symbol: Annotated[str, "ticker symbol of the company"],
        start_date: Annotated[str, "Start date in yyyy-mm-dd format"],
        end_date: Annotated[str, "End date in yyyy-mm-dd format"],
    ) -> str:
        """
        Retrieve the stock price data for a given ticker symbol from Yahoo Finance.
        Args:
            symbol (str): Ticker symbol of the company, e.g. AAPL, TSM
            start_date (str): Start date in yyyy-mm-dd format
            end_date (str): End date in yyyy-mm-dd format
        Returns:
            str: A formatted dataframe containing the stock price data for the specified ticker symbol in the specified date range.
        """

        result_data = interface.get_YFin_data_online(symbol, start_date, end_date)

        return result_data

    @staticmethod
    @tool
    def get_stockstats_indicators_report(
        symbol: Annotated[str, "ticker symbol of the company"],
        indicator: Annotated[
            str, "technical indicator to get the analysis and report of"
        ],
        curr_date: Annotated[
            str, "The current trading date you are trading on, YYYY-mm-dd"
        ],
        look_back_days: Annotated[int, "how many days to look back"] = 30,
    ) -> str:
        """
        Retrieve stock stats indicators for a given ticker symbol and indicator.
        Args:
            symbol (str): Ticker symbol of the company, e.g. AAPL, TSM
            indicator (str): Technical indicator to get the analysis and report of
            curr_date (str): The current trading date you are trading on, YYYY-mm-dd
            look_back_days (int): How many days to look back, default is 30
        Returns:
            str: A formatted dataframe containing the stock stats indicators for the specified ticker symbol and indicator.
        """

        result_stockstats = interface.get_stock_stats_indicators_window(
            symbol, indicator, curr_date, look_back_days, False
        )

        return result_stockstats

    @staticmethod
    @tool
    def get_stockstats_indicators_report_online(
        symbol: Annotated[str, "ticker symbol of the company"],
        indicator: Annotated[
            str, "technical indicator to get the analysis and report of"
        ],
        curr_date: Annotated[
            str, "The current trading date you are trading on, YYYY-mm-dd"
        ],
        look_back_days: Annotated[int, "how many days to look back"] = 30,
    ) -> str:
        """
        Retrieve stock stats indicators for a given ticker symbol and indicator.
        Args:
            symbol (str): Ticker symbol of the company, e.g. AAPL, TSM
            indicator (str): Technical indicator to get the analysis and report of
            curr_date (str): The current trading date you are trading on, YYYY-mm-dd
            look_back_days (int): How many days to look back, default is 30
        Returns:
            str: A formatted dataframe containing the stock stats indicators for the specified ticker symbol and indicator.
        """

        result_stockstats = interface.get_stock_stats_indicators_window(
            symbol, indicator, curr_date, look_back_days, True
        )

        return result_stockstats

    @staticmethod
    @tool
    def get_finnhub_company_insider_sentiment(
        ticker: Annotated[str, "ticker symbol for the company"],
        curr_date: Annotated[
            str,
            "current date of you are trading at, yyyy-mm-dd",
        ],
    ):
        """
        Retrieve insider sentiment information about a company (retrieved from public SEC information) for the past 30 days
        Args:
            ticker (str): ticker symbol of the company
            curr_date (str): current date you are trading at, yyyy-mm-dd
        Returns:
            str: a report of the sentiment in the past 30 days starting at curr_date
        """

        data_sentiment = interface.get_finnhub_company_insider_sentiment(
            ticker, curr_date, 30
        )

        return data_sentiment

    @staticmethod
    @tool
    def get_finnhub_company_insider_transactions(
        ticker: Annotated[str, "ticker symbol"],
        curr_date: Annotated[
            str,
            "current date you are trading at, yyyy-mm-dd",
        ],
    ):
        """
        Retrieve insider transaction information about a company (retrieved from public SEC information) for the past 30 days
        Args:
            ticker (str): ticker symbol of the company
            curr_date (str): current date you are trading at, yyyy-mm-dd
        Returns:
            str: a report of the company's insider transactions/trading information in the past 30 days
        """

        data_trans = interface.get_finnhub_company_insider_transactions(
            ticker, curr_date, 30
        )

        return data_trans

    @staticmethod
    @tool
    def get_simfin_balance_sheet(
        ticker: Annotated[str, "ticker symbol"],
        freq: Annotated[
            str,
            "reporting frequency of the company's financial history: annual/quarterly",
        ],
        curr_date: Annotated[str, "current date you are trading at, yyyy-mm-dd"],
    ):
        """
        Retrieve the most recent balance sheet of a company
        Args:
            ticker (str): ticker symbol of the company
            freq (str): reporting frequency of the company's financial history: annual / quarterly
            curr_date (str): current date you are trading at, yyyy-mm-dd
        Returns:
            str: a report of the company's most recent balance sheet
        """

        data_balance_sheet = interface.get_simfin_balance_sheet(ticker, freq, curr_date)

        return data_balance_sheet

    @staticmethod
    @tool
    def get_simfin_cashflow(
        ticker: Annotated[str, "ticker symbol"],
        freq: Annotated[
            str,
            "reporting frequency of the company's financial history: annual/quarterly",
        ],
        curr_date: Annotated[str, "current date you are trading at, yyyy-mm-dd"],
    ):
        """
        Retrieve the most recent cash flow statement of a company
        Args:
            ticker (str): ticker symbol of the company
            freq (str): reporting frequency of the company's financial history: annual / quarterly
            curr_date (str): current date you are trading at, yyyy-mm-dd
        Returns:
                str: a report of the company's most recent cash flow statement
        """

        data_cashflow = interface.get_simfin_cashflow(ticker, freq, curr_date)

        return data_cashflow

    @staticmethod
    @tool
    def get_simfin_income_stmt(
        ticker: Annotated[str, "ticker symbol"],
        freq: Annotated[
            str,
            "reporting frequency of the company's financial history: annual/quarterly",
        ],
        curr_date: Annotated[str, "current date you are trading at, yyyy-mm-dd"],
    ):
        """
        Retrieve the most recent income statement of a company
        Args:
            ticker (str): ticker symbol of the company
            freq (str): reporting frequency of the company's financial history: annual / quarterly
            curr_date (str): current date you are trading at, yyyy-mm-dd
        Returns:
                str: a report of the company's most recent income statement
        """

        data_income_stmt = interface.get_simfin_income_statements(
            ticker, freq, curr_date
        )

        return data_income_stmt

    @staticmethod
    @tool
    def get_google_news(
        query: Annotated[str, "Query to search with"],
        curr_date: Annotated[str, "Curr date in yyyy-mm-dd format"],
    ):
        """
        Retrieve the latest news from Google News based on a query and date range.
        Args:
            query (str): Query to search with
            curr_date (str): Current date in yyyy-mm-dd format
            look_back_days (int): How many days to look back
        Returns:
            str: A formatted string containing the latest news from Google News based on the query and date range.
        """

        google_news_results = interface.get_google_news(query, curr_date, 7)

        return google_news_results

    @staticmethod
    @tool
    def get_realtime_stock_news(
        ticker: Annotated[str, "Ticker of a company. e.g. AAPL, TSM"],
        curr_date: Annotated[str, "Current date in yyyy-mm-dd format"],
    ) -> str:
        """
        è·å–è‚¡ç¥¨çš„å®æ—¶æ–°é—»åˆ†æï¼Œè§£å†³ä¼ ç»Ÿæ–°é—»æºçš„æ»åæ€§é—®é¢˜ã€‚
        æ•´åˆå¤šä¸ªä¸“ä¸šè´¢ç»APIï¼Œæä¾›15-30åˆ†é’Ÿå†…çš„æœ€æ–°æ–°é—»ã€‚
        æ”¯æŒå¤šç§æ–°é—»æºè½®è¯¢æœºåˆ¶ï¼Œä¼˜å…ˆä½¿ç”¨å®æ—¶æ–°é—»èšåˆå™¨ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨å°è¯•å¤‡ç”¨æ–°é—»æºã€‚
        å¯¹äºAè‚¡å’Œæ¸¯è‚¡ï¼Œä¼šä¼˜å…ˆä½¿ç”¨ä¸­æ–‡è´¢ç»æ–°é—»æºï¼ˆå¦‚ä¸œæ–¹è´¢å¯Œï¼‰ã€‚
        
        Args:
            ticker (str): è‚¡ç¥¨ä»£ç ï¼Œå¦‚ AAPL, TSM, 600036.SH
            curr_date (str): å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸º yyyy-mm-dd
        Returns:
            str: åŒ…å«å®æ—¶æ–°é—»åˆ†æã€ç´§æ€¥ç¨‹åº¦è¯„ä¼°ã€æ—¶æ•ˆæ€§è¯´æ˜çš„æ ¼å¼åŒ–æŠ¥å‘Š
        """
        from core.dataflows.realtime_news_utils import get_realtime_stock_news
        return get_realtime_stock_news(ticker, curr_date, hours_back=6)

    @tool
    def get_stock_news_openai(
        self,
        ticker: Annotated[str, "the company's ticker"],
        curr_date: Annotated[str, "Current date in yyyy-mm-dd format"],
    ):
        """
        Retrieve the latest news about a given stock by using OpenAI's news API.
        Args:
            ticker (str): Ticker of a company. e.g. AAPL, TSM
            curr_date (str): Current date in yyyy-mm-dd format
        Returns:
            str: A formatted string containing the latest news about the company on the given date.
        """
        logger.info(f"ğŸ“° [OpenAIæ–°é—»å·¥å…·] è·å– {ticker} è‚¡ç¥¨æ–°é—»")
        
        # å‘é€å¼€å§‹é€šçŸ¥
        self._send_tool_status_sync(
            tool_name="get_stock_news_openai",
            status="starting",
            symbol=ticker,
            message=f"å¼€å§‹è·å– {ticker} OpenAIè‚¡ç¥¨æ–°é—»"
        )
        
        try:
            openai_news_results = interface.get_stock_news_openai(ticker, curr_date, Toolkit._current_timeframe)
            
            # å‘é€æˆåŠŸé€šçŸ¥
            self._send_tool_status_sync(
                tool_name="get_stock_news_openai",
                status="completed",
                symbol=ticker,
                message=f"æˆåŠŸè·å– {ticker} OpenAIè‚¡ç¥¨æ–°é—»"
            )
            
            logger.info(f"âœ… [OpenAIæ–°é—»å·¥å…·] æ–°é—»è·å–æˆåŠŸ: {ticker}")
            return openai_news_results
            
        except Exception as e:
            error_msg = f"OpenAIè‚¡ç¥¨æ–°é—»è·å–å¤±è´¥: {str(e)}"
            logger.error(f"âŒ [OpenAIæ–°é—»å·¥å…·] {error_msg}")
            
            # å‘é€é”™è¯¯é€šçŸ¥
            self._send_tool_status_sync(
                tool_name="get_stock_news_openai",
                status="failed",
                symbol=ticker,
                message=error_msg
            )
            
            return error_msg

    @staticmethod
    @tool
    def get_global_news_openai(
        curr_date: Annotated[str, "Current date in yyyy-mm-dd format"],
    ):
        """
        Retrieve the latest macroeconomics news on a given date using OpenAI's macroeconomics news API.
        Args:
            curr_date (str): Current date in yyyy-mm-dd format
        Returns:
            str: A formatted string containing the latest macroeconomic news on the given date.
        """

        openai_news_results = interface.get_global_news_openai(curr_date)

        return openai_news_results

    @staticmethod
    # @tool  # å·²ç§»é™¤ï¼šè¯·ä½¿ç”¨ get_stock_fundamentals_unified
    def get_fundamentals_openai(
        ticker: Annotated[str, "the company's ticker"],
        curr_date: Annotated[str, "Current date in yyyy-mm-dd format"],
    ):
        """
        Retrieve the latest fundamental information about a given stock on a given date by using OpenAI's news API.
        Args:
            ticker (str): Ticker of a company. e.g. AAPL, TSM
            curr_date (str): Current date in yyyy-mm-dd format
        Returns:
            str: A formatted string containing the latest fundamental information about the company on the given date.
        """
        logger.debug(f"ğŸ“Š [DEBUG] get_fundamentals_openai è¢«è°ƒç”¨: ticker={ticker}, date={curr_date}")

        # æ£€æŸ¥æ˜¯å¦ä¸ºä¸­å›½è‚¡ç¥¨
        import re
        if re.match(r'^\d{6}$', str(ticker)):
            logger.debug(f"ğŸ“Š [DEBUG] æ£€æµ‹åˆ°ä¸­å›½Aè‚¡ä»£ç : {ticker}")
            # ä½¿ç”¨ç»Ÿä¸€æ¥å£è·å–ä¸­å›½è‚¡ç¥¨åç§°
            try:
                from core.dataflows.interface import get_china_stock_info_unified
                stock_info = get_china_stock_info_unified(ticker)

                # è§£æè‚¡ç¥¨åç§°
                if "è‚¡ç¥¨åç§°:" in stock_info:
                    company_name = stock_info.split("è‚¡ç¥¨åç§°:")[1].split("\n")[0].strip()
                else:
                    company_name = f"è‚¡ç¥¨ä»£ç {ticker}"

                logger.debug(f"ğŸ“Š [DEBUG] ä¸­å›½è‚¡ç¥¨åç§°æ˜ å°„: {ticker} -> {company_name}")
            except Exception as e:
                logger.error(f"âš ï¸ [DEBUG] ä»ç»Ÿä¸€æ¥å£è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")
                company_name = f"è‚¡ç¥¨ä»£ç {ticker}"

            # ä¿®æ”¹æŸ¥è¯¢ä»¥åŒ…å«æ­£ç¡®çš„å…¬å¸åç§°
            modified_query = f"{company_name}({ticker})"
            logger.debug(f"ğŸ“Š [DEBUG] ä¿®æ”¹åçš„æŸ¥è¯¢: {modified_query}")
        else:
            logger.debug(f"ğŸ“Š [DEBUG] æ£€æµ‹åˆ°éä¸­å›½è‚¡ç¥¨: {ticker}")
            modified_query = ticker

        try:
            openai_fundamentals_results = interface.get_fundamentals_openai(
                modified_query, curr_date
            )
            logger.debug(f"ğŸ“Š [DEBUG] OpenAIåŸºæœ¬é¢åˆ†æç»“æœé•¿åº¦: {len(openai_fundamentals_results) if openai_fundamentals_results else 0}")
            return openai_fundamentals_results
        except Exception as e:
            logger.error(f"âŒ [DEBUG] OpenAIåŸºæœ¬é¢åˆ†æå¤±è´¥: {str(e)}")
            return f"åŸºæœ¬é¢åˆ†æå¤±è´¥: {str(e)}"

    @staticmethod
    # @tool  # å·²ç§»é™¤ï¼šè¯·ä½¿ç”¨ get_stock_fundamentals_unified
    def get_china_fundamentals(
        ticker: Annotated[str, "ä¸­å›½Aè‚¡è‚¡ç¥¨ä»£ç ï¼Œå¦‚600036"],
        curr_date: Annotated[str, "å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸ºyyyy-mm-dd"],
    ):
        """
        è·å–ä¸­å›½Aè‚¡è‚¡ç¥¨çš„åŸºæœ¬é¢ä¿¡æ¯ï¼Œä½¿ç”¨ä¸­å›½è‚¡ç¥¨æ•°æ®æºã€‚
        Args:
            ticker (str): ä¸­å›½Aè‚¡è‚¡ç¥¨ä»£ç ï¼Œå¦‚600036, 000001
            curr_date (str): å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸ºyyyy-mm-dd
        Returns:
            str: åŒ…å«è‚¡ç¥¨åŸºæœ¬é¢ä¿¡æ¯çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        """
        logger.debug(f"ğŸ“Š [DEBUG] get_china_fundamentals è¢«è°ƒç”¨: ticker={ticker}, date={curr_date}")

        # æ£€æŸ¥æ˜¯å¦ä¸ºä¸­å›½è‚¡ç¥¨
        import re
        if not re.match(r'^\d{6}$', str(ticker)):
            return f"é”™è¯¯ï¼š{ticker} ä¸æ˜¯æœ‰æ•ˆçš„ä¸­å›½Aè‚¡ä»£ç æ ¼å¼"

        try:
            # ä½¿ç”¨ç»Ÿä¸€æ•°æ®æºæ¥å£è·å–è‚¡ç¥¨æ•°æ®ï¼ˆé»˜è®¤Tushareï¼Œæ”¯æŒå¤‡ç”¨æ•°æ®æºï¼‰
            from core.dataflows.interface import get_china_stock_data_unified
            logger.debug(f"ğŸ“Š [DEBUG] æ­£åœ¨è·å– {ticker} çš„è‚¡ç¥¨æ•°æ®...")

            # è·å–æœ€è¿‘30å¤©çš„æ•°æ®ç”¨äºåŸºæœ¬é¢åˆ†æ
            from datetime import datetime, timedelta
            end_date = datetime.strptime(curr_date, '%Y-%m-%d')
            start_date = end_date - timedelta(days=30)

            stock_data = get_china_stock_data_unified(
                ticker,
                start_date.strftime('%Y-%m-%d'),
                end_date.strftime('%Y-%m-%d')
            )

            logger.debug(f"ğŸ“Š [DEBUG] è‚¡ç¥¨æ•°æ®è·å–å®Œæˆï¼Œé•¿åº¦: {len(stock_data) if stock_data else 0}")

            if not stock_data or "è·å–å¤±è´¥" in stock_data or "âŒ" in stock_data:
                return f"æ— æ³•è·å–è‚¡ç¥¨ {ticker} çš„åŸºæœ¬é¢æ•°æ®ï¼š{stock_data}"

            # è°ƒç”¨çœŸæ­£çš„åŸºæœ¬é¢åˆ†æ
            from core.dataflows.optimized_china_data import OptimizedChinaDataProvider

            # åˆ›å»ºåˆ†æå™¨å®ä¾‹
            analyzer = OptimizedChinaDataProvider()

            # ç”ŸæˆçœŸæ­£çš„åŸºæœ¬é¢åˆ†ææŠ¥å‘Š
            fundamentals_report = analyzer._generate_fundamentals_report(ticker, stock_data)

            logger.debug(f"ğŸ“Š [DEBUG] ä¸­å›½åŸºæœ¬é¢åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            logger.debug(f"ğŸ“Š [DEBUG] get_china_fundamentals ç»“æœé•¿åº¦: {len(fundamentals_report)}")

            return fundamentals_report

        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            logger.error(f"âŒ [DEBUG] get_china_fundamentals å¤±è´¥:")
            logger.error(f"âŒ [DEBUG] é”™è¯¯: {str(e)}")
            logger.error(f"âŒ [DEBUG] å †æ ˆ: {error_details}")
            return f"ä¸­å›½è‚¡ç¥¨åŸºæœ¬é¢åˆ†æå¤±è´¥: {str(e)}"

    @staticmethod
    # @tool  # å·²ç§»é™¤ï¼šè¯·ä½¿ç”¨ get_stock_fundamentals_unified æˆ– get_stock_market_data_unified
    def get_hk_stock_data_unified(
        symbol: Annotated[str, "æ¸¯è‚¡ä»£ç ï¼Œå¦‚ï¼š0700.HKã€9988.HKç­‰"],
        start_date: Annotated[str, "å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"],
        end_date: Annotated[str, "ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"]
    ) -> str:
        """
        è·å–æ¸¯è‚¡æ•°æ®çš„ç»Ÿä¸€æ¥å£ï¼Œä¼˜å…ˆä½¿ç”¨AKShareæ•°æ®æºï¼Œå¤‡ç”¨Yahoo Finance

        Args:
            symbol: æ¸¯è‚¡ä»£ç  (å¦‚: 0700.HK)
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)

        Returns:
            str: æ ¼å¼åŒ–çš„æ¸¯è‚¡æ•°æ®
        """
        logger.debug(f"ğŸ‡­ğŸ‡° [DEBUG] get_hk_stock_data_unified è¢«è°ƒç”¨: symbol={symbol}, start_date={start_date}, end_date={end_date}")

        try:
            from core.dataflows.interface import get_hk_stock_data_unified

            result = get_hk_stock_data_unified(symbol, start_date, end_date)

            logger.debug(f"ğŸ‡­ğŸ‡° [DEBUG] æ¸¯è‚¡æ•°æ®è·å–å®Œæˆï¼Œé•¿åº¦: {len(result) if result else 0}")

            return result

        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            logger.error(f"âŒ [DEBUG] get_hk_stock_data_unified å¤±è´¥:")
            logger.error(f"âŒ [DEBUG] é”™è¯¯: {str(e)}")
            logger.error(f"âŒ [DEBUG] å †æ ˆ: {error_details}")
            return f"æ¸¯è‚¡æ•°æ®è·å–å¤±è´¥: {str(e)}"

    @staticmethod
    @tool
    @log_tool_call(tool_name="get_stock_fundamentals_unified", log_args=True)
    def get_stock_fundamentals_unified(
        ticker: Annotated[str, "è‚¡ç¥¨ä»£ç ï¼ˆæ”¯æŒAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰"],
        start_date: Annotated[str, "å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"] = None,
        end_date: Annotated[str, "ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"] = None,
        curr_date: Annotated[str, "å½“å‰æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"] = None
    ) -> str:
        """
        ç»Ÿä¸€çš„è‚¡ç¥¨åŸºæœ¬é¢åˆ†æå·¥å…·
        è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹ï¼ˆAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰å¹¶è°ƒç”¨ç›¸åº”çš„æ•°æ®æº

        Args:
            ticker: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001ã€0700.HKã€AAPLï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼‰
            curr_date: å½“å‰æ—¥æœŸï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼‰

        Returns:
            str: åŸºæœ¬é¢åˆ†ææ•°æ®å’ŒæŠ¥å‘Š
        """
        logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] åˆ†æè‚¡ç¥¨: {ticker}")

        # æ·»åŠ è¯¦ç»†çš„è‚¡ç¥¨ä»£ç è¿½è¸ªæ—¥å¿—
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·æ¥æ”¶åˆ°çš„åŸå§‹è‚¡ç¥¨ä»£ç : '{ticker}' (ç±»å‹: {type(ticker)})")
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç é•¿åº¦: {len(str(ticker))}")
        logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è‚¡ç¥¨ä»£ç å­—ç¬¦: {list(str(ticker))}")

        # ä¿å­˜åŸå§‹tickerç”¨äºå¯¹æ¯”
        original_ticker = ticker

        try:
            from core.utils.stock_utils import StockUtils
            from datetime import datetime, timedelta

            # è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹
            market_info = StockUtils.get_market_info(ticker)
            is_china = market_info['is_china']
            is_hk = market_info['is_hk']
            is_us = market_info['is_us']

            logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] StockUtils.get_market_info è¿”å›çš„å¸‚åœºä¿¡æ¯: {market_info}")
            logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] è‚¡ç¥¨ç±»å‹: {market_info['market_name']}")
            logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] è´§å¸: {market_info['currency_name']} ({market_info['currency_symbol']})")

            # æ£€æŸ¥tickeræ˜¯å¦åœ¨å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿäº†å˜åŒ–
            if str(ticker) != str(original_ticker):
                logger.warning(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è­¦å‘Šï¼šè‚¡ç¥¨ä»£ç å‘ç”Ÿäº†å˜åŒ–ï¼åŸå§‹: '{original_ticker}' -> å½“å‰: '{ticker}'")

            # è®¾ç½®é»˜è®¤æ—¥æœŸ
            if not curr_date:
                curr_date = datetime.now().strftime('%Y-%m-%d')
            if not start_date:
                start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
            if not end_date:
                end_date = curr_date

            result_data = []

            if is_china:
                # ä¸­å›½Aè‚¡ï¼šè·å–è‚¡ç¥¨æ•°æ® + åŸºæœ¬é¢æ•°æ®
                logger.info(f"ğŸ‡¨ğŸ‡³ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] å¤„ç†Aè‚¡æ•°æ®...")
                logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è¿›å…¥Aè‚¡å¤„ç†åˆ†æ”¯ï¼Œticker: '{ticker}'")

                try:
                    # è·å–è‚¡ç¥¨ä»·æ ¼æ•°æ®
                    from core.dataflows.interface import get_china_stock_data_unified
                    logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è°ƒç”¨ get_china_stock_data_unifiedï¼Œä¼ å…¥å‚æ•°: ticker='{ticker}', start_date='{start_date}', end_date='{end_date}'")
                    stock_data = get_china_stock_data_unified(ticker, start_date, end_date)
                    logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] get_china_stock_data_unified è¿”å›ç»“æœå‰200å­—ç¬¦: {stock_data[:200] if stock_data else 'None'}")
                    result_data.append(f"## Aè‚¡ä»·æ ¼æ•°æ®\n{stock_data}")
                except Exception as e:
                    logger.error(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] get_china_stock_data_unified è°ƒç”¨å¤±è´¥: {e}")
                    result_data.append(f"## Aè‚¡ä»·æ ¼æ•°æ®\nè·å–å¤±è´¥: {e}")

                try:
                    # è·å–åŸºæœ¬é¢æ•°æ®
                    from core.dataflows.optimized_china_data import OptimizedChinaDataProvider
                    analyzer = OptimizedChinaDataProvider()
                    logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] è°ƒç”¨ OptimizedChinaDataProvider._generate_fundamentals_reportï¼Œä¼ å…¥å‚æ•°: ticker='{ticker}'")
                    fundamentals_data = analyzer._generate_fundamentals_report(ticker, stock_data if 'stock_data' in locals() else "")
                    logger.info(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] _generate_fundamentals_report è¿”å›ç»“æœå‰200å­—ç¬¦: {fundamentals_data[:200] if fundamentals_data else 'None'}")
                    result_data.append(f"## Aè‚¡åŸºæœ¬é¢æ•°æ®\n{fundamentals_data}")
                except Exception as e:
                    logger.error(f"ğŸ” [è‚¡ç¥¨ä»£ç è¿½è¸ª] _generate_fundamentals_report è°ƒç”¨å¤±è´¥: {e}")
                    result_data.append(f"## Aè‚¡åŸºæœ¬é¢æ•°æ®\nè·å–å¤±è´¥: {e}")

            elif is_hk:
                # æ¸¯è‚¡ï¼šä½¿ç”¨AKShareæ•°æ®æºï¼Œæ”¯æŒå¤šé‡å¤‡ç”¨æ–¹æ¡ˆ
                logger.info(f"ğŸ‡­ğŸ‡° [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] å¤„ç†æ¸¯è‚¡æ•°æ®...")

                hk_data_success = False

                # ä¸»è¦æ•°æ®æºï¼šAKShare
                try:
                    from core.dataflows.interface import get_hk_stock_data_unified
                    hk_data = get_hk_stock_data_unified(ticker, start_date, end_date)

                    # æ£€æŸ¥æ•°æ®è´¨é‡
                    if hk_data and len(hk_data) > 100 and "âŒ" not in hk_data:
                        result_data.append(f"## æ¸¯è‚¡æ•°æ®\n{hk_data}")
                        hk_data_success = True
                        logger.info(f"âœ… [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ¸¯è‚¡ä¸»è¦æ•°æ®æºæˆåŠŸ")
                    else:
                        logger.warning(f"âš ï¸ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ¸¯è‚¡ä¸»è¦æ•°æ®æºè´¨é‡ä¸ä½³")

                except Exception as e:
                    logger.error(f"âš ï¸ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ¸¯è‚¡ä¸»è¦æ•°æ®æºå¤±è´¥: {e}")

                # å¤‡ç”¨æ–¹æ¡ˆï¼šåŸºç¡€æ¸¯è‚¡ä¿¡æ¯
                if not hk_data_success:
                    try:
                        from core.dataflows.interface import get_hk_stock_info_unified
                        hk_info = get_hk_stock_info_unified(ticker)

                        basic_info = f"""## æ¸¯è‚¡åŸºç¡€ä¿¡æ¯

**è‚¡ç¥¨ä»£ç **: {ticker}
**è‚¡ç¥¨åç§°**: {hk_info.get('name', f'æ¸¯è‚¡{ticker}')}
**äº¤æ˜“è´§å¸**: æ¸¯å¸ (HK$)
**äº¤æ˜“æ‰€**: é¦™æ¸¯äº¤æ˜“æ‰€ (HKG)
**æ•°æ®æº**: {hk_info.get('source', 'åŸºç¡€ä¿¡æ¯')}

âš ï¸ æ³¨æ„ï¼šè¯¦ç»†çš„ä»·æ ¼å’Œè´¢åŠ¡æ•°æ®æš‚æ—¶æ— æ³•è·å–ï¼Œå»ºè®®ç¨åé‡è¯•æˆ–ä½¿ç”¨å…¶ä»–æ•°æ®æºã€‚

**åŸºæœ¬é¢åˆ†æå»ºè®®**ï¼š
- å»ºè®®æŸ¥çœ‹å…¬å¸æœ€æ–°è´¢æŠ¥
- å…³æ³¨æ¸¯è‚¡å¸‚åœºæ•´ä½“èµ°åŠ¿
- è€ƒè™‘æ±‡ç‡å› ç´ å¯¹æŠ•èµ„çš„å½±å“
"""
                        result_data.append(basic_info)
                        logger.info(f"âœ… [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ¸¯è‚¡å¤‡ç”¨ä¿¡æ¯æˆåŠŸ")

                    except Exception as e2:
                        # æœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆ
                        fallback_info = f"""## æ¸¯è‚¡ä¿¡æ¯ï¼ˆå¤‡ç”¨ï¼‰

**è‚¡ç¥¨ä»£ç **: {ticker}
**è‚¡ç¥¨ç±»å‹**: æ¸¯è‚¡
**äº¤æ˜“è´§å¸**: æ¸¯å¸ (HK$)
**äº¤æ˜“æ‰€**: é¦™æ¸¯äº¤æ˜“æ‰€ (HKG)

âŒ æ•°æ®è·å–é‡åˆ°é—®é¢˜: {str(e2)}

**å»ºè®®**ï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. ç¨åé‡è¯•åˆ†æ
3. ä½¿ç”¨å…¶ä»–æ¸¯è‚¡æ•°æ®æº
4. æŸ¥çœ‹å…¬å¸å®˜æ–¹è´¢æŠ¥
"""
                        result_data.append(fallback_info)
                        logger.warning(f"âš ï¸ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ¸¯è‚¡ä½¿ç”¨æœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆ")

            else:
                # ç¾è‚¡ï¼šä½¿ç”¨OpenAI/Finnhubæ•°æ®æº
                logger.info(f"ğŸ‡ºğŸ‡¸ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] å¤„ç†ç¾è‚¡æ•°æ®...")

                try:
                    from core.dataflows.interface import get_fundamentals_openai
                    us_data = get_fundamentals_openai(ticker, curr_date)
                    result_data.append(f"## ç¾è‚¡åŸºæœ¬é¢æ•°æ®\n{us_data}")
                except Exception as e:
                    result_data.append(f"## ç¾è‚¡åŸºæœ¬é¢æ•°æ®\nè·å–å¤±è´¥: {e}")

            # ç»„åˆæ‰€æœ‰æ•°æ®
            combined_result = f"""# {ticker} åŸºæœ¬é¢åˆ†ææ•°æ®

**è‚¡ç¥¨ç±»å‹**: {market_info['market_name']}
**è´§å¸**: {market_info['currency_name']} ({market_info['currency_symbol']})
**åˆ†ææ—¥æœŸ**: {curr_date}

{chr(10).join(result_data)}

---
*æ•°æ®æ¥æº: æ ¹æ®è‚¡ç¥¨ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ•°æ®æº*
"""

            logger.info(f"ğŸ“Š [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] æ•°æ®è·å–å®Œæˆï¼Œæ€»é•¿åº¦: {len(combined_result)}")
            return combined_result

        except Exception as e:
            error_msg = f"ç»Ÿä¸€åŸºæœ¬é¢åˆ†æå·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"âŒ [ç»Ÿä¸€åŸºæœ¬é¢å·¥å…·] {error_msg}")
            return error_msg

    @staticmethod
    @tool
    @log_tool_call(tool_name="get_stock_market_data_unified", log_args=True)
    def get_stock_market_data_unified(
        ticker: Annotated[str, "ä»£å¸ç¬¦å·ï¼ˆå¦‚BTCã€ETHç­‰ï¼‰"],
        start_date: Annotated[str, "å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"],
        end_date: Annotated[str, "ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"]
    ) -> str:
        """
        ç»Ÿä¸€çš„å¸‚åœºæ•°æ®å·¥å…· - æ”¯æŒåŠ å¯†è´§å¸
        è‡ªåŠ¨è¯†åˆ«èµ„äº§ç±»å‹å¹¶è°ƒç”¨ç›¸åº”çš„æ•°æ®æºè·å–ä»·æ ¼å’ŒæŠ€æœ¯æŒ‡æ ‡æ•°æ®

        Args:
            ticker: ä»£å¸ç¬¦å·ï¼ˆå¦‚ï¼šBTCã€ETHã€USDTï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰

        Returns:
            str: å¸‚åœºæ•°æ®å’ŒæŠ€æœ¯åˆ†ææŠ¥å‘Š
        """
        logger.info(f"ğŸ“ˆ [ç»Ÿä¸€å¸‚åœºå·¥å…·] åˆ†æ: {ticker}")

        try:
            from core.utils.stock_utils import StockUtils

            # è‡ªåŠ¨è¯†åˆ«èµ„äº§ç±»å‹
            market_info = StockUtils.get_market_info(ticker)
            
            logger.info(f"ğŸ“ˆ [ç»Ÿä¸€å¸‚åœºå·¥å…·] èµ„äº§ç±»å‹: {market_info['market_name']}")
            
            # å¦‚æœæ˜¯åŠ å¯†è´§å¸ï¼Œä½¿ç”¨åŠ å¯†è´§å¸API
            if market_info['is_crypto']:
                logger.info(f"ğŸª™ [ç»Ÿä¸€å¸‚åœºå·¥å…·] å¤„ç†åŠ å¯†è´§å¸æ•°æ®...")
                
                try:
                    from core.agents.tools import analyst_tools
                    
                    # è·å–ä»·æ ¼æ•°æ®
                    price_data = analyst_tools.get_crypto_price_data(ticker, days_back=30)
                    
                    if 'error' in price_data:
                        return f"åŠ å¯†è´§å¸æ•°æ®è·å–å¤±è´¥: {price_data['error']}"
                    
                    # è·å–æŠ€æœ¯æŒ‡æ ‡
                    indicators_data = analyst_tools.get_technical_indicators(ticker)
                    
                    # è¿”å›æ ¼å¼åŒ–çš„åŠ å¯†è´§å¸æ•°æ®
                    result = f"""# {ticker} å¸‚åœºæ•°æ®åˆ†æ

**ç±»å‹**: åŠ å¯†è´§å¸
**å½“å‰ä»·æ ¼**: ${price_data.get('latest_price', 0):.2f}
**ä»·æ ¼å˜åŒ–**: {price_data.get('price_change_pct', 0):.2f}%
**åˆ†ææœŸé—´**: {start_date} è‡³ {end_date}
**æ•°æ®è®°å½•**: {price_data.get('total_records', 0)}æ¡

## æŠ€æœ¯æŒ‡æ ‡
"""
                    
                    if 'error' not in indicators_data:
                        indicators = indicators_data.get('indicators', {})
                        
                        # RSI
                        rsi = indicators.get('rsi')
                        if rsi:
                            status = "è¶…ä¹°" if rsi > 70 else "è¶…å–" if rsi < 30 else "æ­£å¸¸"
                            result += f"- RSI (14): {rsi:.2f} ({status})\n"
                        
                        # ç§»åŠ¨å¹³å‡çº¿
                        sma_20 = indicators.get('sma_20')
                        sma_50 = indicators.get('sma_50')
                        if sma_20:
                            result += f"- SMA (20): ${sma_20:.2f}\n"
                        if sma_50:
                            result += f"- SMA (50): ${sma_50:.2f}\n"
                        
                        # MACD
                        macd = indicators.get('macd')
                        macd_signal = indicators.get('macd_signal')
                        if macd and macd_signal:
                            result += f"- MACD: {macd:.4f}\n"
                            result += f"- MACDä¿¡å·çº¿: {macd_signal:.4f}\n"
                        
                        # å¸ƒæ—å¸¦
                        bb_upper = indicators.get('bb_upper')
                        bb_lower = indicators.get('bb_lower')
                        if bb_upper and bb_lower:
                            result += f"- å¸ƒæ—å¸¦ä¸Šè½¨: ${bb_upper:.2f}\n"
                            result += f"- å¸ƒæ—å¸¦ä¸‹è½¨: ${bb_lower:.2f}\n"
                    else:
                        result += "æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥\n"
                    
                    result += "\n---\n*æ•°æ®æ¥æº: å®æ—¶åŠ å¯†è´§å¸API*"
                    
                    logger.info(f"âœ… [ç»Ÿä¸€å¸‚åœºå·¥å…·] åŠ å¯†è´§å¸æ•°æ®è·å–å®Œæˆ")
                    return result
                    
                except Exception as e:
                    error_msg = f"åŠ å¯†è´§å¸æ•°æ®è·å–å¤±è´¥: {str(e)}"
                    logger.error(f"âŒ [ç»Ÿä¸€å¸‚åœºå·¥å…·] {error_msg}")
                    return error_msg
            else:
                # éåŠ å¯†è´§å¸èµ„äº§æš‚ä¸æ”¯æŒ
                return f"æš‚ä¸æ”¯æŒéåŠ å¯†è´§å¸èµ„äº§: {ticker}"
                
        except Exception as e:
            error_msg = f"ç»Ÿä¸€å¸‚åœºæ•°æ®å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"âŒ [ç»Ÿä¸€å¸‚åœºå·¥å…·] {error_msg}")
            return error_msg

    @staticmethod
    @tool
    @log_tool_call(tool_name="get_stock_news_unified", log_args=True)
    def get_stock_news_unified(
        ticker: Annotated[str, "è‚¡ç¥¨ä»£ç ï¼ˆæ”¯æŒAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰"],
        curr_date: Annotated[str, "å½“å‰æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"],
    ) -> str:
        """
        ç»Ÿä¸€çš„è‚¡ç¥¨æ–°é—»å·¥å…·
        è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹ï¼ˆAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰å¹¶è°ƒç”¨ç›¸åº”çš„æ–°é—»æ•°æ®æº

        Args:
            ticker: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001ã€0700.HKã€AAPLï¼‰
            curr_date: å½“å‰æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰

        Returns:
            str: æ–°é—»åˆ†ææŠ¥å‘Š
        """
        logger.info(f"ğŸ“° [ç»Ÿä¸€æ–°é—»å·¥å…·] åˆ†æè‚¡ç¥¨: {ticker}")

        try:
            from core.utils.stock_utils import StockUtils
            from datetime import datetime, timedelta

            # è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹
            market_info = StockUtils.get_market_info(ticker)
            is_china = market_info['is_china']
            is_hk = market_info['is_hk']
            is_us = market_info['is_us']

            logger.info(f"ğŸ“° [ç»Ÿä¸€æ–°é—»å·¥å…·] è‚¡ç¥¨ç±»å‹: {market_info['market_name']}")

            # è®¡ç®—æ–°é—»æŸ¥è¯¢çš„æ—¥æœŸèŒƒå›´
            end_date = datetime.strptime(curr_date, '%Y-%m-%d')
            days_back = timeframe_to_days(Toolkit._current_timeframe)
            start_date = end_date - timedelta(days=days_back)
            start_date_str = start_date.strftime('%Y-%m-%d')

            result_data = []

            if is_china or is_hk:
                # ä¸­å›½Aè‚¡å’Œæ¸¯è‚¡ï¼šä½¿ç”¨AKShareä¸œæ–¹è´¢å¯Œæ–°é—»å’ŒGoogleæ–°é—»ï¼ˆä¸­æ–‡æœç´¢ï¼‰
                logger.info(f"ğŸ‡¨ğŸ‡³ğŸ‡­ğŸ‡° [ç»Ÿä¸€æ–°é—»å·¥å…·] å¤„ç†ä¸­æ–‡æ–°é—»...")

                # 1. å°è¯•è·å–AKShareä¸œæ–¹è´¢å¯Œæ–°é—»
                try:
                    # å¤„ç†è‚¡ç¥¨ä»£ç 
                    clean_ticker = ticker.replace('.SH', '').replace('.SZ', '').replace('.SS', '')\
                                   .replace('.HK', '').replace('.XSHE', '').replace('.XSHG', '')
                    
                    logger.info(f"ğŸ‡¨ğŸ‡³ğŸ‡­ğŸ‡° [ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»: {clean_ticker}")
                    
                    # å¯¼å…¥AKShareæ–°é—»è·å–å‡½æ•°
                    from core.dataflows.akshare_utils import get_stock_news_em
                    
                    # è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»
                    news_df = get_stock_news_em(clean_ticker)
                    
                    if not news_df.empty:
                        # æ ¼å¼åŒ–ä¸œæ–¹è´¢å¯Œæ–°é—»
                        em_news_items = []
                        for _, row in news_df.iterrows():
                            news_title = row.get('æ ‡é¢˜', '')
                            news_time = row.get('æ—¶é—´', '')
                            news_url = row.get('é“¾æ¥', '')
                            
                            news_item = f"- **{news_title}** [{news_time}]({news_url})"
                            em_news_items.append(news_item)
                        
                        # æ·»åŠ åˆ°ç»“æœä¸­
                        if em_news_items:
                            em_news_text = "\n".join(em_news_items)
                            result_data.append(f"## ä¸œæ–¹è´¢å¯Œæ–°é—»\n{em_news_text}")
                            logger.info(f"ğŸ‡¨ğŸ‡³ğŸ‡­ğŸ‡° [ç»Ÿä¸€æ–°é—»å·¥å…·] æˆåŠŸè·å–{len(em_news_items)}æ¡ä¸œæ–¹è´¢å¯Œæ–°é—»")
                except Exception as em_e:
                    logger.error(f"âŒ [ç»Ÿä¸€æ–°é—»å·¥å…·] ä¸œæ–¹è´¢å¯Œæ–°é—»è·å–å¤±è´¥: {em_e}")
                    result_data.append(f"## ä¸œæ–¹è´¢å¯Œæ–°é—»\nè·å–å¤±è´¥: {em_e}")

                # 2. è·å–Googleæ–°é—»ä½œä¸ºè¡¥å……
                try:
                    # è·å–å…¬å¸ä¸­æ–‡åç§°ç”¨äºæœç´¢
                    if is_china:
                        # Aè‚¡ä½¿ç”¨è‚¡ç¥¨ä»£ç æœç´¢ï¼Œæ·»åŠ æ›´å¤šä¸­æ–‡å…³é”®è¯
                        clean_ticker = ticker.replace('.SH', '').replace('.SZ', '').replace('.SS', '')\
                                       .replace('.XSHE', '').replace('.XSHG', '')
                        search_query = f"{clean_ticker} è‚¡ç¥¨ å…¬å¸ è´¢æŠ¥ æ–°é—»"
                        logger.info(f"ğŸ‡¨ğŸ‡³ [ç»Ÿä¸€æ–°é—»å·¥å…·] Aè‚¡Googleæ–°é—»æœç´¢å…³é”®è¯: {search_query}")
                    else:
                        # æ¸¯è‚¡ä½¿ç”¨ä»£ç æœç´¢
                        search_query = f"{ticker} æ¸¯è‚¡"
                        logger.info(f"ğŸ‡­ğŸ‡° [ç»Ÿä¸€æ–°é—»å·¥å…·] æ¸¯è‚¡Googleæ–°é—»æœç´¢å…³é”®è¯: {search_query}")

                    from core.dataflows.interface import get_google_news
                    news_data = get_google_news(search_query, curr_date)
                    result_data.append(f"## Googleæ–°é—»\n{news_data}")
                    logger.info(f"ğŸ‡¨ğŸ‡³ğŸ‡­ğŸ‡° [ç»Ÿä¸€æ–°é—»å·¥å…·] æˆåŠŸè·å–Googleæ–°é—»")
                except Exception as google_e:
                    logger.error(f"âŒ [ç»Ÿä¸€æ–°é—»å·¥å…·] Googleæ–°é—»è·å–å¤±è´¥: {google_e}")
                    result_data.append(f"## Googleæ–°é—»\nè·å–å¤±è´¥: {google_e}")

            else:
                # ç¾è‚¡ï¼šä½¿ç”¨Finnhubæ–°é—»
                logger.info(f"ğŸ‡ºğŸ‡¸ [ç»Ÿä¸€æ–°é—»å·¥å…·] å¤„ç†ç¾è‚¡æ–°é—»...")

                try:
                    from core.dataflows.interface import get_finnhub_news
                    news_data = get_finnhub_news(ticker, start_date_str, curr_date)
                    result_data.append(f"## ç¾è‚¡æ–°é—»\n{news_data}")
                except Exception as e:
                    result_data.append(f"## ç¾è‚¡æ–°é—»\nè·å–å¤±è´¥: {e}")

            # ç»„åˆæ‰€æœ‰æ•°æ®
            combined_result = f"""# {ticker} æ–°é—»åˆ†æ

**è‚¡ç¥¨ç±»å‹**: {market_info['market_name']}
**åˆ†ææ—¥æœŸ**: {curr_date}
**æ–°é—»æ—¶é—´èŒƒå›´**: {start_date_str} è‡³ {curr_date}

{chr(10).join(result_data)}

---
*æ•°æ®æ¥æº: æ ¹æ®è‚¡ç¥¨ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ–°é—»æº*
"""

            logger.info(f"ğŸ“° [ç»Ÿä¸€æ–°é—»å·¥å…·] æ•°æ®è·å–å®Œæˆï¼Œæ€»é•¿åº¦: {len(combined_result)}")
            return combined_result

        except Exception as e:
            error_msg = f"ç»Ÿä¸€æ–°é—»å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"âŒ [ç»Ÿä¸€æ–°é—»å·¥å…·] {error_msg}")
            return error_msg

    @staticmethod
    @tool
    @log_tool_call(tool_name="get_stock_sentiment_unified", log_args=True)
    def get_stock_sentiment_unified(
        ticker: Annotated[str, "è‚¡ç¥¨ä»£ç ï¼ˆæ”¯æŒAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰"],
        curr_date: Annotated[str, "å½“å‰æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD"]
    ) -> str:
        """
        ç»Ÿä¸€çš„è‚¡ç¥¨æƒ…ç»ªåˆ†æå·¥å…·
        è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹ï¼ˆAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰å¹¶è°ƒç”¨ç›¸åº”çš„æƒ…ç»ªæ•°æ®æº

        Args:
            ticker: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001ã€0700.HKã€AAPLï¼‰
            curr_date: å½“å‰æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰

        Returns:
            str: æƒ…ç»ªåˆ†ææŠ¥å‘Š
        """
        logger.info(f"ğŸ˜Š [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] åˆ†æè‚¡ç¥¨: {ticker}")

        try:
            from core.utils.stock_utils import StockUtils

            # è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹
            market_info = StockUtils.get_market_info(ticker)
            is_china = market_info['is_china']
            is_hk = market_info['is_hk']
            is_us = market_info['is_us']

            logger.info(f"ğŸ˜Š [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] è‚¡ç¥¨ç±»å‹: {market_info['market_name']}")

            result_data = []

            if is_china or is_hk:
                # ä¸­å›½Aè‚¡å’Œæ¸¯è‚¡ï¼šä½¿ç”¨ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æ
                logger.info(f"ğŸ‡¨ğŸ‡³ğŸ‡­ğŸ‡° [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] å¤„ç†ä¸­æ–‡å¸‚åœºæƒ…ç»ª...")

                try:
                    # å¯ä»¥é›†æˆå¾®åšã€é›ªçƒã€ä¸œæ–¹è´¢å¯Œç­‰ä¸­æ–‡ç¤¾äº¤åª’ä½“æƒ…ç»ª
                    # ç›®å‰ä½¿ç”¨åŸºç¡€çš„æƒ…ç»ªåˆ†æ
                    sentiment_summary = f"""
## ä¸­æ–‡å¸‚åœºæƒ…ç»ªåˆ†æ

**è‚¡ç¥¨**: {ticker} ({market_info['market_name']})
**åˆ†ææ—¥æœŸ**: {curr_date}

### å¸‚åœºæƒ…ç»ªæ¦‚å†µ
- ç”±äºä¸­æ–‡ç¤¾äº¤åª’ä½“æƒ…ç»ªæ•°æ®æºæš‚æœªå®Œå…¨é›†æˆï¼Œå½“å‰æä¾›åŸºç¡€åˆ†æ
- å»ºè®®å…³æ³¨é›ªçƒã€ä¸œæ–¹è´¢å¯Œã€åŒèŠ±é¡ºç­‰å¹³å°çš„è®¨è®ºçƒ­åº¦
- æ¸¯è‚¡å¸‚åœºè¿˜éœ€å…³æ³¨é¦™æ¸¯æœ¬åœ°è´¢ç»åª’ä½“æƒ…ç»ª

### æƒ…ç»ªæŒ‡æ ‡
- æ•´ä½“æƒ…ç»ª: ä¸­æ€§
- è®¨è®ºçƒ­åº¦: å¾…åˆ†æ
- æŠ•èµ„è€…ä¿¡å¿ƒ: å¾…è¯„ä¼°

*æ³¨ï¼šå®Œæ•´çš„ä¸­æ–‡ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­*
"""
                    result_data.append(sentiment_summary)
                except Exception as e:
                    result_data.append(f"## ä¸­æ–‡å¸‚åœºæƒ…ç»ª\nè·å–å¤±è´¥: {e}")

            else:
                # ç¾è‚¡ï¼šä½¿ç”¨Redditæƒ…ç»ªåˆ†æ
                logger.info(f"ğŸ‡ºğŸ‡¸ [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] å¤„ç†ç¾è‚¡æƒ…ç»ª...")

                try:
                    from core.dataflows.interface import get_reddit_sentiment

                    sentiment_data = get_reddit_sentiment(ticker, curr_date)
                    result_data.append(f"## ç¾è‚¡Redditæƒ…ç»ª\n{sentiment_data}")
                except Exception as e:
                    result_data.append(f"## ç¾è‚¡Redditæƒ…ç»ª\nè·å–å¤±è´¥: {e}")

            # ç»„åˆæ‰€æœ‰æ•°æ®
            combined_result = f"""# {ticker} æƒ…ç»ªåˆ†æ

**è‚¡ç¥¨ç±»å‹**: {market_info['market_name']}
**åˆ†ææ—¥æœŸ**: {curr_date}

{chr(10).join(result_data)}

---
*æ•°æ®æ¥æº: æ ¹æ®è‚¡ç¥¨ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æƒ…ç»ªæ•°æ®æº*
"""

            logger.info(f"ğŸ˜Š [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] æ•°æ®è·å–å®Œæˆï¼Œæ€»é•¿åº¦: {len(combined_result)}")
            return combined_result

        except Exception as e:
            error_msg = f"ç»Ÿä¸€æƒ…ç»ªåˆ†æå·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"âŒ [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] {error_msg}")
            return error_msg
