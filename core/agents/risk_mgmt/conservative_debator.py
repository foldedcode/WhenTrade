from langchain_core.messages import AIMessage
import time
import json

# å¯¼å…¥ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
from core.utils.logging_init import get_logger
logger = get_logger("default")

# å¯¼å…¥æç¤ºè¯åŠ è½½å™¨
from core.agents.prompt_loader import get_prompt_loader

# å¯¼å…¥æ¶ˆæ¯å¤„ç†å·¥å…· (Linus: use clean data structures)
from core.agents.utils.message_utils import (
    add_debate_turn,
    get_relevant_context,
    format_context_for_prompt,
    clean_content
)

# å¯¼å…¥è½®æ¬¡æ„ŸçŸ¥å·¥å…·
from core.agents.utils.debate_utils import (
    is_first_round_analysis,
    get_analysis_context_for_prompt
)


def get_latest_response(full_response):
    """æå–æœ€æ–°çš„æ ¸å¿ƒè§‚ç‚¹ï¼Œè·³è¿‡å¤è¿°éƒ¨åˆ†"""
    if not full_response:
        return ""
    
    # æŒ‰æ®µè½åˆ†å‰²
    paragraphs = full_response.split('\n')
    
    # è¿‡æ»¤æ‰å¤è¿°æ€§çš„æ®µè½ï¼ˆåŒ…å«è¿™äº›å…³é”®è¯çš„æ®µè½å¯èƒ½æ˜¯åœ¨å¤è¿°ä»–äººè§‚ç‚¹ï¼‰
    restatement_keywords = [
        "ä½ è¯´", "æ‚¨è¯´", "ä»–è¯´", "æåˆ°", "è®¤ä¸º", "è§‰å¾—",
        "æŒ‡å‡º", "è¡¨ç¤º", "å¼ºè°ƒ", "åˆšæ‰", "ä¹‹å‰",
        "ä½ çš„è§‚ç‚¹", "æ‚¨çš„è§‚ç‚¹", "ä»–çš„è§‚ç‚¹"
    ]
    
    # æ‰¾åˆ°æ ¸å¿ƒè§‚ç‚¹æ®µè½ï¼ˆä»åå¾€å‰æ‰¾ï¼Œè·³è¿‡å¤è¿°ï¼‰
    core_paragraphs = []
    for p in reversed(paragraphs):
        p_clean = p.strip()
        if not p_clean:
            continue
            
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¤è¿°æ®µè½
        is_restatement = any(keyword in p_clean[:50] for keyword in restatement_keywords)
        
        if not is_restatement:
            core_paragraphs.append(p_clean)
            if len('\n'.join(core_paragraphs)) > 300:  # æ”¶é›†è¶³å¤Ÿçš„æ ¸å¿ƒå†…å®¹
                break
    
    # åè½¬é¡ºåºï¼ˆå› ä¸ºæ˜¯ä»åå¾€å‰æ”¶é›†çš„ï¼‰
    core_paragraphs.reverse()
    
    # ç»„åˆå¹¶æˆªå–
    result = '\n'.join(core_paragraphs)
    return result[:500] if len(result) > 500 else result


def create_safe_debator(llm):
    def safe_node(state) -> dict:
        risk_debate_state = state["risk_debate_state"]
        debate_turns = risk_debate_state.get("debate_turns", [])
        
        # Get relevant context using the new structure (Linus: eliminate special cases)
        relevant_context = format_context_for_prompt(
            debate_turns, 
            "safe",
            max_context=3  # Only last 3 turns
        )

        market_research_report = state["market_report"]
        sentiment_report = state["sentiment_report"]
        news_report = state["news_report"]

        trader_decision = state.get("investment_plan", "")
        
        # ä½¿ç”¨è½®æ¬¡æ„ŸçŸ¥åŠŸèƒ½ç”Ÿæˆä¸Šä¸‹æ–‡
        analysis_context = get_analysis_context_for_prompt(
            debate_turns, 
            "safe",  # conservative åœ¨ç³»ç»Ÿä¸­æ˜¯ safe
            relevant_context
        )
        
        # è·å–å…¶ä»–åˆ†æå¸ˆçš„è§‚ç‚¹å†…å®¹
        risky_response = ""
        neutral_response = ""
        
        if analysis_context["analysis_mode"] != "independent":
            # ä»debate_turnsä¸­æå–riskyå’Œneutralçš„è§‚ç‚¹
            for turn in debate_turns:
                if turn.get("speaker") == "risky":
                    risky_response = turn.get("content", "")[:200] + "..."
                elif turn.get("speaker") == "neutral":
                    neutral_response = turn.get("content", "")[:200] + "..."

        # ä½¿ç”¨æç¤ºè¯åŠ è½½å™¨è·å–é…ç½®
        prompt_loader = get_prompt_loader()
        # è·å–è¯­è¨€å‚æ•°ï¼ˆä»stateä¸­æå–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤ä¸­æ–‡ï¼‰
        language = state.get("language", "zh-CN")
        
        prompt_config = prompt_loader.load_prompt("conservative_debator", language=language)
        
        # è·å–ç³»ç»Ÿæ¶ˆæ¯æ¨¡æ¿
        system_message_template = prompt_config.get("system_message", "æ‚¨æ˜¯ä¿å®ˆé£é™©åˆ†æå¸ˆã€‚")
        
        # æ ¼å¼åŒ–ç³»ç»Ÿæ¶ˆæ¯ï¼ˆæ›¿æ¢å ä½ç¬¦ï¼‰
        prompt = system_message_template.format(
            trader_decision=trader_decision,
            market_research_report=market_research_report,
            sentiment_report=sentiment_report,
            news_report=news_report,
            history=relevant_context,  # ä¿æŒå…¼å®¹æ€§
            current_risky_response=risky_response,  # æ ¹æ®è½®æ¬¡åŠ¨æ€è®¾ç½®
            current_neutral_response=neutral_response  # æ ¹æ®è½®æ¬¡åŠ¨æ€è®¾ç½®
        )
        
        # è®°å½•æç¤ºè¯ç‰ˆæœ¬
        prompt_version = prompt_loader.get_prompt_version("conservative_debator")
        logger.debug(f"ğŸš« [ä¿å®ˆé£é™©åˆ†æå¸ˆ] ä½¿ç”¨æç¤ºè¯ç‰ˆæœ¬: {prompt_version}")
        
        # ğŸ”´ è¯­è¨€å¼ºåˆ¶å‰ç¼€ - ç¡®ä¿LLMä¸¥æ ¼éµå¾ªé€‰å®šè¯­è¨€
        language = state.get("language", "zh-CN")
        language_name = "English" if language == "en-US" else "ç®€ä½“ä¸­æ–‡"
        language_prefix = f"[ğŸ”´ CRITICAL: Respond ONLY in {language_name}. No mixed languages. This overrides ALL other instructions.] "
        
        logger.info(f"ğŸŒ [conservative_debator] è¯­è¨€è®¾ç½®: {language} -> {language_name}")
        logger.debug(f"ğŸ”´ [conservative_debator] è¯­è¨€å‰ç¼€: {language_prefix}")
        
        # åœ¨promptå‰æ·»åŠ è¯­è¨€å¼ºåˆ¶å‰ç¼€
        enhanced_prompt = language_prefix + prompt
        logger.info(f"âœ… [conservative_debator] å·²æ·»åŠ è¯­è¨€å‰ç¼€åˆ°prompt")
        
        response = llm.invoke(enhanced_prompt)

        # æ£€æŸ¥è§’è‰²æ··æ·†
        argument = response.content
        if "æ¿€è¿›" in argument[:100] or "é«˜é£é™©é«˜å›æŠ¥" in argument[:100] or "ç§¯ææ‹¥æŠ±" in argument[:100]:
            logger.warning("âš ï¸ ä¿å®ˆåˆ†æå¸ˆè§’è‰²æ··æ·†ï¼Œé‡æ–°ç”Ÿæˆ...")
            # å¦‚æœæ£€æµ‹åˆ°è§’è‰²æ··æ·†ï¼Œä½¿ç”¨é»˜è®¤å›åº”
            argument = "æˆ‘è®¤ä¸ºæˆ‘ä»¬åº”è¯¥æ›´åŠ è°¨æ…ã€‚å¸‚åœºæ³¢åŠ¨æ€§å¤§ï¼ŒæŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤ºçŸ­æœŸå¯èƒ½é¢ä¸´å›è°ƒå‹åŠ›ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¿æŠ¤èµ„äº§æ¯”è¿½æ±‚é«˜å›æŠ¥æ›´é‡è¦ã€‚å»ºè®®ç­‰å¾…æ›´æ˜ç¡®çš„ä¹°å…¥ä¿¡å·ã€‚"
        
        # Clean the content
        argument = clean_content(argument)
        
        # Add to debate turns using the new structure (Linus: single source of truth)
        updated_turns = add_debate_turn(
            debate_turns,
            speaker="safe",
            content=argument
        )
        
        new_risk_debate_state = {
            "debate_turns": updated_turns,  # Single source of truth
            "latest_speaker": "Safe",
            "count": risk_debate_state["count"] + 1,
            "judge_decision": risk_debate_state.get("judge_decision", ""),
            # Deprecated fields - kept for compatibility
            "history": "",  # No longer accumulate
            "risky_history": "",  # No longer accumulate
            "safe_history": "",  # No longer accumulate
            "neutral_history": "",  # No longer accumulate
            "current_safe_response": argument,  # Keep for compatibility
            "current_risky_response": risk_debate_state.get("current_risky_response", ""),
            "current_neutral_response": risk_debate_state.get("current_neutral_response", "")
        }

        # Create clean AIMessage for message chain continuity
        clean_message = AIMessage(content=response.content)

        return {
            "messages": [clean_message],
            "risk_debate_state": new_risk_debate_state
        }

    return safe_node
