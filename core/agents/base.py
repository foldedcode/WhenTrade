"""
Êô∫ËÉΩÂàÜÊûê‰ª£ÁêÜÂÆûÁé∞
"""

from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional, Literal
from datetime import datetime
import json
import asyncio
import logging
from enum import Enum

logger = logging.getLogger(__name__)


class ThoughtType(str, Enum):
    """Thought type enumeration"""
    OBSERVATION = "observation"
    ANALYSIS = "analysis"
    CONCLUSION = "conclusion"
    QUESTION = "question"


class AgentThought:
    """Agent thought record"""
    
    def __init__(
        self,
        agent_id: str,
        domain: str,
        thought_type: ThoughtType,
        content: str,
        confidence: float = 0.5,
        evidence: List[Dict[str, Any]] = None
    ):
        self.agent_id = agent_id
        self.domain = domain
        self.timestamp = datetime.utcnow().timestamp()
        self.thought_type = thought_type
        self.content = content
        self.confidence = confidence
        self.evidence = evidence or []
        
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary format"""
        return {
            "agentId": self.agent_id,
            "domain": self.domain,
            "timestamp": self.timestamp,
            "thoughtType": self.thought_type.value,
            "content": self.content,
            "confidence": self.confidence,
            "evidence": self.evidence
        }


class BaseAnalyst(ABC):
    """Base analyst class"""
    
    def __init__(self, llm: Any, name: str = None, domain: str = None):
        self.llm = llm
        self.name = name or self.__class__.__name__
        self.domain = domain or self._get_default_domain()
        self.analysis_cache = {}
        self.confidence_factors = {}
        self.thought_stream: List[AgentThought] = []
        self.stop_event = None  # Add stop event support
        
        # Inject tool adapter
        try:
            from core.agents.tools import analyst_tools
            self.tools = analyst_tools
        except ImportError as e:
            import logging
            logging.warning(f"‚ö†Ô∏è Failed to import tool adapter: {e}")
            self.tools = None
        
    @abstractmethod
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = 3) -> Dict[str, Any]:
        """Execute analysis"""
        pass
        
    @abstractmethod
    def get_expertise_areas(self) -> List[str]:
        """Get expertise areas"""
        pass
        
    @abstractmethod
    def _get_default_domain(self) -> str:
        """Get default analysis domain"""
        pass
        
    def record_thought(
        self,
        thought_type: ThoughtType,
        content: str,
        confidence: float = 0.5,
        evidence: List[Dict[str, Any]] = None
    ) -> AgentThought:
        """Record thinking process"""
        thought = AgentThought(
            agent_id=self.name,
            domain=self.domain,
            thought_type=thought_type,
            content=content,
            confidence=confidence,
            evidence=evidence
        )
        self.thought_stream.append(thought)
        logger.debug(f"{self.name} {thought_type.value}: {content}")
        return thought
        
    def get_thought_stream(self) -> List[Dict[str, Any]]:
        """Get thought stream"""
        return [thought.to_dict() for thought in self.thought_stream]
        
    def clear_thoughts(self):
        """Clear thought records"""
        self.thought_stream = []
        
    def check_stop_signal(self) -> bool:
        """Check stop signal
        
        Returns:
            bool: Returns True if stop signal received
        """
        if self.stop_event and self.stop_event.is_set():
            logger.info(f"Agent {self.name} received stop signal, interrupting execution")
            return True
        return False
        
    def set_stop_event(self, stop_event):
        """Set stop event - propagate to APIExecutor"""
        self.stop_event = stop_event
        
        # Propagate to tool set's APIExecutor
        if hasattr(self, 'toolkit') and self.toolkit:
            # Get global APIExecutor instance
            from core.services.tools.api_executor import get_api_executor
            api_executor = get_api_executor()
            api_executor.set_stop_event(stop_event)
            logger.debug(f"üõë [{self.name}] Stop event propagated to APIExecutor")
        
    async def debate(self, topic: str, other_opinions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Debate with other analysts"""
        prompt = f"""
        As {self.name}, I need to express my opinion on the following topic and respond to other analysts:
        
        Topic: {topic}
        
        Other analysts' opinions:
        {json.dumps(other_opinions, ensure_ascii=False, indent=2)}
        
        Based on my professional domain and analytical methods, please provide:
        1. My core viewpoint
        2. Evaluation of other viewpoints
        3. Evidence supporting my viewpoint
        4. Potential risks or uncertainties
        
        Return in JSON format.
        """
        
        response = await self.llm.generate(prompt)
        return {
            "analyst": self.name,
            "debate_response": response,
            "timestamp": datetime.utcnow().isoformat()
        }
        
    def calculate_confidence(self, factors: Dict[str, float]) -> float:
        """Calculate confidence score"""
        # Calculate weighted confidence based on multiple factors
        weights = {
            "data_quality": 0.3,
            "data_recency": 0.2,
            "analysis_depth": 0.2,
            "market_conditions": 0.3
        }
        
        confidence = 0.0
        for factor, value in factors.items():
            weight = weights.get(factor, 0.1)
            confidence += weight * value
            
        return min(max(confidence, 0.0), 1.0)


class BaseCryptoAnalyst(BaseAnalyst):
    """Base crypto analyst class - eliminate code duplication, configuration-driven"""
    
    def __init__(self, llm: Any, config: Dict[str, Any]):
        """
        Initialize crypto analyst
        
        Args:
            llm: Language model instance
            config: Analyst configuration (loaded from YAML)
        """
        super().__init__(
            llm, 
            config.get("name", self.__class__.__name__),
            config.get("domain", "Cryptocurrency Analysis")
        )
        self.config = config
        
        # Load professional settings from configuration
        self.expertise_areas = config.get("expertise_areas", [])
        self.analysis_depth = config.get("analysis_depth", 3)
        self.tool_config = config.get("tools", {})
        
        logger.debug(f"Initializing crypto analyst: {self.name}")
    
    def get_expertise_areas(self) -> List[str]:
        """Get expertise areas"""
        return self.expertise_areas
    
    def _get_default_domain(self) -> str:
        """Get default analysis domain"""
        return "Cryptocurrency Analysis"
    
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = None) -> Dict[str, Any]:
        """
        Execute cryptocurrency analysis - unified process, configuration-driven
        
        Args:
            target: Analysis target (cryptocurrency symbol)
            data: Input data
            depth: Analysis depth
        
        Returns:
            Analysis result
        """
        # Check stop signal
        if self.check_stop_signal():
            return {"cancelled": True, "analyst_type": "crypto", "message": "Analysis cancelled by user"}
            
        analysis_depth = depth or self.analysis_depth
        self.clear_thoughts()
        
        # Record analysis start
        self.record_thought(
            ThoughtType.OBSERVATION,
            f"Starting {self.name} analysis for {target}, depth level: {analysis_depth}",
            confidence=0.9
        )
        
        # Tool execution phase
        tool_results = {}
        if self.tools and self.tool_config.get("enabled", True):
            # Check stop signalÔºàÂ∑•ÂÖ∑ÊâßË°åÂâçÔºâ
            if self.check_stop_signal():
                return {"cancelled": True, "analyst_type": "crypto", "message": "Analysis cancelled before tool execution"}
            tool_results = await self._execute_tools(target, data)
        
        # Check stop signalÔºàÂàÜÊûêÈò∂ÊÆµÂâçÔºâ
        if self.check_stop_signal():
            return {"cancelled": True, "analyst_type": "crypto", "message": "Analysis cancelled before LLM analysis"}
        
        # ÂàÜÊûêÈò∂ÊÆµ - ‰ΩøÁî®ÈÖçÁΩÆÁöÑÊèêÁ§∫ËØçÊ®°Êùø
        analysis_result = await self._perform_analysis(target, data, tool_results, analysis_depth)
        
        # ËÆ°ÁÆóÁΩÆ‰ø°Â∫¶
        confidence = self._calculate_analysis_confidence(tool_results, analysis_depth)
        
        # ËÆ∞ÂΩïÁªìËÆ∫
        self.record_thought(
            ThoughtType.CONCLUSION,
            f"{self.name} analysis completed, confidence: {confidence:.2f}",
            confidence=confidence
        )
        
        return {
            "analyst_type": self.config.get("type", "crypto"),
            "analysis": analysis_result,
            "confidence_score": confidence,
            "timestamp": datetime.utcnow().isoformat(),
            "thought_stream": self.get_thought_stream(),
            "tool_results": tool_results
        }
    
    async def _execute_tools(self, target: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """Execute tools to get data - subclasses can override to customize tool execution"""
        tool_results = {}
        
        # Âü∫Á°Ä‰ª∑Ê†ºÊï∞ÊçÆ
        if hasattr(self.tools, 'get_crypto_price_data'):
            try:
                price_data = self.tools.get_crypto_price_data(target, days_back=30)
                if 'error' not in price_data:
                    tool_results['price_data'] = price_data
                    self.record_thought(
                        ThoughtType.OBSERVATION,
                        f"Successfully retrieved price data for {target}",
                        confidence=0.8
                    )
            except Exception as e:
                logger.warning(f"Failed to retrieve price data: {e}")
        
        return tool_results
    
    async def _perform_analysis(self, target: str, data: Dict[str, Any], tool_results: Dict[str, Any], depth: int) -> str:
        """
        Execute specific analysis - using configured prompts
        Subclasses can override to implement specific analysis logic
        """
        # ‰ΩøÁî®ÊèêÁ§∫ËØçÂä†ËΩΩÂô®Ëé∑ÂèñÈÖçÁΩÆ
        from core.agents.prompt_loader import get_prompt_loader
        
        # Ëé∑ÂèñËØ≠Ë®ÄÂèÇÊï∞Ôºà‰ªédata‰∏≠ÊèêÂèñÔºåÂ¶ÇÊûúÊ≤°ÊúâÂàô‰ΩøÁî®ÈªòËÆ§‰∏≠ÊñáÔºâ
        language = data.get("language", "zh-CN")
        
        prompt_loader = get_prompt_loader()
        analyst_type = self.config.get("prompt_type", "market")
        prompt_config = prompt_loader.load_prompt(analyst_type, language=language)
        
        # ÊûÑÂª∫ÂàÜÊûêÊèêÁ§∫ËØç
        analysis_prompt = self._build_analysis_prompt(
            target, data, tool_results, depth, prompt_config
        )
        
        # ÊâßË°åLLMÂàÜÊûê
        response = await self.llm.generate(analysis_prompt)
        
        self.record_thought(
            ThoughtType.ANALYSIS,
            f"Completed {analyst_type} analysis",
            confidence=0.7
        )
        
        return response
    
    def _build_analysis_prompt(self, target: str, data: Dict[str, Any], 
                              tool_results: Dict[str, Any], depth: int,
                              prompt_config: Dict[str, Any]) -> str:
        """Build analysis prompt - unified template"""
        
        system_message = prompt_config.get("system_message", f"You are a professional {self.name}")
        
        # Ê†ºÂºèÂåñÂü∫Á°Ä‰ø°ÊÅØ
        base_prompt = f"""
{system_message}

Analysis Target: {target}
Analysis Depth: {depth}/5
Current Date: {datetime.utcnow().strftime('%Y-%m-%d')}

"""
        
        # Ê∑ªÂä†Â∑•ÂÖ∑Êï∞ÊçÆ
        if tool_results:
            base_prompt += "Retrieved Data:\n"
            for tool_name, result in tool_results.items():
                base_prompt += f"{tool_name}: {json.dumps(result, ensure_ascii=False, indent=2)}\n\n"
        
        # Ê∑ªÂä†ÂàÜÊûêË¶ÅÊ±Ç
        focus_areas = self.config.get("analysis_focus", [])
        if focus_areas:
            base_prompt += f"Key Analysis Areas: {', '.join(focus_areas)}\n\n"
        
        base_prompt += """
Please conduct professional analysis based on the above data, including:
1. Key indicator interpretation
2. Trend analysis
3. Risk assessment
4. Investment recommendations

Return analysis results in structured format.
"""
        
        return base_prompt
    
    def _calculate_analysis_confidence(self, tool_results: Dict[str, Any], depth: int) -> float:
        """Calculate analysis confidence"""
        factors = {
            "data_quality": 0.8 if tool_results else 0.5,
            "data_recency": 0.8,  # Assume data is recent
            "analysis_depth": depth / 5,
            "market_conditions": 0.7
        }
        
        return self.calculate_confidence(factors)


class TechnicalAnalyst(BaseAnalyst):
    """Technical Analyst"""
    
    def __init__(self, llm: Any):
        super().__init__(llm, "Technical Analyst")
        
    def get_expertise_areas(self) -> List[str]:
        return ["price_patterns", "technical_indicators", "trend_analysis", "support_resistance"]
        
    def _get_default_domain(self) -> str:
        return "Technical Analysis"
        
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = 3) -> Dict[str, Any]:
        """Execute technical analysis"""
        # Check stop signal
        if self.check_stop_signal():
            return {"cancelled": True, "analyst_type": "technical", "message": "Analysis cancelled by user"}
            
        # Ê∏ÖÁ©∫‰πãÂâçÁöÑÊÄùËÄÉËÆ∞ÂΩï
        self.clear_thoughts()
        
        # ‰ΩøÁî®Â∑•ÂÖ∑Ëé∑ÂèñÂÆûÊó∂‰ª∑Ê†ºÊï∞ÊçÆ
        real_time_data = {}
        technical_indicators = {}
        
        if self.tools:
            self.record_thought(
                ThoughtType.OBSERVATION,
                f"Retrieving real-time price data and technical indicators for {target}...",
                confidence=0.9
            )
            
            # Ëé∑ÂèñÂÆûÊó∂‰ª∑Ê†ºÊï∞ÊçÆ
            price_result = self.tools.get_crypto_price_data(target, days_back=30)
            
            # Check stop signal
            if self.check_stop_signal():
                return {"cancelled": True, "analyst_type": "technical", "message": "Analysis cancelled during price data retrieval"}
            
            if 'error' not in price_result:
                real_time_data = price_result
                latest_price = price_result.get('latest_price')
                price_change_pct = price_result.get('price_change_pct')
                
                self.record_thought(
                    ThoughtType.OBSERVATION,
                    f"Retrieved real-time data for {target}: Current price ${latest_price:.2f}, " +
                    f"Change {price_change_pct:.2f}% ({price_result.get('total_records')} records)",
                    confidence=0.95
                )
            
            # Check stop signal
            if self.check_stop_signal():
                return {"cancelled": True, "analyst_type": "technical", "message": "Analysis cancelled before retrieving technical indicators"}
            
            # Ëé∑ÂèñÊäÄÊúØÊåáÊ†á
            indicators_result = self.tools.get_technical_indicators(
                target, 
                indicators=['sma', 'rsi', 'macd', 'bb'],
                period_days=30
            )
            if 'error' not in indicators_result:
                technical_indicators = indicators_result.get('indicators', {})
                
                # ÂàÜÊûêRSI‰ø°Âè∑
                rsi = technical_indicators.get('rsi')
                if rsi:
                    if rsi > 70:
                        self.record_thought(
                            ThoughtType.ANALYSIS,
                            f"RSI indicator at {rsi:.1f}, showing overbought condition, may face pullback pressure",
                            confidence=0.8
                        )
                    elif rsi < 30:
                        self.record_thought(
                            ThoughtType.ANALYSIS,
                            f"RSI indicator at {rsi:.1f}, showing oversold condition, may see bounce opportunity",
                            confidence=0.8
                        )
        
        # ‰ΩøÁî®‰º†ÂÖ•ÁöÑÊï∞ÊçÆ‰Ωú‰∏∫ÂêéÂ§á
        price_data = real_time_data if real_time_data else data.get("price_data", {})
        
        # ËÆ∞ÂΩïËßÇÂØü
        latest_price = price_data.get('latest_price') or price_data.get('current_price', 0)
        price_change = price_data.get('price_change_pct') or price_data.get('change_24h', 0)
        
        self.record_thought(
            ThoughtType.OBSERVATION,
            f"Starting technical analysis of {target}. Current price: ${latest_price}, " +
            f"Change: {price_change}%",
            confidence=0.9
        )
        
        # ËÆ∞ÂΩïÂàùÊ≠•ÂàÜÊûê
        if price_data.get('change_24h', 0) > 5:
            self.record_thought(
                ThoughtType.ANALYSIS,
                "Strong uptrend detected, 24-hour gain exceeds 5%, need to analyze if this is sustainable growth",
                confidence=0.7
            )
        elif price_data.get('change_24h', 0) < -5:
            self.record_thought(
                ThoughtType.ANALYSIS,
                "Significant downtrend detected, 24-hour decline exceeds 5%, need to assess support level strength",
                confidence=0.7
            )
        
        # ÊûÑÂª∫ÂåÖÂê´ÂÆûÊó∂Êï∞ÊçÆÁöÑÂàÜÊûêÊèêÁ§∫
        indicators_text = ""
        if technical_indicators:
            indicators_text = "\nTechnical Indicators:"
            for indicator, value in technical_indicators.items():
                if isinstance(value, dict):
                    for sub_key, sub_value in value.items():
                        indicators_text += f"\n- {sub_key}: {sub_value}"
                else:
                    indicators_text += f"\n- {indicator}: {value}"
        
        analysis_prompt = f"""
        Conduct in-depth technical analysis for {target} (Depth Level: {depth}/5):
        
        Real-time Price Data:
        - Current Price: ${price_data.get('latest_price') or price_data.get('current_price', 0)}
        - Price Change: {price_data.get('price_change_pct') or price_data.get('change_24h', 0)}%
        - Price Change Amount: ${price_data.get('price_change', 0)}
        - Data Records: {price_data.get('total_records', 'N/A')}
        - Analysis Period: {price_data.get('start_date', 'N/A')} to {price_data.get('end_date', 'N/A')}
        {indicators_text}
        
        Please analyze based on the above real-time data:
        1. Price trends (short-term, medium-term, long-term)
        2. Key support and resistance levels
        3. Technical indicator signal interpretation
        4. Risk assessment
        5. Trading recommendations
        
        Special Notes:
        - RSI > 70 indicates overbought, < 30 indicates oversold
        - MACD signal line crossovers indicate trend changes
        - Bollinger Bands position indicates price pressure/support
        
        Return in JSON format, including:
        - analysis: Detailed analysis content
        - summary: Brief summary
        - rating: Rating (bullish/neutral/bearish)
        - confidence_score: Confidence level (0-1)
        - key_findings: List of key findings
        - recommendations: List of specific recommendations
        """
        
        # ËÆ∞ÂΩïÂàÜÊûêËøáÁ®ã
        self.record_thought(
            ThoughtType.ANALYSIS,
            "Conducting comprehensive analysis of price trends, technical indicators, and volume data...",
            confidence=0.8
        )
        
        # Check stop signalÔºàLLMË∞ÉÁî®ÂâçÔºâ
        if self.check_stop_signal():
            return {"cancelled": True, "analyst_type": "technical", "message": "Analysis cancelled before LLM call"}
        
        response = await self.llm.generate(analysis_prompt)
        
        # ËÆ°ÁÆóÁΩÆ‰ø°Â∫¶
        confidence_factors = {
            "data_quality": 0.8 if price_data else 0.2,
            "data_recency": 0.9,  # Assume data is latest
            "analysis_depth": depth / 5,
            "market_conditions": 0.7
        }
        
        final_confidence = self.calculate_confidence(confidence_factors)
        
        # ËÆ∞ÂΩïÁªìËÆ∫
        self.record_thought(
            ThoughtType.CONCLUSION,
            f"Technical analysis completed, overall confidence: {final_confidence:.2f}",
            confidence=final_confidence
        )
        
        result = {
            "analyst_type": "technical",
            "analysis": response,
            "confidence_score": final_confidence,
            "timestamp": datetime.utcnow().isoformat(),
            "thought_stream": self.get_thought_stream()
        }
        
        return result


class FundamentalAnalyst(BaseAnalyst):
    """Fundamental Analyst"""
    
    def __init__(self, llm: Any):
        super().__init__(llm, "Fundamental Analyst")
        
    def get_expertise_areas(self) -> List[str]:
        return ["financial_metrics", "business_model", "competitive_position", "growth_potential"]
        
    def _get_default_domain(self) -> str:
        return "Fundamental Analysis"
        
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = 3) -> Dict[str, Any]:
        """Execute fundamental analysis"""
        fundamentals = data.get("fundamentals", {})
        market_type = data.get("market_type", "stock")
        
        # Ê∏ÖÁ©∫‰πãÂâçÁöÑÊÄùËÄÉËÆ∞ÂΩï
        self.clear_thoughts()
        
        # ËÆ∞ÂΩïÂàùÂßãËßÇÂØü
        self.record_thought(
            ThoughtType.OBSERVATION,
            f"Starting fundamental analysis for {target}, market type: {market_type}",
            confidence=0.9
        )
        
        if market_type == "stock":
            # ÂàÜÊûêË¥¢Âä°Êï∞ÊçÆ
            if fundamentals:
                pe_ratio = fundamentals.get("pe_ratio", 0)
                revenue_growth = fundamentals.get("revenue_growth", 0)
                
                if pe_ratio > 0 and pe_ratio < 20:
                    self.record_thought(
                        ThoughtType.ANALYSIS,
                        f"P/E ratio of {pe_ratio} is in reasonable valuation range",
                        confidence=0.8,
                        evidence=[{"type": "valuation", "value": pe_ratio}]
                    )
                elif pe_ratio >= 20:
                    self.record_thought(
                        ThoughtType.ANALYSIS,
                        f"High P/E ratio of {pe_ratio}, need to check if supported by high growth",
                        confidence=0.7,
                        evidence=[{"type": "valuation", "value": pe_ratio}]
                    )
                
                if revenue_growth > 15:
                    self.record_thought(
                        ThoughtType.ANALYSIS,
                        f"Revenue growth rate of {revenue_growth}% shows good growth potential",
                        confidence=0.8,
                        evidence=[{"type": "growth", "value": revenue_growth}]
                    )
            
            analysis_prompt = f"""
            Conduct fundamental analysis for {target} (Depth Level: {depth}/5):
            
            Fundamental Data:
            {json.dumps(fundamentals, ensure_ascii=False, indent=2)}
            
            Please analyze:
            1. Financial health status
            2. Profitability and growth trends
            3. Valuation levels
            4. Industry position and competitive advantages
            5. Management quality
            
            Return analysis results in JSON format.
            """
        else:
            # Âä†ÂØÜË¥ßÂ∏ÅÁöÑÂü∫Êú¨Èù¢ÂàÜÊûê
            self.record_thought(
                ThoughtType.ANALYSIS,
                "Cryptocurrency fundamental analysis will focus on technical innovation, team strength, and ecosystem development",
                confidence=0.8
            )
            
            analysis_prompt = f"""
            Conduct fundamental analysis for {target} (Depth Level: {depth}/5):
            
            Please analyze:
            1. Project technology and innovation
            2. Team background and execution capability
            3. Token economic model
            4. Market adoption and ecosystem development
            5. Competitive landscape
            
            Return analysis results in JSON format.
            """
        
        self.record_thought(
            ThoughtType.ANALYSIS,
            "Conducting comprehensive analysis of financial data, business model, and competitive advantages...",
            confidence=0.85
        )
            
        response = await self.llm.generate(analysis_prompt)
        
        # ËÆ°ÁÆóÁΩÆ‰ø°Â∫¶
        confidence_factors = {
            "data_quality": 0.9 if fundamentals else 0.3,
            "data_recency": 0.8,
            "analysis_depth": depth / 5,
            "market_conditions": 0.6
        }
        
        final_confidence = self.calculate_confidence(confidence_factors)
        
        # ËÆ∞ÂΩïÁªìËÆ∫
        self.record_thought(
            ThoughtType.CONCLUSION,
            f"Fundamental analysis completed, overall confidence: {final_confidence:.2f}",
            confidence=final_confidence
        )
        
        return {
            "analyst_type": "fundamental",
            "analysis": response,
            "confidence_score": final_confidence,
            "timestamp": datetime.utcnow().isoformat(),
            "thought_stream": self.get_thought_stream()
        }


class SentimentAnalyst(BaseAnalyst):
    """Sentiment Analyst"""
    
    def __init__(self, llm: Any):
        super().__init__(llm, "Sentiment Analyst")
        
    def get_expertise_areas(self) -> List[str]:
        return ["social_sentiment", "news_analysis", "market_psychology", "trend_momentum"]
        
    def _get_default_domain(self) -> str:
        return "Sentiment Analysis"
        
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = 3) -> Dict[str, Any]:
        """ÊâßË°åÊÉÖÁª™ÂàÜÊûê"""
        # Ê∏ÖÁ©∫‰πãÂâçÁöÑÊÄùËÄÉËÆ∞ÂΩï
        self.clear_thoughts()
        
        # ‰ΩøÁî®Â∑•ÂÖ∑Ëé∑ÂèñÂÆûÊó∂Êñ∞ÈóªÂíåÊÉÖÁª™Êï∞ÊçÆ
        real_time_news = []
        sentiment_data = {}
        
        if self.tools:
            self.record_thought(
                ThoughtType.OBSERVATION,
                f"Ê≠£Âú®Ëé∑Âèñ{target}ÁöÑÂÆûÊó∂Êñ∞ÈóªÂíåÂ∏ÇÂú∫ÊÉÖÁª™Êï∞ÊçÆ...",
                confidence=0.9
            )
            
            # Ëé∑ÂèñÂÆûÊó∂Êñ∞Èóª
            news_result = self.tools.get_crypto_news(target, days_back=7, max_results=15)
            if 'error' not in news_result:
                real_time_news = news_result.get('articles', [])
                news_count = news_result.get('news_count', 0)
                
                self.record_thought(
                    ThoughtType.OBSERVATION,
                    f"Ëé∑ÂèñÂà∞{news_count}Êù°{target}Áõ∏ÂÖ≥Êñ∞ÈóªÔºàËøáÂéª7Â§©Ôºâ",
                    confidence=0.95
                )
                
                # ÂàÜÊûêÊñ∞ÈóªÊ†áÈ¢òÊÉÖÊÑüÂÄæÂêëÔºàÁÆÄÂçïÂêØÂèëÂºèÔºâ
                positive_keywords = ['rise', 'surge', 'bull', 'gain', 'up', 'positive', 'growth', 'Ê∂®', '‰∏äÊ∂®', 'ÁúãÊ∂®']
                negative_keywords = ['fall', 'drop', 'bear', 'loss', 'down', 'negative', 'crash', 'Ë∑å', '‰∏ãË∑å', 'ÁúãË∑å']
                
                positive_count = 0
                negative_count = 0
                
                for article in real_time_news[:10]:
                    headline = article.get('headline', '').lower()
                    if any(keyword in headline for keyword in positive_keywords):
                        positive_count += 1
                    elif any(keyword in headline for keyword in negative_keywords):
                        negative_count += 1
                
                if positive_count > negative_count:
                    self.record_thought(
                        ThoughtType.ANALYSIS,
                        f"Êñ∞ÈóªÊÉÖÁª™ÂÅèÂêëÁßØÊûÅÔºö{positive_count}Ê≠£Èù¢ vs {negative_count}Ë¥üÈù¢ÔºåÂ∏ÇÂú∫È¢ÑÊúü‰πêËßÇ",
                        confidence=0.75
                    )
                elif negative_count > positive_count:
                    self.record_thought(
                        ThoughtType.ANALYSIS,
                        f"Êñ∞ÈóªÊÉÖÁª™ÂÅèÂêëÊ∂àÊûÅÔºö{negative_count}Ë¥üÈù¢ vs {positive_count}Ê≠£Èù¢ÔºåÂ∏ÇÂú∫ÊÉÖÁª™Ë∞®ÊÖé",
                        confidence=0.75
                    )
                else:
                    self.record_thought(
                        ThoughtType.ANALYSIS,
                        f"Êñ∞ÈóªÊÉÖÁª™‰∏≠ÊÄßÔºö{positive_count}Ê≠£Èù¢ vs {negative_count}Ë¥üÈù¢ÔºåËßÇÊúõÊÉÖÁª™ÊµìÂéö",
                        confidence=0.7
                    )
            
            # Ëé∑ÂèñÁªºÂêàÊÉÖÁª™ÂàÜÊûê
            sentiment_result = self.tools.get_sentiment_analysis(target, days_back=7)
            if 'error' not in sentiment_result:
                sentiment_data = sentiment_result
                
                total_articles = sentiment_result.get('summary', {}).get('total_news_articles', 0)
                self.record_thought(
                    ThoughtType.OBSERVATION,
                    f"ÁªºÂêàÊÉÖÁª™ÂàÜÊûêÊ∂µÁõñ{total_articles}ÁØáÊñáÁ´†ÔºåÊï∞ÊçÆÊù•Ê∫êÔºöFinnHub„ÄÅRedditÁ≠â",
                    confidence=0.8
                )
        
        # ‰ΩøÁî®ÂÆûÊó∂Êï∞ÊçÆÔºå‰º†ÂÖ•Êï∞ÊçÆ‰Ωú‰∏∫ÂêéÂ§á
        news = real_time_news if real_time_news else data.get("news", [])
        sentiment = sentiment_data if sentiment_data else data.get("sentiment", {})
        
        # ËÆ∞ÂΩïÊúÄÁªàÊï∞ÊçÆÁªüËÆ°
        self.record_thought(
            ThoughtType.OBSERVATION,
            f"ÊÉÖÁª™ÂàÜÊûêÊï∞ÊçÆÔºö{len(news)}Êù°Êñ∞ÈóªÔºåÊÉÖÁª™Êï∞ÊçÆ{'Â∑≤Ëé∑Âèñ' if sentiment else 'Áº∫Â§±'}",
            confidence=0.9
        )
        
        # ÂàÜÊûêÊñ∞ÈóªÊÉÖÁª™
        if news:
            positive_count = sum(1 for n in news[:10] if n.get("sentiment", 0) > 0.5)
            negative_count = sum(1 for n in news[:10] if n.get("sentiment", 0) < -0.5)
            
            if positive_count > negative_count:
                self.record_thought(
                    ThoughtType.ANALYSIS,
                    f"ËøëÊúüÊñ∞ÈóªÂÅèÂêëÁßØÊûÅÔºà{positive_count}Ê≠£Èù¢ vs {negative_count}Ë¥üÈù¢ÔºâÔºåÂ∏ÇÂú∫ÊÉÖÁª™‰πêËßÇ",
                    confidence=0.7,
                    evidence=[{"positive_news": positive_count, "negative_news": negative_count}]
                )
            elif negative_count > positive_count:
                self.record_thought(
                    ThoughtType.ANALYSIS,
                    f"ËøëÊúüÊñ∞ÈóªÂÅèÂêëÊ∂àÊûÅÔºà{negative_count}Ë¥üÈù¢ vs {positive_count}Ê≠£Èù¢ÔºâÔºåÂ∏ÇÂú∫ÊÉÖÁª™Ë∞®ÊÖé",
                    confidence=0.7,
                    evidence=[{"positive_news": positive_count, "negative_news": negative_count}]
                )
        
        # ÂàÜÊûêÁ§æ‰∫§Â™í‰ΩìÊÉÖÁª™
        if sentiment.get("twitter_mentions", 0) > 1000:
            self.record_thought(
                ThoughtType.ANALYSIS,
                f"Á§æ‰∫§Â™í‰ΩìËÆ®ËÆ∫ÁÉ≠Â∫¶È´òÔºà{sentiment.get('twitter_mentions', 0)}Ê¨°ÊèêÂèäÔºâÔºåÂÖ≥Ê≥®Â∫¶‰∏äÂçá",
                confidence=0.8
            )
        
        # Ê†ºÂºèÂåñÂÆûÊó∂Êñ∞ÈóªÊï∞ÊçÆ
        news_summary = ""
        if news:
            news_summary = f"ÂÆûÊó∂Êñ∞ÈóªÊ†áÈ¢òÔºàÊúÄËøë{len(news)}Êù°ÔºâÔºö\n"
            for i, article in enumerate(news[:5], 1):  # Âè™ÊòæÁ§∫Ââç5Êù°ÈÅøÂÖçÂ§™Èïø
                news_summary += f"{i}. {article.get('headline', 'No headline')}\n"
                news_summary += f"   Êù•Ê∫ê: {article.get('source', 'Unknown')} | Êó∂Èó¥: {article.get('datetime', 'N/A')}\n"
        
        analysis_prompt = f"""
        ÂØπ{target}ËøõË°åÂ∏ÇÂú∫ÊÉÖÁª™ÂàÜÊûêÔºàÊ∑±Â∫¶Á∫ßÂà´Ôºö{depth}/5ÔºâÔºö
        
        {news_summary}
        
        ÊÉÖÁª™Êï∞ÊçÆÁªüËÆ°Ôºö
        - Êñ∞ÈóªÊñáÁ´†Êï∞Èáè: {len(news)}Êù°
        - Êï∞ÊçÆÊù•Ê∫ê: FinnHub„ÄÅRedditÁ≠âÂ§öÂπ≥Âè∞
        - ÂàÜÊûêÊó∂Èó¥ËåÉÂõ¥: ËøáÂéª7Â§©
        
        ÁªºÂêàÊÉÖÁª™ÂàÜÊûêÁªìÊûúÔºö
        {json.dumps(sentiment, ensure_ascii=False, indent=2) if sentiment else "ÊöÇÊó†ÁªºÂêàÊÉÖÁª™Êï∞ÊçÆ"}
        
        ËØ∑Âü∫‰∫é‰ª•‰∏äÂÆûÊó∂Êï∞ÊçÆËøõË°åÊ∑±Â∫¶ÊÉÖÁª™ÂàÜÊûêÔºö
        1. Êï¥‰ΩìÂ∏ÇÂú∫ÊÉÖÁª™Ë∂ãÂäøÔºàÁßØÊûÅ/‰∏≠ÊÄß/Ê∂àÊûÅÔºâ
        2. Êñ∞ÈóªÂ™í‰ΩìÊä•ÈÅìÂÄæÂêëÂàÜÊûê
        3. Â∏ÇÂú∫ÂÖ≥Ê≥®Â∫¶ÂíåËÆ®ËÆ∫ÁÉ≠Â∫¶
        4. ÊΩúÂú®ÁöÑÊÉÖÁª™ËΩ¨Êäò‰ø°Âè∑
        5. ‰∏ªË¶ÅÊÉÖÁª™È©±Âä®Âõ†Á¥†ËØÜÂà´
        6. ÂØπ‰ª∑Ê†ºËµ∞ÂäøÁöÑÊÉÖÁª™ÂΩ±ÂìçÈ¢ÑÊµã
        
        ‰ª•JSONÊ†ºÂºèËøîÂõûÂàÜÊûêÁªìÊûúÔºåÂåÖÂê´Ôºö
        - analysis: ËØ¶ÁªÜÂàÜÊûêÂÜÖÂÆπ
        - summary: ÁÆÄÁü≠ÊÄªÁªì
        - sentiment_score: ÊÉÖÁª™ËØÑÂàÜ(-1Âà∞1Ôºå-1ÊúÄÊ∂àÊûÅÔºå1ÊúÄÁßØÊûÅ)
        - confidence_score: ÁΩÆ‰ø°Â∫¶Ôºà0-1Ôºâ
        - key_findings: ÂÖ≥ÈîÆÂèëÁé∞ÂàóË°®
        - recommendations: Âü∫‰∫éÊÉÖÁª™ÁöÑÊìç‰ΩúÂª∫ËÆÆ
        """
        
        self.record_thought(
            ThoughtType.ANALYSIS,
            "Ê≠£Âú®ÁªºÂêàÂàÜÊûêÊñ∞ÈóªÊÉÖÊÑü„ÄÅÁ§æ‰∫§Â™í‰ΩìÁÉ≠Â∫¶ÂíåÂ∏ÇÂú∫ÂøÉÁêÜ...",
            confidence=0.8
        )
        
        response = await self.llm.generate(analysis_prompt)
        
        # ËÆ°ÁÆóÁΩÆ‰ø°Â∫¶
        confidence_factors = {
            "data_quality": min(1.0, len(news) / 20),
            "data_recency": 0.9,
            "analysis_depth": depth / 5,
            "market_conditions": 0.7
        }
        
        final_confidence = self.calculate_confidence(confidence_factors)
        
        # ËÆ∞ÂΩïÁªìËÆ∫
        self.record_thought(
            ThoughtType.CONCLUSION,
            f"ÊÉÖÁª™ÂàÜÊûêÂÆåÊàêÔºåÁªºÂêàÁΩÆ‰ø°Â∫¶Ôºö{final_confidence:.2f}",
            confidence=final_confidence
        )
        
        return {
            "analyst_type": "sentiment",
            "analysis": response,
            "confidence_score": final_confidence,
            "timestamp": datetime.utcnow().isoformat(),
            "thought_stream": self.get_thought_stream()
        }


class RiskAnalyst(BaseAnalyst):
    """È£éÈô©ÂàÜÊûêÂ∏à"""
    
    def __init__(self, llm: Any):
        super().__init__(llm, "È£éÈô©ÂàÜÊûêÂ∏à")
        
    def get_expertise_areas(self) -> List[str]:
        return ["risk_assessment", "volatility_analysis", "downside_protection", "portfolio_impact"]
        
    def _get_default_domain(self) -> str:
        return "È£éÈô©ÁÆ°ÁêÜ"
        
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = 3) -> Dict[str, Any]:
        """ÊâßË°åÈ£éÈô©ÂàÜÊûê"""
        price_data = data.get("price_data", {})
        
        # Ê∏ÖÁ©∫‰πãÂâçÁöÑÊÄùËÄÉËÆ∞ÂΩï
        self.clear_thoughts()
        
        # ËÆ∞ÂΩïÂàùÂßãËßÇÂØü
        self.record_thought(
            ThoughtType.OBSERVATION,
            f"ÂºÄÂßãÂØπ{target}ËøõË°åÈ£éÈô©ËØÑ‰º∞ÔºåÈáçÁÇπÂÖ≥Ê≥®Ê≥¢Âä®ÊÄßÂíå‰∏ãË°åÈ£éÈô©",
            confidence=0.9
        )
        
        # ÂàÜÊûêÊ≥¢Âä®ÊÄß
        volatility = price_data.get('volatility_daily', 0)
        if volatility > 5:
            self.record_thought(
                ThoughtType.ANALYSIS,
                f"Êó•Ê≥¢Âä®ÁéáÈ´òËææ{volatility}%ÔºåÂ±û‰∫éÈ´òÈ£éÈô©ËµÑ‰∫ß",
                confidence=0.9,
                evidence=[{"type": "volatility", "value": volatility}]
            )
        elif volatility > 2:
            self.record_thought(
                ThoughtType.ANALYSIS,
                f"Êó•Ê≥¢Âä®Áéá‰∏∫{volatility}%ÔºåÈ£éÈô©ÈÄÇ‰∏≠",
                confidence=0.8,
                evidence=[{"type": "volatility", "value": volatility}]
            )
        
        # ÂàÜÊûê‰ª∑Ê†º‰ΩçÁΩÆ
        current_price = price_data.get('current_price', 0)
        high_52w = price_data.get('high_52w', 0)
        low_52w = price_data.get('low_52w', 0)
        
        if high_52w > 0 and current_price > 0:
            price_position = (current_price - low_52w) / (high_52w - low_52w) * 100
            if price_position > 80:
                self.record_thought(
                    ThoughtType.ANALYSIS,
                    f"ÂΩìÂâç‰ª∑Ê†ºÊé•Ëøë52Âë®È´òÁÇπÔºà{price_position:.1f}%‰ΩçÁΩÆÔºâÔºåÈúÄË≠¶ÊÉïÂõûË∞ÉÈ£éÈô©",
                    confidence=0.8
                )
            elif price_position < 20:
                self.record_thought(
                    ThoughtType.ANALYSIS,
                    f"ÂΩìÂâç‰ª∑Ê†ºÊé•Ëøë52Âë®‰ΩéÁÇπÔºà{price_position:.1f}%‰ΩçÁΩÆÔºâÔºåÂèØËÉΩÂ≠òÂú®ÂèçÂºπÊú∫‰ºö",
                    confidence=0.7
                )
        
        analysis_prompt = f"""
        ÂØπ{target}ËøõË°åÈ£éÈô©ÂàÜÊûêÔºàÊ∑±Â∫¶Á∫ßÂà´Ôºö{depth}/5ÔºâÔºö
        
        ‰ª∑Ê†ºÊ≥¢Âä®Êï∞ÊçÆÔºö
        - ÂΩìÂâç‰ª∑Ê†ºÔºö${price_data.get('current_price', 0)}
        - 52Âë®ÊúÄÈ´òÔºö${price_data.get('high_52w', 0)}
        - 52Âë®ÊúÄ‰ΩéÔºö${price_data.get('low_52w', 0)}
        - Êó•Ê≥¢Âä®ÁéáÔºö{price_data.get('volatility_daily', 0)}%
        
        ËØ∑ÂàÜÊûêÔºö
        1. ‰∏ªË¶ÅÈ£éÈô©Âõ†Á¥†
        2. Ê≥¢Âä®ÊÄßËØÑ‰º∞
        3. ‰∏ãË°åÈ£éÈô©
        4. È£éÈô©ÁºìËß£Á≠ñÁï•
        5. È£éÈô©Êî∂ÁõäÊØî
        
        ‰ª•JSONÊ†ºÂºèËøîÂõûÂàÜÊûêÁªìÊûú„ÄÇ
        """
        
        self.record_thought(
            ThoughtType.ANALYSIS,
            "Ê≠£Âú®ÁªºÂêàËØÑ‰º∞Â∏ÇÂú∫È£éÈô©„ÄÅ‰∏™ËÇ°È£éÈô©ÂíåÁ≥ªÁªüÊÄßÈ£éÈô©...",
            confidence=0.85
        )
        
        response = await self.llm.generate(analysis_prompt)
        
        # ËÆ°ÁÆóÁΩÆ‰ø°Â∫¶
        confidence_factors = {
            "data_quality": 0.8 if price_data else 0.2,
            "data_recency": 0.9,
            "analysis_depth": depth / 5,
            "market_conditions": 0.5  # È£éÈô©ÂàÜÊûêÂú®‰∏çÁ°ÆÂÆöÂ∏ÇÂú∫‰∏≠Êõ¥ÈáçË¶Å
        }
        
        final_confidence = self.calculate_confidence(confidence_factors)
        
        # ËÆ∞ÂΩïÁªìËÆ∫
        self.record_thought(
            ThoughtType.CONCLUSION,
            f"È£éÈô©ÂàÜÊûêÂÆåÊàêÔºåÁªºÂêàÁΩÆ‰ø°Â∫¶Ôºö{final_confidence:.2f}",
            confidence=final_confidence
        )
        
        return {
            "analyst_type": "risk",
            "analysis": response,
            "confidence_score": final_confidence,
            "timestamp": datetime.utcnow().isoformat(),
            "thought_stream": self.get_thought_stream()
        }


class MarketAnalyst(BaseAnalyst):
    """Â∏ÇÂú∫ÂàÜÊûêÂ∏à"""
    
    def __init__(self, llm: Any):
        super().__init__(llm, "Â∏ÇÂú∫ÂàÜÊûêÂ∏à")
        
    def get_expertise_areas(self) -> List[str]:
        return ["macro_trends", "sector_analysis", "market_cycles", "cross_asset_correlation"]
        
    def _get_default_domain(self) -> str:
        return "Â∏ÇÂú∫ÂàÜÊûê"
        
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = 3) -> Dict[str, Any]:
        """ÊâßË°åÂ∏ÇÂú∫ÂàÜÊûê"""
        # Ê∏ÖÁ©∫‰πãÂâçÁöÑÊÄùËÄÉËÆ∞ÂΩï
        self.clear_thoughts()
        
        # ‰ΩøÁî®Â∑•ÂÖ∑Ëé∑ÂèñÂ∏ÇÂú∫Êï∞ÊçÆÂíåÊñ∞Èóª
        market_context = {}
        if self.tools:
            self.record_thought(
                ThoughtType.OBSERVATION,
                f"Ê≠£Âú®Ëé∑Âèñ{target}ÁöÑÂ∏ÇÂú∫Êï∞ÊçÆÂíåÁõ∏ÂÖ≥Êñ∞Èóª...",
                confidence=0.9
            )
            
            # Ëé∑Âèñ‰ª∑Ê†ºÊï∞ÊçÆ‰Ωú‰∏∫Â∏ÇÂú∫ËÉåÊôØ
            price_result = self.tools.get_crypto_price_data(target, days_back=30)
            if 'error' not in price_result:
                market_context['price_data'] = price_result
                
                self.record_thought(
                    ThoughtType.OBSERVATION,
                    f"Ëé∑Âèñ{target}Â∏ÇÂú∫Êï∞ÊçÆÔºöÂΩìÂâç‰ª∑Ê†º${price_result.get('latest_price', 0):.2f}Ôºå" +
                    f"30Â§©ÂèòÂåñ{price_result.get('price_change_pct', 0):.2f}%",
                    confidence=0.9
                )
        
        # ËÆ∞ÂΩïÂàùÂßãËßÇÂØü
        self.record_thought(
            ThoughtType.OBSERVATION,
            f"ÂºÄÂßãÂØπ{target}ËøõË°åÂÆèËßÇÂ∏ÇÂú∫ÂàÜÊûêÔºåËØÑ‰º∞Êï¥‰ΩìÂ∏ÇÂú∫ÁéØÂ¢ÉÂíåË°å‰∏öË∂ãÂäø",
            confidence=0.9
        )
        
        # ÂàÜÊûêÂ∏ÇÂú∫Êï∞ÊçÆ
        market_data = data.get("market_data", {})
        if market_data:
            market_trend = market_data.get("trend", "unknown")
            if market_trend == "bullish":
                self.record_thought(
                    ThoughtType.ANALYSIS,
                    "Êï¥‰ΩìÂ∏ÇÂú∫Ë∂ãÂäøÂêëÂ•ΩÔºåÊúâÂà©‰∫éÈ£éÈô©ËµÑ‰∫ßË°®Áé∞",
                    confidence=0.8
                )
            elif market_trend == "bearish":
                self.record_thought(
                    ThoughtType.ANALYSIS,
                    "Â∏ÇÂú∫Â§Ñ‰∫é‰∏ãË°åË∂ãÂäøÔºåÈúÄË¶ÅË∞®ÊÖéËØÑ‰º∞È£éÈô©",
                    confidence=0.8
                )
        
        # Ê£ÄÊü•ÊòØÂê¶ÊúâË°å‰∏öÊï∞ÊçÆ
        sector_data = data.get("sector_data", {})
        if sector_data:
            self.record_thought(
                ThoughtType.ANALYSIS,
                "Ê≠£Âú®ÂàÜÊûêË°å‰∏öË°®Áé∞ÂíåÊùøÂùóËΩÆÂä®ÊÉÖÂÜµ...",
                confidence=0.7
            )
        
        # ÊèêÂá∫ÂÖ≥ÈîÆÈóÆÈ¢ò
        self.record_thought(
            ThoughtType.QUESTION,
            "ÂΩìÂâçÂ∏ÇÂú∫Âë®ÊúüÂ§Ñ‰∫é‰ªÄ‰πàÈò∂ÊÆµÔºüÊîøÁ≠ñÈù¢ÊòØÂê¶ÊúâÈáçÂ§ßÂèòÂåñÔºü",
            confidence=0.6
        )
        
        analysis_prompt = f"""
        ÂØπ{target}ËøõË°åÂÆèËßÇÂ∏ÇÂú∫ÂàÜÊûêÔºàÊ∑±Â∫¶Á∫ßÂà´Ôºö{depth}/5ÔºâÔºö
        
        Â∏ÇÂú∫Êï∞ÊçÆÔºö
        {json.dumps(market_data, ensure_ascii=False, indent=2) if market_data else "Êó†"}
        
        Ë°å‰∏öÊï∞ÊçÆÔºö
        {json.dumps(sector_data, ensure_ascii=False, indent=2) if sector_data else "Êó†"}
        
        ËØ∑ÂàÜÊûêÔºö
        1. ÂÆèËßÇÁªèÊµéÁéØÂ¢É
        2. Ë°å‰∏ö/ÊùøÂùóË∂ãÂäø
        3. Â∏ÇÂú∫Âë®Êúü‰ΩçÁΩÆ
        4. Áõ∏ÂÖ≥ËµÑ‰∫ßË°®Áé∞
        5. ÊîøÁ≠ñÂíåÁõëÁÆ°ÂΩ±Âìç
        
        ‰ª•JSONÊ†ºÂºèËøîÂõûÂàÜÊûêÁªìÊûú„ÄÇ
        """
        
        self.record_thought(
            ThoughtType.ANALYSIS,
            "Ê≠£Âú®ÁªºÂêàÂàÜÊûêÂÆèËßÇÁéØÂ¢É„ÄÅË°å‰∏öË∂ãÂäøÂíåÊîøÁ≠ñÂΩ±Âìç...",
            confidence=0.8
        )
        
        response = await self.llm.generate(analysis_prompt)
        
        # ËÆ°ÁÆóÁΩÆ‰ø°Â∫¶
        confidence_factors = {
            "data_quality": 0.7,
            "data_recency": 0.8,
            "analysis_depth": depth / 5,
            "market_conditions": 0.6
        }
        
        final_confidence = self.calculate_confidence(confidence_factors)
        
        # ËÆ∞ÂΩïÁªìËÆ∫
        self.record_thought(
            ThoughtType.CONCLUSION,
            f"Â∏ÇÂú∫ÂàÜÊûêÂÆåÊàêÔºåÁªºÂêàÁΩÆ‰ø°Â∫¶Ôºö{final_confidence:.2f}",
            confidence=final_confidence
        )
        
        return {
            "analyst_type": "market",
            "analysis": response,
            "confidence_score": final_confidence,
            "timestamp": datetime.utcnow().isoformat(),
            "thought_stream": self.get_thought_stream()
        }


class AgentCoordinator:
    """‰ª£ÁêÜÂçèË∞ÉÂô® - ÁÆ°ÁêÜÂ§ö‰∏™ÂàÜÊûêÂ∏àÁöÑÂçè‰Ωú"""
    
    def __init__(self, agents: List[BaseAnalyst]):
        self.agents = agents
        self.debate_rounds = 3
        
    async def collaborative_analysis(
        self, 
        target: str, 
        data: Dict[str, Any], 
        depth: int = 3
    ) -> Dict[str, Any]:
        """ÊâßË°åÂçè‰ΩúÂàÜÊûê"""
        logger.info(f"ÂºÄÂßãÂØπ{target}ÁöÑÂçè‰ΩúÂàÜÊûêÔºåÂèÇ‰∏éÂàÜÊûêÂ∏àÔºö{len(self.agents)}‰∏™")
        
        # Á¨¨‰∏ÄÈò∂ÊÆµÔºöÁã¨Á´ãÂàÜÊûê
        individual_analyses = await self._conduct_individual_analyses(target, data, depth)
        
        # Á¨¨‰∫åÈò∂ÊÆµÔºöËßÇÁÇπ‰∫§ÊµÅÂíåËæ©ËÆ∫
        debate_results = await self._conduct_debate(target, individual_analyses)
        
        # Á¨¨‰∏âÈò∂ÊÆµÔºöÂΩ¢ÊàêÂÖ±ËØÜ
        consensus = await self._form_consensus(individual_analyses, debate_results)
        
        return {
            "individual_analyses": individual_analyses,
            "debate_results": debate_results,
            "consensus": consensus,
            "timestamp": datetime.utcnow().isoformat()
        }
        
    async def _conduct_individual_analyses(
        self, 
        target: str, 
        data: Dict[str, Any], 
        depth: int
    ) -> List[Dict[str, Any]]:
        """ËøõË°åÁã¨Á´ãÂàÜÊûê"""
        tasks = []
        for agent in self.agents:
            task = agent.analyze(target, data, depth)
            tasks.append(task)
            
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ËøáÊª§ÊéâÂ§±Ë¥•ÁöÑÂàÜÊûê
        valid_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"Agent {self.agents[i].name} analysis failed: {result}")
            else:
                valid_results.append(result)
                
        return valid_results
        
    async def _conduct_debate(
        self, 
        target: str, 
        analyses: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ËøõË°åËßÇÁÇπËæ©ËÆ∫"""
        debate_results = []
        
        # ÊèêÂèñ‰∏ªË¶ÅËßÇÁÇπÂàÜÊ≠ß
        divergent_topics = self._identify_divergent_topics(analyses)
        
        for topic in divergent_topics[:3]:  # ÈôêÂà∂Ëæ©ËÆ∫ËØùÈ¢òÊï∞Èáè
            logger.info(f"ÂºÄÂßãËæ©ËÆ∫ËØùÈ¢òÔºö{topic}")
            
            # ÊØè‰∏™ÂàÜÊûêÂ∏àÂØπËØ•ËØùÈ¢òÂèëË°®ËßÇÁÇπ
            debate_round = []
            for agent in self.agents:
                other_opinions = [
                    {
                        "analyst": a.get("analyst_type"),
                        "opinion": a.get("analysis", {}).get(topic, "Êó†ËßÇÁÇπ")
                    }
                    for a in analyses
                    if a.get("analyst_type") != agent.name.lower()
                ]
                
                opinion = await agent.debate(topic, other_opinions)
                debate_round.append(opinion)
                
            debate_results.append({
                "topic": topic,
                "round": debate_round,
                "timestamp": datetime.utcnow().isoformat()
            })
            
        return debate_results
        
    async def _form_consensus(
        self, 
        analyses: List[Dict[str, Any]], 
        debates: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ÂΩ¢ÊàêÂÖ±ËØÜÊÑèËßÅ"""
        # Êî∂ÈõÜÊâÄÊúâËØÑÁ∫ß
        ratings = []
        confidences = []
        
        for analysis in analyses:
            if "rating" in analysis.get("analysis", {}):
                ratings.append(analysis["analysis"]["rating"])
            if "confidence_score" in analysis:
                confidences.append(analysis["confidence_score"])
                
        # ËÆ°ÁÆóÂÖ±ËØÜËØÑÁ∫ß
        consensus_rating = self._calculate_weighted_consensus(ratings, confidences)
        
        # Êï¥ÂêàÂÖ≥ÈîÆÂèëÁé∞
        all_findings = []
        for analysis in analyses:
            findings = analysis.get("analysis", {}).get("key_findings", [])
            all_findings.extend(findings)
            
        # Êï¥ÂêàÂª∫ËÆÆ
        all_recommendations = []
        for analysis in analyses:
            recommendations = analysis.get("analysis", {}).get("recommendations", [])
            all_recommendations.extend(recommendations)
            
        return {
            "consensus_rating": consensus_rating,
            "average_confidence": sum(confidences) / len(confidences) if confidences else 0.5,
            "key_findings": self._prioritize_findings(all_findings),
            "recommendations": self._prioritize_recommendations(all_recommendations),
            "participating_analysts": len(analyses),
            "debate_topics": [d["topic"] for d in debates]
        }
        
    def _identify_divergent_topics(self, analyses: List[Dict[str, Any]]) -> List[str]:
        """ËØÜÂà´ÂàÜÊ≠ßËØùÈ¢ò"""
        # ÁÆÄÂåñÂÆûÁé∞ÔºöËøîÂõûÈ¢ÑÂÆö‰πâÁöÑÂÖ≥ÈîÆËØùÈ¢ò
        return [
            "‰ª∑Ê†ºËµ∞ÂäøÈ¢ÑÊµã",
            "‰∏ªË¶ÅÈ£éÈô©Âõ†Á¥†",
            "ÊäïËµÑÊó∂Êú∫Âà§Êñ≠"
        ]
        
    def _calculate_weighted_consensus(
        self, 
        ratings: List[str], 
        confidences: List[float]
    ) -> str:
        """ËÆ°ÁÆóÂä†ÊùÉÂÖ±ËØÜ"""
        if not ratings:
            return "neutral"
            
        rating_scores = {
            "bullish": 1,
            "neutral": 0,
            "bearish": -1
        }
        
        # Â¶ÇÊûúÊ≤°ÊúâÁΩÆ‰ø°Â∫¶Ôºå‰ΩøÁî®ÁÆÄÂçïÂπ≥Âùá
        if not confidences or len(confidences) != len(ratings):
            total_score = sum(rating_scores.get(r, 0) for r in ratings)
            avg_score = total_score / len(ratings)
        else:
            # ‰ΩøÁî®ÁΩÆ‰ø°Â∫¶Âä†ÊùÉ
            weighted_sum = sum(
                rating_scores.get(r, 0) * c 
                for r, c in zip(ratings, confidences)
            )
            total_confidence = sum(confidences)
            avg_score = weighted_sum / total_confidence if total_confidence > 0 else 0
            
        if avg_score > 0.3:
            return "bullish"
        elif avg_score < -0.3:
            return "bearish"
        else:
            return "neutral"
            
    def _prioritize_findings(self, findings: List[Any]) -> List[Any]:
        """‰ºòÂÖàÁ∫ßÊéíÂ∫èÂÖ≥ÈîÆÂèëÁé∞"""
        # ÁÆÄÂåñÂÆûÁé∞ÔºöÂéªÈáçÂπ∂ËøîÂõûÂâç5‰∏™
        unique_findings = []
        seen = set()
        
        for finding in findings:
            finding_str = str(finding)
            if finding_str not in seen:
                seen.add(finding_str)
                unique_findings.append(finding)
                
        return unique_findings[:5]
        
    def _prioritize_recommendations(self, recommendations: List[Any]) -> List[Any]:
        """‰ºòÂÖàÁ∫ßÊéíÂ∫èÂª∫ËÆÆ"""
        # ÁÆÄÂåñÂÆûÁé∞ÔºöÂéªÈáçÂπ∂ËøîÂõûÂâç3‰∏™
        unique_recommendations = []
        seen = set()
        
        for rec in recommendations:
            rec_str = str(rec)
            if rec_str not in seen:
                seen.add(rec_str)
                unique_recommendations.append(rec)
                
        return unique_recommendations[:3]