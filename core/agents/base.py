"""
æ™ºèƒ½åˆ†æä»£ç†å®ç°
"""

from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional, Literal
from datetime import datetime
import json
import asyncio
import logging
from enum import Enum

logger = logging.getLogger(__name__)


class ThoughtType(str, Enum):
    """Thought type enumeration"""
    OBSERVATION = "observation"
    ANALYSIS = "analysis"
    CONCLUSION = "conclusion"
    QUESTION = "question"


class AgentThought:
    """Agent thought record"""
    
    def __init__(
        self,
        agent_id: str,
        domain: str,
        thought_type: ThoughtType,
        content: str,
        confidence: float = 0.5,
        evidence: List[Dict[str, Any]] = None
    ):
        self.agent_id = agent_id
        self.domain = domain
        self.timestamp = datetime.utcnow().timestamp()
        self.thought_type = thought_type
        self.content = content
        self.confidence = confidence
        self.evidence = evidence or []
        
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary format"""
        return {
            "agentId": self.agent_id,
            "domain": self.domain,
            "timestamp": self.timestamp,
            "thoughtType": self.thought_type.value,
            "content": self.content,
            "confidence": self.confidence,
            "evidence": self.evidence
        }


class BaseAnalyst(ABC):
    """Base analyst class"""
    
    def __init__(self, llm: Any, name: str = None, domain: str = None):
        self.llm = llm
        self.name = name or self.__class__.__name__
        self.domain = domain or self._get_default_domain()
        self.analysis_cache = {}
        self.confidence_factors = {}
        self.thought_stream: List[AgentThought] = []
        self.stop_event = None  # Add stop event support
        
        # Inject tool adapter
        try:
            from core.agents.tools import analyst_tools
            self.tools = analyst_tools
        except ImportError as e:
            import logging
            logging.warning(f"âš ï¸ Failed to import tool adapter: {e}")
            self.tools = None
        
    @abstractmethod
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = 3) -> Dict[str, Any]:
        """Execute analysis"""
        pass
        
    @abstractmethod
    def get_expertise_areas(self) -> List[str]:
        """Get expertise areas"""
        pass
        
    @abstractmethod
    def _get_default_domain(self) -> str:
        """Get default analysis domain"""
        pass
        
    def record_thought(
        self,
        thought_type: ThoughtType,
        content: str,
        confidence: float = 0.5,
        evidence: List[Dict[str, Any]] = None
    ) -> AgentThought:
        """Record thinking process"""
        thought = AgentThought(
            agent_id=self.name,
            domain=self.domain,
            thought_type=thought_type,
            content=content,
            confidence=confidence,
            evidence=evidence
        )
        self.thought_stream.append(thought)
        logger.debug(f"{self.name} {thought_type.value}: {content}")
        return thought
        
    def get_thought_stream(self) -> List[Dict[str, Any]]:
        """Get thought stream"""
        return [thought.to_dict() for thought in self.thought_stream]
        
    def clear_thoughts(self):
        """Clear thought records"""
        self.thought_stream = []
        
    def check_stop_signal(self) -> bool:
        """Check stop signal
        
        Returns:
            bool: Returns True if stop signal received
        """
        if self.stop_event and self.stop_event.is_set():
            logger.info(f"Agent {self.name} received stop signal, interrupting execution")
            return True
        return False
        
    def set_stop_event(self, stop_event):
        """Set stop event - propagate to APIExecutor"""
        self.stop_event = stop_event
        
        # Propagate to tool set's APIExecutor
        if hasattr(self, 'toolkit') and self.toolkit:
            # Get global APIExecutor instance
            from core.services.tools.api_executor import get_api_executor
            api_executor = get_api_executor()
            api_executor.set_stop_event(stop_event)
            logger.debug(f"ğŸ›‘ [{self.name}] Stop event propagated to APIExecutor")
        
    async def debate(self, topic: str, other_opinions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Debate with other analysts"""
        prompt = f"""
        As {self.name}, I need to express my opinion on the following topic and respond to other analysts:
        
        Topic: {topic}
        
        Other analysts' opinions:
        {json.dumps(other_opinions, ensure_ascii=False, indent=2)}
        
        Based on my professional domain and analytical methods, please provide:
        1. My core viewpoint
        2. Evaluation of other viewpoints
        3. Evidence supporting my viewpoint
        4. Potential risks or uncertainties
        
        Return in JSON format.
        """
        
        response = await self.llm.generate(prompt)
        return {
            "analyst": self.name,
            "debate_response": response,
            "timestamp": datetime.utcnow().isoformat()
        }
        
    def calculate_confidence(self, factors: Dict[str, float]) -> float:
        """Calculate confidence score"""
        # Calculate weighted confidence based on multiple factors
        weights = {
            "data_quality": 0.3,
            "data_recency": 0.2,
            "analysis_depth": 0.2,
            "market_conditions": 0.3
        }
        
        confidence = 0.0
        for factor, value in factors.items():
            weight = weights.get(factor, 0.1)
            confidence += weight * value
            
        return min(max(confidence, 0.0), 1.0)


class BaseCryptoAnalyst(BaseAnalyst):
    """Base crypto analyst class - eliminate code duplication, configuration-driven"""
    
    def __init__(self, llm: Any, config: Dict[str, Any]):
        """
        Initialize crypto analyst
        
        Args:
            llm: Language model instance
            config: Analyst configuration (loaded from YAML)
        """
        super().__init__(
            llm, 
            config.get("name", self.__class__.__name__),
            config.get("domain", "Cryptocurrency Analysis")
        )
        self.config = config
        
        # Load professional settings from configuration
        self.expertise_areas = config.get("expertise_areas", [])
        self.analysis_depth = config.get("analysis_depth", 3)
        self.tool_config = config.get("tools", {})
        
        logger.debug(f"Initializing crypto analyst: {self.name}")
    
    def get_expertise_areas(self) -> List[str]:
        """Get expertise areas"""
        return self.expertise_areas
    
    def _get_default_domain(self) -> str:
        """Get default analysis domain"""
        return "Cryptocurrency Analysis"
    
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = None) -> Dict[str, Any]:
        """
        Execute cryptocurrency analysis - unified process, configuration-driven
        
        Args:
            target: Analysis target (cryptocurrency symbol)
            data: Input data
            depth: Analysis depth
        
        Returns:
            Analysis result
        """
        # Check stop signal
        if self.check_stop_signal():
            return {"cancelled": True, "analyst_type": "crypto", "message": "Analysis cancelled by user"}
            
        analysis_depth = depth or self.analysis_depth
        self.clear_thoughts()
        
        # Record analysis start
        self.record_thought(
            ThoughtType.OBSERVATION,
            f"Starting {self.name} analysis for {target}, depth level: {analysis_depth}",
            confidence=0.9
        )
        
        # Tool execution phase
        tool_results = {}
        if self.tools and self.tool_config.get("enabled", True):
            # Check stop signalï¼ˆå·¥å…·æ‰§è¡Œå‰ï¼‰
            if self.check_stop_signal():
                return {"cancelled": True, "analyst_type": "crypto", "message": "Analysis cancelled before tool execution"}
            tool_results = await self._execute_tools(target, data)
        
        # Check stop signalï¼ˆåˆ†æé˜¶æ®µå‰ï¼‰
        if self.check_stop_signal():
            return {"cancelled": True, "analyst_type": "crypto", "message": "Analysis cancelled before LLM analysis"}
        
        # åˆ†æé˜¶æ®µ - ä½¿ç”¨é…ç½®çš„æç¤ºè¯æ¨¡æ¿
        analysis_result = await self._perform_analysis(target, data, tool_results, analysis_depth)
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._calculate_analysis_confidence(tool_results, analysis_depth)
        
        # è®°å½•ç»“è®º
        self.record_thought(
            ThoughtType.CONCLUSION,
            f"{self.name} analysis completed, confidence: {confidence:.2f}",
            confidence=confidence
        )
        
        return {
            "analyst_type": self.config.get("type", "crypto"),
            "analysis": analysis_result,
            "confidence_score": confidence,
            "timestamp": datetime.utcnow().isoformat(),
            "thought_stream": self.get_thought_stream(),
            "tool_results": tool_results
        }
    
    async def _execute_tools(self, target: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """Execute tools to get data - subclasses can override to customize tool execution"""
        tool_results = {}
        
        # åŸºç¡€ä»·æ ¼æ•°æ®
        if hasattr(self.tools, 'get_crypto_price_data'):
            try:
                price_data = self.tools.get_crypto_price_data(target, days_back=30)
                if 'error' not in price_data:
                    tool_results['price_data'] = price_data
                    self.record_thought(
                        ThoughtType.OBSERVATION,
                        f"Successfully retrieved price data for {target}",
                        confidence=0.8
                    )
            except Exception as e:
                logger.warning(f"Failed to retrieve price data: {e}")
        
        return tool_results
    
    async def _perform_analysis(self, target: str, data: Dict[str, Any], tool_results: Dict[str, Any], depth: int) -> str:
        """
        Execute specific analysis - using configured prompts
        Subclasses can override to implement specific analysis logic
        """
        # ä½¿ç”¨æç¤ºè¯åŠ è½½å™¨è·å–é…ç½®
        from core.agents.prompt_loader import get_prompt_loader
        
        # è·å–è¯­è¨€å‚æ•°ï¼ˆä»dataä¸­æå–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤ä¸­æ–‡ï¼‰
        language = data.get("language", "zh-CN")
        
        prompt_loader = get_prompt_loader()
        analyst_type = self.config.get("prompt_type", "market")
        prompt_config = prompt_loader.load_prompt(analyst_type, language=language)
        
        # æ„å»ºåˆ†ææç¤ºè¯
        analysis_prompt = self._build_analysis_prompt(
            target, data, tool_results, depth, prompt_config
        )
        
        # æ‰§è¡ŒLLMåˆ†æ
        response = await self.llm.generate(analysis_prompt)
        
        self.record_thought(
            ThoughtType.ANALYSIS,
            f"Completed {analyst_type} analysis",
            confidence=0.7
        )
        
        return response
    
    def _build_analysis_prompt(self, target: str, data: Dict[str, Any], 
                              tool_results: Dict[str, Any], depth: int,
                              prompt_config: Dict[str, Any]) -> str:
        """Build analysis prompt - unified template"""
        
        system_message = prompt_config.get("system_message", f"You are a professional {self.name}")
        
        # æ ¼å¼åŒ–åŸºç¡€ä¿¡æ¯
        base_prompt = f"""
{system_message}

Analysis Target: {target}
Analysis Depth: {depth}/5
Current Date: {datetime.utcnow().strftime('%Y-%m-%d')}

"""
        
        # æ·»åŠ å·¥å…·æ•°æ®
        if tool_results:
            base_prompt += "Retrieved Data:\n"
            for tool_name, result in tool_results.items():
                base_prompt += f"{tool_name}: {json.dumps(result, ensure_ascii=False, indent=2)}\n\n"
        
        # æ·»åŠ åˆ†æè¦æ±‚
        focus_areas = self.config.get("analysis_focus", [])
        if focus_areas:
            base_prompt += f"Key Analysis Areas: {', '.join(focus_areas)}\n\n"
        
        base_prompt += """
Please conduct professional analysis based on the above data, including:
1. Key indicator interpretation
2. Trend analysis
3. Risk assessment
4. Investment recommendations

Return analysis results in structured format.
"""
        
        return base_prompt
    
    def _calculate_analysis_confidence(self, tool_results: Dict[str, Any], depth: int) -> float:
        """Calculate analysis confidence"""
        factors = {
            "data_quality": 0.8 if tool_results else 0.5,
            "data_recency": 0.8,  # Assume data is recent
            "analysis_depth": depth / 5,
            "market_conditions": 0.7
        }
        
        return self.calculate_confidence(factors)


class TechnicalAnalyst(BaseAnalyst):
    """Technical Analyst"""
    
    def __init__(self, llm: Any):
        super().__init__(llm, "Technical Analyst")
        
    def get_expertise_areas(self) -> List[str]:
        return ["price_patterns", "technical_indicators", "trend_analysis", "support_resistance"]
        
    def _get_default_domain(self) -> str:
        return "Technical Analysis"
        
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = 3) -> Dict[str, Any]:
        """Execute technical analysis"""
        # Check stop signal
        if self.check_stop_signal():
            return {"cancelled": True, "analyst_type": "technical", "message": "Analysis cancelled by user"}
            
        # æ¸…ç©ºä¹‹å‰çš„æ€è€ƒè®°å½•
        self.clear_thoughts()
        
        # ä½¿ç”¨å·¥å…·è·å–å®æ—¶ä»·æ ¼æ•°æ®
        real_time_data = {}
        technical_indicators = {}
        
        if self.tools:
            self.record_thought(
                ThoughtType.OBSERVATION,
                f"Retrieving real-time price data and technical indicators for {target}...",
                confidence=0.9
            )
            
            # è·å–å®æ—¶ä»·æ ¼æ•°æ®
            price_result = self.tools.get_crypto_price_data(target, days_back=30)
            
            # Check stop signal
            if self.check_stop_signal():
                return {"cancelled": True, "analyst_type": "technical", "message": "Analysis cancelled during price data retrieval"}
            
            if 'error' not in price_result:
                real_time_data = price_result
                latest_price = price_result.get('latest_price')
                price_change_pct = price_result.get('price_change_pct')
                
                self.record_thought(
                    ThoughtType.OBSERVATION,
                    f"Retrieved real-time data for {target}: Current price ${latest_price:.2f}, " +
                    f"Change {price_change_pct:.2f}% ({price_result.get('total_records')} records)",
                    confidence=0.95
                )
            
            # Check stop signal
            if self.check_stop_signal():
                return {"cancelled": True, "analyst_type": "technical", "message": "Analysis cancelled before retrieving technical indicators"}
            
            # è·å–æŠ€æœ¯æŒ‡æ ‡
            indicators_result = self.tools.get_technical_indicators(
                target, 
                indicators=['sma', 'rsi', 'macd', 'bb'],
                period_days=30
            )
            if 'error' not in indicators_result:
                technical_indicators = indicators_result.get('indicators', {})
                
                # åˆ†æRSIä¿¡å·
                rsi = technical_indicators.get('rsi')
                if rsi:
                    if rsi > 70:
                        self.record_thought(
                            ThoughtType.ANALYSIS,
                            f"RSI indicator at {rsi:.1f}, showing overbought condition, may face pullback pressure",
                            confidence=0.8
                        )
                    elif rsi < 30:
                        self.record_thought(
                            ThoughtType.ANALYSIS,
                            f"RSI indicator at {rsi:.1f}, showing oversold condition, may see bounce opportunity",
                            confidence=0.8
                        )
        
        # ä½¿ç”¨ä¼ å…¥çš„æ•°æ®ä½œä¸ºåå¤‡
        price_data = real_time_data if real_time_data else data.get("price_data", {})
        
        # è®°å½•è§‚å¯Ÿ
        latest_price = price_data.get('latest_price') or price_data.get('current_price', 0)
        price_change = price_data.get('price_change_pct') or price_data.get('change_24h', 0)
        
        self.record_thought(
            ThoughtType.OBSERVATION,
            f"Starting technical analysis of {target}. Current price: ${latest_price}, " +
            f"Change: {price_change}%",
            confidence=0.9
        )
        
        # è®°å½•åˆæ­¥åˆ†æ
        if price_data.get('change_24h', 0) > 5:
            self.record_thought(
                ThoughtType.ANALYSIS,
                "Strong uptrend detected, 24-hour gain exceeds 5%, need to analyze if this is sustainable growth",
                confidence=0.7
            )
        elif price_data.get('change_24h', 0) < -5:
            self.record_thought(
                ThoughtType.ANALYSIS,
                "Significant downtrend detected, 24-hour decline exceeds 5%, need to assess support level strength",
                confidence=0.7
            )
        
        # æ„å»ºåŒ…å«å®æ—¶æ•°æ®çš„åˆ†ææç¤º
        indicators_text = ""
        if technical_indicators:
            indicators_text = "\nTechnical Indicators:"
            for indicator, value in technical_indicators.items():
                if isinstance(value, dict):
                    for sub_key, sub_value in value.items():
                        indicators_text += f"\n- {sub_key}: {sub_value}"
                else:
                    indicators_text += f"\n- {indicator}: {value}"
        
        analysis_prompt = f"""
        Conduct in-depth technical analysis for {target} (Depth Level: {depth}/5):
        
        Real-time Price Data:
        - Current Price: ${price_data.get('latest_price') or price_data.get('current_price', 0)}
        - Price Change: {price_data.get('price_change_pct') or price_data.get('change_24h', 0)}%
        - Price Change Amount: ${price_data.get('price_change', 0)}
        - Data Records: {price_data.get('total_records', 'N/A')}
        - Analysis Period: {price_data.get('start_date', 'N/A')} to {price_data.get('end_date', 'N/A')}
        {indicators_text}
        
        Please analyze based on the above real-time data:
        1. Price trends (short-term, medium-term, long-term)
        2. Key support and resistance levels
        3. Technical indicator signal interpretation
        4. Risk assessment
        5. Trading recommendations
        
        Special Notes:
        - RSI > 70 indicates overbought, < 30 indicates oversold
        - MACD signal line crossovers indicate trend changes
        - Bollinger Bands position indicates price pressure/support
        
        Return in JSON format, including:
        - analysis: Detailed analysis content
        - summary: Brief summary
        - rating: Rating (bullish/neutral/bearish)
        - confidence_score: Confidence level (0-1)
        - key_findings: List of key findings
        - recommendations: List of specific recommendations
        """
        
        # è®°å½•åˆ†æè¿‡ç¨‹
        self.record_thought(
            ThoughtType.ANALYSIS,
            "Conducting comprehensive analysis of price trends, technical indicators, and volume data...",
            confidence=0.8
        )
        
        # Check stop signalï¼ˆLLMè°ƒç”¨å‰ï¼‰
        if self.check_stop_signal():
            return {"cancelled": True, "analyst_type": "technical", "message": "Analysis cancelled before LLM call"}
        
        response = await self.llm.generate(analysis_prompt)
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence_factors = {
            "data_quality": 0.8 if price_data else 0.2,
            "data_recency": 0.9,  # Assume data is latest
            "analysis_depth": depth / 5,
            "market_conditions": 0.7
        }
        
        final_confidence = self.calculate_confidence(confidence_factors)
        
        # è®°å½•ç»“è®º
        self.record_thought(
            ThoughtType.CONCLUSION,
            f"Technical analysis completed, overall confidence: {final_confidence:.2f}",
            confidence=final_confidence
        )
        
        result = {
            "analyst_type": "technical",
            "analysis": response,
            "confidence_score": final_confidence,
            "timestamp": datetime.utcnow().isoformat(),
            "thought_stream": self.get_thought_stream()
        }
        
        return result


class FundamentalAnalyst(BaseAnalyst):
    """Fundamental Analyst"""
    
    def __init__(self, llm: Any):
        super().__init__(llm, "Fundamental Analyst")
        
    def get_expertise_areas(self) -> List[str]:
        return ["financial_metrics", "business_model", "competitive_position", "growth_potential"]
        
    def _get_default_domain(self) -> str:
        return "Fundamental Analysis"
        
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = 3) -> Dict[str, Any]:
        """Execute fundamental analysis"""
        fundamentals = data.get("fundamentals", {})
        market_type = data.get("market_type", "stock")
        
        # æ¸…ç©ºä¹‹å‰çš„æ€è€ƒè®°å½•
        self.clear_thoughts()
        
        # è®°å½•åˆå§‹è§‚å¯Ÿ
        self.record_thought(
            ThoughtType.OBSERVATION,
            f"Starting fundamental analysis for {target}, market type: {market_type}",
            confidence=0.9
        )
        
        if market_type == "stock":
            # åˆ†æè´¢åŠ¡æ•°æ®
            if fundamentals:
                pe_ratio = fundamentals.get("pe_ratio", 0)
                revenue_growth = fundamentals.get("revenue_growth", 0)
                
                if pe_ratio > 0 and pe_ratio < 20:
                    self.record_thought(
                        ThoughtType.ANALYSIS,
                        f"P/E ratio of {pe_ratio} is in reasonable valuation range",
                        confidence=0.8,
                        evidence=[{"type": "valuation", "value": pe_ratio}]
                    )
                elif pe_ratio >= 20:
                    self.record_thought(
                        ThoughtType.ANALYSIS,
                        f"High P/E ratio of {pe_ratio}, need to check if supported by high growth",
                        confidence=0.7,
                        evidence=[{"type": "valuation", "value": pe_ratio}]
                    )
                
                if revenue_growth > 15:
                    self.record_thought(
                        ThoughtType.ANALYSIS,
                        f"Revenue growth rate of {revenue_growth}% shows good growth potential",
                        confidence=0.8,
                        evidence=[{"type": "growth", "value": revenue_growth}]
                    )
            
            analysis_prompt = f"""
            Conduct fundamental analysis for {target} (Depth Level: {depth}/5):
            
            Fundamental Data:
            {json.dumps(fundamentals, ensure_ascii=False, indent=2)}
            
            Please analyze:
            1. Financial health status
            2. Profitability and growth trends
            3. Valuation levels
            4. Industry position and competitive advantages
            5. Management quality
            
            Return analysis results in JSON format.
            """
        else:
            # åŠ å¯†è´§å¸çš„åŸºæœ¬é¢åˆ†æ
            self.record_thought(
                ThoughtType.ANALYSIS,
                "Cryptocurrency fundamental analysis will focus on technical innovation, team strength, and ecosystem development",
                confidence=0.8
            )
            
            analysis_prompt = f"""
            Conduct fundamental analysis for {target} (Depth Level: {depth}/5):
            
            Please analyze:
            1. Project technology and innovation
            2. Team background and execution capability
            3. Token economic model
            4. Market adoption and ecosystem development
            5. Competitive landscape
            
            Return analysis results in JSON format.
            """
        
        self.record_thought(
            ThoughtType.ANALYSIS,
            "Conducting comprehensive analysis of financial data, business model, and competitive advantages...",
            confidence=0.85
        )
            
        response = await self.llm.generate(analysis_prompt)
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence_factors = {
            "data_quality": 0.9 if fundamentals else 0.3,
            "data_recency": 0.8,
            "analysis_depth": depth / 5,
            "market_conditions": 0.6
        }
        
        final_confidence = self.calculate_confidence(confidence_factors)
        
        # è®°å½•ç»“è®º
        self.record_thought(
            ThoughtType.CONCLUSION,
            f"Fundamental analysis completed, overall confidence: {final_confidence:.2f}",
            confidence=final_confidence
        )
        
        return {
            "analyst_type": "fundamental",
            "analysis": response,
            "confidence_score": final_confidence,
            "timestamp": datetime.utcnow().isoformat(),
            "thought_stream": self.get_thought_stream()
        }


class SentimentAnalyst(BaseAnalyst):
    """Sentiment Analyst"""
    
    def __init__(self, llm: Any):
        super().__init__(llm, "Sentiment Analyst")
        
    def get_expertise_areas(self) -> List[str]:
        return ["social_sentiment", "news_analysis", "market_psychology", "trend_momentum"]
        
    def _get_default_domain(self) -> str:
        return "Sentiment Analysis"
        
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = 3) -> Dict[str, Any]:
        """æ‰§è¡Œæƒ…ç»ªåˆ†æ"""
        # æ¸…ç©ºä¹‹å‰çš„æ€è€ƒè®°å½•
        self.clear_thoughts()
        
        # ä½¿ç”¨å·¥å…·è·å–å®æ—¶æ–°é—»å’Œæƒ…ç»ªæ•°æ®
        real_time_news = []
        sentiment_data = {}
        
        if self.tools:
            self.record_thought(
                ThoughtType.OBSERVATION,
                f"æ­£åœ¨è·å–{target}çš„å®æ—¶æ–°é—»å’Œå¸‚åœºæƒ…ç»ªæ•°æ®...",
                confidence=0.9
            )
            
            # è·å–å®æ—¶æ–°é—»
            news_result = self.tools.get_crypto_news(target, days_back=7, max_results=15)
            if 'error' not in news_result:
                real_time_news = news_result.get('articles', [])
                news_count = news_result.get('news_count', 0)
                
                self.record_thought(
                    ThoughtType.OBSERVATION,
                    f"è·å–åˆ°{news_count}æ¡{target}ç›¸å…³æ–°é—»ï¼ˆè¿‡å»7å¤©ï¼‰",
                    confidence=0.95
                )
                
                # åˆ†ææ–°é—»æ ‡é¢˜æƒ…æ„Ÿå€¾å‘ï¼ˆç®€å•å¯å‘å¼ï¼‰
                positive_keywords = ['rise', 'surge', 'bull', 'gain', 'up', 'positive', 'growth', 'æ¶¨', 'ä¸Šæ¶¨', 'çœ‹æ¶¨']
                negative_keywords = ['fall', 'drop', 'bear', 'loss', 'down', 'negative', 'crash', 'è·Œ', 'ä¸‹è·Œ', 'çœ‹è·Œ']
                
                positive_count = 0
                negative_count = 0
                
                for article in real_time_news[:10]:
                    headline = article.get('headline', '').lower()
                    if any(keyword in headline for keyword in positive_keywords):
                        positive_count += 1
                    elif any(keyword in headline for keyword in negative_keywords):
                        negative_count += 1
                
                if positive_count > negative_count:
                    self.record_thought(
                        ThoughtType.ANALYSIS,
                        f"æ–°é—»æƒ…ç»ªåå‘ç§¯æï¼š{positive_count}æ­£é¢ vs {negative_count}è´Ÿé¢ï¼Œå¸‚åœºé¢„æœŸä¹è§‚",
                        confidence=0.75
                    )
                elif negative_count > positive_count:
                    self.record_thought(
                        ThoughtType.ANALYSIS,
                        f"æ–°é—»æƒ…ç»ªåå‘æ¶ˆæï¼š{negative_count}è´Ÿé¢ vs {positive_count}æ­£é¢ï¼Œå¸‚åœºæƒ…ç»ªè°¨æ…",
                        confidence=0.75
                    )
                else:
                    self.record_thought(
                        ThoughtType.ANALYSIS,
                        f"æ–°é—»æƒ…ç»ªä¸­æ€§ï¼š{positive_count}æ­£é¢ vs {negative_count}è´Ÿé¢ï¼Œè§‚æœ›æƒ…ç»ªæµ“åš",
                        confidence=0.7
                    )
            
            # è·å–ç»¼åˆæƒ…ç»ªåˆ†æ
            sentiment_result = self.tools.get_sentiment_analysis(target, days_back=7)
            if 'error' not in sentiment_result:
                sentiment_data = sentiment_result
                
                total_articles = sentiment_result.get('summary', {}).get('total_news_articles', 0)
                self.record_thought(
                    ThoughtType.OBSERVATION,
                    f"ç»¼åˆæƒ…ç»ªåˆ†ææ¶µç›–{total_articles}ç¯‡æ–‡ç« ï¼Œæ•°æ®æ¥æºï¼šFinnHubã€Redditç­‰",
                    confidence=0.8
                )
        
        # ä½¿ç”¨å®æ—¶æ•°æ®ï¼Œä¼ å…¥æ•°æ®ä½œä¸ºåå¤‡
        news = real_time_news if real_time_news else data.get("news", [])
        sentiment = sentiment_data if sentiment_data else data.get("sentiment", {})
        
        # è®°å½•æœ€ç»ˆæ•°æ®ç»Ÿè®¡
        self.record_thought(
            ThoughtType.OBSERVATION,
            f"æƒ…ç»ªåˆ†ææ•°æ®ï¼š{len(news)}æ¡æ–°é—»ï¼Œæƒ…ç»ªæ•°æ®{'å·²è·å–' if sentiment else 'ç¼ºå¤±'}",
            confidence=0.9
        )
        
        # åˆ†ææ–°é—»æƒ…ç»ª
        if news:
            positive_count = sum(1 for n in news[:10] if n.get("sentiment", 0) > 0.5)
            negative_count = sum(1 for n in news[:10] if n.get("sentiment", 0) < -0.5)
            
            if positive_count > negative_count:
                self.record_thought(
                    ThoughtType.ANALYSIS,
                    f"è¿‘æœŸæ–°é—»åå‘ç§¯æï¼ˆ{positive_count}æ­£é¢ vs {negative_count}è´Ÿé¢ï¼‰ï¼Œå¸‚åœºæƒ…ç»ªä¹è§‚",
                    confidence=0.7,
                    evidence=[{"positive_news": positive_count, "negative_news": negative_count}]
                )
            elif negative_count > positive_count:
                self.record_thought(
                    ThoughtType.ANALYSIS,
                    f"è¿‘æœŸæ–°é—»åå‘æ¶ˆæï¼ˆ{negative_count}è´Ÿé¢ vs {positive_count}æ­£é¢ï¼‰ï¼Œå¸‚åœºæƒ…ç»ªè°¨æ…",
                    confidence=0.7,
                    evidence=[{"positive_news": positive_count, "negative_news": negative_count}]
                )
        
        # åˆ†æç¤¾äº¤åª’ä½“æƒ…ç»ª
        if sentiment.get("twitter_mentions", 0) > 1000:
            self.record_thought(
                ThoughtType.ANALYSIS,
                f"ç¤¾äº¤åª’ä½“è®¨è®ºçƒ­åº¦é«˜ï¼ˆ{sentiment.get('twitter_mentions', 0)}æ¬¡æåŠï¼‰ï¼Œå…³æ³¨åº¦ä¸Šå‡",
                confidence=0.8
            )
        
        # æ ¼å¼åŒ–å®æ—¶æ–°é—»æ•°æ®
        news_summary = ""
        if news:
            news_summary = f"å®æ—¶æ–°é—»æ ‡é¢˜ï¼ˆæœ€è¿‘{len(news)}æ¡ï¼‰ï¼š\n"
            for i, article in enumerate(news[:5], 1):  # åªæ˜¾ç¤ºå‰5æ¡é¿å…å¤ªé•¿
                news_summary += f"{i}. {article.get('headline', 'No headline')}\n"
                news_summary += f"   æ¥æº: {article.get('source', 'Unknown')} | æ—¶é—´: {article.get('datetime', 'N/A')}\n"
        
        analysis_prompt = f"""
        å¯¹{target}è¿›è¡Œå¸‚åœºæƒ…ç»ªåˆ†æï¼ˆæ·±åº¦çº§åˆ«ï¼š{depth}/5ï¼‰ï¼š
        
        {news_summary}
        
        æƒ…ç»ªæ•°æ®ç»Ÿè®¡ï¼š
        - æ–°é—»æ–‡ç« æ•°é‡: {len(news)}æ¡
        - æ•°æ®æ¥æº: FinnHubã€Redditç­‰å¤šå¹³å°
        - åˆ†ææ—¶é—´èŒƒå›´: è¿‡å»7å¤©
        
        ç»¼åˆæƒ…ç»ªåˆ†æç»“æœï¼š
        {json.dumps(sentiment, ensure_ascii=False, indent=2) if sentiment else "æš‚æ— ç»¼åˆæƒ…ç»ªæ•°æ®"}
        
        è¯·åŸºäºä»¥ä¸Šå®æ—¶æ•°æ®è¿›è¡Œæ·±åº¦æƒ…ç»ªåˆ†æï¼š
        1. æ•´ä½“å¸‚åœºæƒ…ç»ªè¶‹åŠ¿ï¼ˆç§¯æ/ä¸­æ€§/æ¶ˆæï¼‰
        2. æ–°é—»åª’ä½“æŠ¥é“å€¾å‘åˆ†æ
        3. å¸‚åœºå…³æ³¨åº¦å’Œè®¨è®ºçƒ­åº¦
        4. æ½œåœ¨çš„æƒ…ç»ªè½¬æŠ˜ä¿¡å·
        5. ä¸»è¦æƒ…ç»ªé©±åŠ¨å› ç´ è¯†åˆ«
        6. å¯¹ä»·æ ¼èµ°åŠ¿çš„æƒ…ç»ªå½±å“é¢„æµ‹
        
        ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ŒåŒ…å«ï¼š
        - analysis: è¯¦ç»†åˆ†æå†…å®¹
        - summary: ç®€çŸ­æ€»ç»“
        - sentiment_score: æƒ…ç»ªè¯„åˆ†(-1åˆ°1ï¼Œ-1æœ€æ¶ˆæï¼Œ1æœ€ç§¯æ)
        - confidence_score: ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
        - key_findings: å…³é”®å‘ç°åˆ—è¡¨
        - recommendations: åŸºäºæƒ…ç»ªçš„æ“ä½œå»ºè®®
        """
        
        self.record_thought(
            ThoughtType.ANALYSIS,
            "æ­£åœ¨ç»¼åˆåˆ†ææ–°é—»æƒ…æ„Ÿã€ç¤¾äº¤åª’ä½“çƒ­åº¦å’Œå¸‚åœºå¿ƒç†...",
            confidence=0.8
        )
        
        response = await self.llm.generate(analysis_prompt)
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence_factors = {
            "data_quality": min(1.0, len(news) / 20),
            "data_recency": 0.9,
            "analysis_depth": depth / 5,
            "market_conditions": 0.7
        }
        
        final_confidence = self.calculate_confidence(confidence_factors)
        
        # è®°å½•ç»“è®º
        self.record_thought(
            ThoughtType.CONCLUSION,
            f"æƒ…ç»ªåˆ†æå®Œæˆï¼Œç»¼åˆç½®ä¿¡åº¦ï¼š{final_confidence:.2f}",
            confidence=final_confidence
        )
        
        return {
            "analyst_type": "sentiment",
            "analysis": response,
            "confidence_score": final_confidence,
            "timestamp": datetime.utcnow().isoformat(),
            "thought_stream": self.get_thought_stream()
        }


class RiskAnalyst(BaseAnalyst):
    """é£é™©åˆ†æå¸ˆ"""
    
    def __init__(self, llm: Any):
        super().__init__(llm, "é£é™©åˆ†æå¸ˆ")
        
    def get_expertise_areas(self) -> List[str]:
        return ["risk_assessment", "volatility_analysis", "downside_protection", "portfolio_impact"]
        
    def _get_default_domain(self) -> str:
        return "é£é™©ç®¡ç†"
        
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = 3) -> Dict[str, Any]:
        """æ‰§è¡Œé£é™©åˆ†æ"""
        price_data = data.get("price_data", {})
        
        # æ¸…ç©ºä¹‹å‰çš„æ€è€ƒè®°å½•
        self.clear_thoughts()
        
        # è®°å½•åˆå§‹è§‚å¯Ÿ
        self.record_thought(
            ThoughtType.OBSERVATION,
            f"å¼€å§‹å¯¹{target}è¿›è¡Œé£é™©è¯„ä¼°ï¼Œé‡ç‚¹å…³æ³¨æ³¢åŠ¨æ€§å’Œä¸‹è¡Œé£é™©",
            confidence=0.9
        )
        
        # åˆ†ææ³¢åŠ¨æ€§
        volatility = price_data.get('volatility_daily', 0)
        if volatility > 5:
            self.record_thought(
                ThoughtType.ANALYSIS,
                f"æ—¥æ³¢åŠ¨ç‡é«˜è¾¾{volatility}%ï¼Œå±äºé«˜é£é™©èµ„äº§",
                confidence=0.9,
                evidence=[{"type": "volatility", "value": volatility}]
            )
        elif volatility > 2:
            self.record_thought(
                ThoughtType.ANALYSIS,
                f"æ—¥æ³¢åŠ¨ç‡ä¸º{volatility}%ï¼Œé£é™©é€‚ä¸­",
                confidence=0.8,
                evidence=[{"type": "volatility", "value": volatility}]
            )
        
        # åˆ†æä»·æ ¼ä½ç½®
        current_price = price_data.get('current_price', 0)
        high_52w = price_data.get('high_52w', 0)
        low_52w = price_data.get('low_52w', 0)
        
        if high_52w > 0 and current_price > 0:
            price_position = (current_price - low_52w) / (high_52w - low_52w) * 100
            if price_position > 80:
                self.record_thought(
                    ThoughtType.ANALYSIS,
                    f"å½“å‰ä»·æ ¼æ¥è¿‘52å‘¨é«˜ç‚¹ï¼ˆ{price_position:.1f}%ä½ç½®ï¼‰ï¼Œéœ€è­¦æƒ•å›è°ƒé£é™©",
                    confidence=0.8
                )
            elif price_position < 20:
                self.record_thought(
                    ThoughtType.ANALYSIS,
                    f"å½“å‰ä»·æ ¼æ¥è¿‘52å‘¨ä½ç‚¹ï¼ˆ{price_position:.1f}%ä½ç½®ï¼‰ï¼Œå¯èƒ½å­˜åœ¨åå¼¹æœºä¼š",
                    confidence=0.7
                )
        
        analysis_prompt = f"""
        å¯¹{target}è¿›è¡Œé£é™©åˆ†æï¼ˆæ·±åº¦çº§åˆ«ï¼š{depth}/5ï¼‰ï¼š
        
        ä»·æ ¼æ³¢åŠ¨æ•°æ®ï¼š
        - å½“å‰ä»·æ ¼ï¼š${price_data.get('current_price', 0)}
        - 52å‘¨æœ€é«˜ï¼š${price_data.get('high_52w', 0)}
        - 52å‘¨æœ€ä½ï¼š${price_data.get('low_52w', 0)}
        - æ—¥æ³¢åŠ¨ç‡ï¼š{price_data.get('volatility_daily', 0)}%
        
        è¯·åˆ†æï¼š
        1. ä¸»è¦é£é™©å› ç´ 
        2. æ³¢åŠ¨æ€§è¯„ä¼°
        3. ä¸‹è¡Œé£é™©
        4. é£é™©ç¼“è§£ç­–ç•¥
        5. é£é™©æ”¶ç›Šæ¯”
        
        ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
        """
        
        self.record_thought(
            ThoughtType.ANALYSIS,
            "æ­£åœ¨ç»¼åˆè¯„ä¼°å¸‚åœºé£é™©ã€ä¸ªè‚¡é£é™©å’Œç³»ç»Ÿæ€§é£é™©...",
            confidence=0.85
        )
        
        response = await self.llm.generate(analysis_prompt)
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence_factors = {
            "data_quality": 0.8 if price_data else 0.2,
            "data_recency": 0.9,
            "analysis_depth": depth / 5,
            "market_conditions": 0.5  # é£é™©åˆ†æåœ¨ä¸ç¡®å®šå¸‚åœºä¸­æ›´é‡è¦
        }
        
        final_confidence = self.calculate_confidence(confidence_factors)
        
        # è®°å½•ç»“è®º
        self.record_thought(
            ThoughtType.CONCLUSION,
            f"é£é™©åˆ†æå®Œæˆï¼Œç»¼åˆç½®ä¿¡åº¦ï¼š{final_confidence:.2f}",
            confidence=final_confidence
        )
        
        return {
            "analyst_type": "risk",
            "analysis": response,
            "confidence_score": final_confidence,
            "timestamp": datetime.utcnow().isoformat(),
            "thought_stream": self.get_thought_stream()
        }


class MarketAnalyst(BaseAnalyst):
    """å¸‚åœºåˆ†æå¸ˆ"""
    
    def __init__(self, llm: Any):
        super().__init__(llm, "å¸‚åœºåˆ†æå¸ˆ")
        
    def get_expertise_areas(self) -> List[str]:
        return ["macro_trends", "sector_analysis", "market_cycles", "cross_asset_correlation"]
        
    def _get_default_domain(self) -> str:
        return "å¸‚åœºåˆ†æ"
        
    async def analyze(self, target: str, data: Dict[str, Any], depth: int = 3) -> Dict[str, Any]:
        """æ‰§è¡Œå¸‚åœºåˆ†æ"""
        # æ¸…ç©ºä¹‹å‰çš„æ€è€ƒè®°å½•
        self.clear_thoughts()
        
        # ä½¿ç”¨å·¥å…·è·å–å¸‚åœºæ•°æ®å’Œæ–°é—»
        market_context = {}
        if self.tools:
            self.record_thought(
                ThoughtType.OBSERVATION,
                f"æ­£åœ¨è·å–{target}çš„å¸‚åœºæ•°æ®å’Œç›¸å…³æ–°é—»...",
                confidence=0.9
            )
            
            # è·å–ä»·æ ¼æ•°æ®ä½œä¸ºå¸‚åœºèƒŒæ™¯
            price_result = self.tools.get_crypto_price_data(target, days_back=30)
            if 'error' not in price_result:
                market_context['price_data'] = price_result
                
                self.record_thought(
                    ThoughtType.OBSERVATION,
                    f"è·å–{target}å¸‚åœºæ•°æ®ï¼šå½“å‰ä»·æ ¼${price_result.get('latest_price', 0):.2f}ï¼Œ" +
                    f"30å¤©å˜åŒ–{price_result.get('price_change_pct', 0):.2f}%",
                    confidence=0.9
                )
        
        # è®°å½•åˆå§‹è§‚å¯Ÿ
        self.record_thought(
            ThoughtType.OBSERVATION,
            f"å¼€å§‹å¯¹{target}è¿›è¡Œå®è§‚å¸‚åœºåˆ†æï¼Œè¯„ä¼°æ•´ä½“å¸‚åœºç¯å¢ƒå’Œè¡Œä¸šè¶‹åŠ¿",
            confidence=0.9
        )
        
        # åˆ†æå¸‚åœºæ•°æ®
        market_data = data.get("market_data", {})
        if market_data:
            market_trend = market_data.get("trend", "unknown")
            if market_trend == "bullish":
                self.record_thought(
                    ThoughtType.ANALYSIS,
                    "æ•´ä½“å¸‚åœºè¶‹åŠ¿å‘å¥½ï¼Œæœ‰åˆ©äºé£é™©èµ„äº§è¡¨ç°",
                    confidence=0.8
                )
            elif market_trend == "bearish":
                self.record_thought(
                    ThoughtType.ANALYSIS,
                    "å¸‚åœºå¤„äºä¸‹è¡Œè¶‹åŠ¿ï¼Œéœ€è¦è°¨æ…è¯„ä¼°é£é™©",
                    confidence=0.8
                )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¡Œä¸šæ•°æ®
        sector_data = data.get("sector_data", {})
        if sector_data:
            self.record_thought(
                ThoughtType.ANALYSIS,
                "æ­£åœ¨åˆ†æè¡Œä¸šè¡¨ç°å’Œæ¿å—è½®åŠ¨æƒ…å†µ...",
                confidence=0.7
            )
        
        # æå‡ºå…³é”®é—®é¢˜
        self.record_thought(
            ThoughtType.QUESTION,
            "å½“å‰å¸‚åœºå‘¨æœŸå¤„äºä»€ä¹ˆé˜¶æ®µï¼Ÿæ”¿ç­–é¢æ˜¯å¦æœ‰é‡å¤§å˜åŒ–ï¼Ÿ",
            confidence=0.6
        )
        
        analysis_prompt = f"""
        å¯¹{target}è¿›è¡Œå®è§‚å¸‚åœºåˆ†æï¼ˆæ·±åº¦çº§åˆ«ï¼š{depth}/5ï¼‰ï¼š
        
        å¸‚åœºæ•°æ®ï¼š
        {json.dumps(market_data, ensure_ascii=False, indent=2) if market_data else "æ— "}
        
        è¡Œä¸šæ•°æ®ï¼š
        {json.dumps(sector_data, ensure_ascii=False, indent=2) if sector_data else "æ— "}
        
        è¯·åˆ†æï¼š
        1. å®è§‚ç»æµç¯å¢ƒ
        2. è¡Œä¸š/æ¿å—è¶‹åŠ¿
        3. å¸‚åœºå‘¨æœŸä½ç½®
        4. ç›¸å…³èµ„äº§è¡¨ç°
        5. æ”¿ç­–å’Œç›‘ç®¡å½±å“
        
        ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
        """
        
        self.record_thought(
            ThoughtType.ANALYSIS,
            "æ­£åœ¨ç»¼åˆåˆ†æå®è§‚ç¯å¢ƒã€è¡Œä¸šè¶‹åŠ¿å’Œæ”¿ç­–å½±å“...",
            confidence=0.8
        )
        
        response = await self.llm.generate(analysis_prompt)
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence_factors = {
            "data_quality": 0.7,
            "data_recency": 0.8,
            "analysis_depth": depth / 5,
            "market_conditions": 0.6
        }
        
        final_confidence = self.calculate_confidence(confidence_factors)
        
        # è®°å½•ç»“è®º
        self.record_thought(
            ThoughtType.CONCLUSION,
            f"å¸‚åœºåˆ†æå®Œæˆï¼Œç»¼åˆç½®ä¿¡åº¦ï¼š{final_confidence:.2f}",
            confidence=final_confidence
        )
        
        return {
            "analyst_type": "market",
            "analysis": response,
            "confidence_score": final_confidence,
            "timestamp": datetime.utcnow().isoformat(),
            "thought_stream": self.get_thought_stream()
        }


class AgentCoordinator:
    """ä»£ç†åè°ƒå™¨ - ç®¡ç†å¤šä¸ªåˆ†æå¸ˆçš„åä½œ"""
    
    def __init__(self, agents: List[BaseAnalyst]):
        self.agents = agents
        self.debate_rounds = 3
        
    async def collaborative_analysis(
        self, 
        target: str, 
        data: Dict[str, Any], 
        depth: int = 3
    ) -> Dict[str, Any]:
        """æ‰§è¡Œåä½œåˆ†æ"""
        logger.info(f"å¼€å§‹å¯¹{target}çš„åä½œåˆ†æï¼Œå‚ä¸åˆ†æå¸ˆï¼š{len(self.agents)}ä¸ª")
        
        # ç¬¬ä¸€é˜¶æ®µï¼šç‹¬ç«‹åˆ†æ
        individual_analyses = await self._conduct_individual_analyses(target, data, depth)
        
        # ç¬¬äºŒé˜¶æ®µï¼šè§‚ç‚¹äº¤æµå’Œè¾©è®º
        debate_results = await self._conduct_debate(target, individual_analyses)
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šå½¢æˆå…±è¯†
        consensus = await self._form_consensus(individual_analyses, debate_results)
        
        return {
            "individual_analyses": individual_analyses,
            "debate_results": debate_results,
            "consensus": consensus,
            "timestamp": datetime.utcnow().isoformat()
        }
        
    async def _conduct_individual_analyses(
        self, 
        target: str, 
        data: Dict[str, Any], 
        depth: int
    ) -> List[Dict[str, Any]]:
        """è¿›è¡Œç‹¬ç«‹åˆ†æ"""
        tasks = []
        for agent in self.agents:
            task = agent.analyze(target, data, depth)
            tasks.append(task)
            
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è¿‡æ»¤æ‰å¤±è´¥çš„åˆ†æ
        valid_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"Agent {self.agents[i].name} analysis failed: {result}")
            else:
                valid_results.append(result)
                
        return valid_results
        
    async def _conduct_debate(
        self, 
        target: str, 
        analyses: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """è¿›è¡Œè§‚ç‚¹è¾©è®º"""
        debate_results = []
        
        # æå–ä¸»è¦è§‚ç‚¹åˆ†æ­§
        divergent_topics = self._identify_divergent_topics(analyses)
        
        for topic in divergent_topics[:3]:  # é™åˆ¶è¾©è®ºè¯é¢˜æ•°é‡
            logger.info(f"å¼€å§‹è¾©è®ºè¯é¢˜ï¼š{topic}")
            
            # æ¯ä¸ªåˆ†æå¸ˆå¯¹è¯¥è¯é¢˜å‘è¡¨è§‚ç‚¹
            debate_round = []
            for agent in self.agents:
                other_opinions = [
                    {
                        "analyst": a.get("analyst_type"),
                        "opinion": a.get("analysis", {}).get(topic, "æ— è§‚ç‚¹")
                    }
                    for a in analyses
                    if a.get("analyst_type") != agent.name.lower()
                ]
                
                opinion = await agent.debate(topic, other_opinions)
                debate_round.append(opinion)
                
            debate_results.append({
                "topic": topic,
                "round": debate_round,
                "timestamp": datetime.utcnow().isoformat()
            })
            
        return debate_results
        
    async def _form_consensus(
        self, 
        analyses: List[Dict[str, Any]], 
        debates: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """å½¢æˆå…±è¯†æ„è§"""
        # æ”¶é›†æ‰€æœ‰è¯„çº§
        ratings = []
        confidences = []
        
        for analysis in analyses:
            if "rating" in analysis.get("analysis", {}):
                ratings.append(analysis["analysis"]["rating"])
            if "confidence_score" in analysis:
                confidences.append(analysis["confidence_score"])
                
        # è®¡ç®—å…±è¯†è¯„çº§
        consensus_rating = self._calculate_weighted_consensus(ratings, confidences)
        
        # æ•´åˆå…³é”®å‘ç°
        all_findings = []
        for analysis in analyses:
            findings = analysis.get("analysis", {}).get("key_findings", [])
            all_findings.extend(findings)
            
        # æ•´åˆå»ºè®®
        all_recommendations = []
        for analysis in analyses:
            recommendations = analysis.get("analysis", {}).get("recommendations", [])
            all_recommendations.extend(recommendations)
            
        return {
            "consensus_rating": consensus_rating,
            "average_confidence": sum(confidences) / len(confidences) if confidences else 0.5,
            "key_findings": self._prioritize_findings(all_findings),
            "recommendations": self._prioritize_recommendations(all_recommendations),
            "participating_analysts": len(analyses),
            "debate_topics": [d["topic"] for d in debates]
        }
        
    def _identify_divergent_topics(self, analyses: List[Dict[str, Any]]) -> List[str]:
        """è¯†åˆ«åˆ†æ­§è¯é¢˜"""
        # ç®€åŒ–å®ç°ï¼šè¿”å›é¢„å®šä¹‰çš„å…³é”®è¯é¢˜
        return [
            "ä»·æ ¼èµ°åŠ¿é¢„æµ‹",
            "ä¸»è¦é£é™©å› ç´ ",
            "æŠ•èµ„æ—¶æœºåˆ¤æ–­"
        ]
        
    def _calculate_weighted_consensus(
        self, 
        ratings: List[str], 
        confidences: List[float]
    ) -> str:
        """è®¡ç®—åŠ æƒå…±è¯†"""
        if not ratings:
            return "neutral"
            
        rating_scores = {
            "bullish": 1,
            "neutral": 0,
            "bearish": -1
        }
        
        # å¦‚æœæ²¡æœ‰ç½®ä¿¡åº¦ï¼Œä½¿ç”¨ç®€å•å¹³å‡
        if not confidences or len(confidences) != len(ratings):
            total_score = sum(rating_scores.get(r, 0) for r in ratings)
            avg_score = total_score / len(ratings)
        else:
            # ä½¿ç”¨ç½®ä¿¡åº¦åŠ æƒ
            weighted_sum = sum(
                rating_scores.get(r, 0) * c 
                for r, c in zip(ratings, confidences)
            )
            total_confidence = sum(confidences)
            avg_score = weighted_sum / total_confidence if total_confidence > 0 else 0
            
        if avg_score > 0.3:
            return "bullish"
        elif avg_score < -0.3:
            return "bearish"
        else:
            return "neutral"
            
    def _prioritize_findings(self, findings: List[Any]) -> List[Any]:
        """ä¼˜å…ˆçº§æ’åºå…³é”®å‘ç°"""
        # ç®€åŒ–å®ç°ï¼šå»é‡å¹¶è¿”å›å‰5ä¸ª
        unique_findings = []
        seen = set()
        
        for finding in findings:
            finding_str = str(finding)
            if finding_str not in seen:
                seen.add(finding_str)
                unique_findings.append(finding)
                
        return unique_findings[:5]
        
    def _prioritize_recommendations(self, recommendations: List[Any]) -> List[Any]:
        """ä¼˜å…ˆçº§æ’åºå»ºè®®"""
        # ç®€åŒ–å®ç°ï¼šå»é‡å¹¶è¿”å›å‰3ä¸ª
        unique_recommendations = []
        seen = set()
        
        for rec in recommendations:
            rec_str = str(rec)
            if rec_str not in seen:
                seen.add(rec_str)
                unique_recommendations.append(rec)
                
        return unique_recommendations[:3]