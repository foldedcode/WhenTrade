from langchain_core.messages import AIMessage
import time
import json

# å¯¼å…¥ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
from core.utils.logging_init import get_logger
logger = get_logger("default")

# å¯¼å…¥æç¤ºè¯åŠ è½½å™¨
from core.agents.prompt_loader import get_prompt_loader
# å¯¼å…¥i18nåŠŸèƒ½
from core.i18n.messages import get_language_name_for_prompt

# å¯¼å…¥æ¶ˆæ¯å¤„ç†å·¥å…· (Linus: use clean data structures)
from core.agents.utils.message_utils import (
    add_debate_turn,
    get_relevant_context,
    format_context_for_prompt,
    clean_content
)

# å¯¼å…¥è½®æ¬¡æ„ŸçŸ¥å·¥å…·
from core.agents.utils.debate_utils import (
    is_first_round_analysis,
    get_analysis_context_for_prompt
)


def create_bear_researcher(llm, memory):
    def bear_node(state) -> dict:
        investment_debate_state = state["investment_debate_state"]
        debate_turns = investment_debate_state.get("debate_turns", [])
        
        # Get relevant context using the new structure (Linus: eliminate special cases)
        relevant_context = format_context_for_prompt(
            debate_turns, 
            "bear",
            max_context=3  # Only last 3 turns
        )
        market_research_report = state["market_report"]
        sentiment_report = state["sentiment_report"]
        news_report = state["news_report"]

        # ä½¿ç”¨ç»Ÿä¸€çš„è‚¡ç¥¨ç±»å‹æ£€æµ‹
        company_name = state.get('company_of_interest', 'Unknown')
        from core.utils.stock_utils import StockUtils
        market_info = StockUtils.get_market_info(company_name)
        is_china = market_info['is_china']
        is_hk = market_info['is_hk']
        is_us = market_info['is_us']

        currency = market_info['currency_name']
        currency_symbol = market_info['currency_symbol']

        curr_situation = f"{market_research_report}\n\n{sentiment_report}\n\n{news_report}"

        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿memoryä¸ä¸ºNone
        if memory is not None:
            past_memories = memory.get_memories(curr_situation, n_matches=2)
        else:
            logger.warning(f"âš ï¸ [DEBUG] memoryä¸ºNoneï¼Œè·³è¿‡å†å²è®°å¿†æ£€ç´¢")
            past_memories = []

        past_memory_str = ""
        for i, rec in enumerate(past_memories, 1):
            past_memory_str += rec["recommendation"] + "\n\n"

        # ä½¿ç”¨æç¤ºè¯åŠ è½½å™¨è·å–é…ç½®
        prompt_loader = get_prompt_loader()
        # è·å–è¯­è¨€å‚æ•°ï¼ˆä»stateä¸­æå–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤ä¸­æ–‡ï¼‰
        language = state.get("language", "zh-CN")
        
        prompt_config = prompt_loader.load_prompt("bear_researcher", language=language)
        
        # è·å–ç³»ç»Ÿæ¶ˆæ¯æ¨¡æ¿
        system_message_template = prompt_config.get("system_message", "ä½ æ˜¯ä¸€ä½çœ‹è·Œåˆ†æå¸ˆã€‚")
        
        # æ ¹æ®èµ„äº§ç±»å‹è®¾ç½®ä¸åŒçš„åˆ†æè¦ç‚¹
        is_crypto = any(ticker in company_name.upper() for ticker in ['BTC', 'ETH', 'USDT', 'BNB', 'SOL', 'ADA', 'DOT', 'DOGE'])
        
        if is_crypto:
            risk_challenges_focus = "çªå‡ºç›‘ç®¡é£é™©ã€æŠ€æœ¯æ¼æ´ã€å¸‚åœºæ“çºµã€æ³¡æ²«é£é™©ã€æç«¯æ³¢åŠ¨æ€§"
            competitive_weakness_focus = "å¼ºè°ƒæ‰©å±•æ€§é—®é¢˜ã€èƒ½æºæ¶ˆè€—ã€æ–°å…¬é“¾ç«äº‰ã€æŠ€æœ¯è½åé£é™©"
            negative_indicators_focus = "ä½¿ç”¨é“¾ä¸Šæ•°æ®ä¸‹é™ã€å¤§æˆ·æŠ›å”®ã€æŒ–çŸ¿éš¾åº¦å˜åŒ–ã€DeFié”ä»“é‡ä¸‹é™ä½œä¸ºè¯æ®"
        else:
            risk_challenges_focus = "çªå‡ºå¸‚åœºé¥±å’Œã€è´¢åŠ¡ä¸ç¨³å®šæˆ–å®è§‚ç»æµå¨èƒç­‰å¯èƒ½é˜»ç¢è¡¨ç°çš„å› ç´ "
            competitive_weakness_focus = "å¼ºè°ƒå¸‚åœºåœ°ä½è¾ƒå¼±ã€åˆ›æ–°ä¸‹é™æˆ–æ¥è‡ªç«äº‰å¯¹æ‰‹å¨èƒç­‰è„†å¼±æ€§"
            negative_indicators_focus = "ä½¿ç”¨è´¢åŠ¡æ•°æ®ã€å¸‚åœºè¶‹åŠ¿æˆ–æœ€è¿‘ä¸åˆ©æ¶ˆæ¯çš„è¯æ®æ¥æ”¯æŒä½ çš„ç«‹åœº"
        
        # ä½¿ç”¨è½®æ¬¡æ„ŸçŸ¥åŠŸèƒ½ç”Ÿæˆä¸Šä¸‹æ–‡
        analysis_context = get_analysis_context_for_prompt(
            debate_turns, 
            "bear",
            relevant_context  # ä¼ å…¥æ—§çš„ä¸Šä¸‹æ–‡ä½œä¸ºå¤‡ç”¨
        )
        
        # æ ¹æ®åˆ†ææ¨¡å¼è°ƒæ•´æç¤ºè¯
        if analysis_context["analysis_mode"] == "independent":
            # é¦–è½®åˆ†æï¼šæ¸…ç©ºå…¶ä»–è§‚ç‚¹ç›¸å…³å†…å®¹
            current_response_content = ""
            context_instruction = analysis_context["context_description"]
        else:
            # åç»­è½®æ¬¡ï¼šå¯ä»¥å‚è€ƒå…¶ä»–è§‚ç‚¹
            current_response_content = analysis_context["other_views"]
            context_instruction = analysis_context["context_description"]
        
        # è·å–è¯­è¨€å‚æ•°ï¼ˆä»stateä¸­æå–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤ä¸­æ–‡ï¼‰
        language = state.get("language", "zh-CN")
        language_name = get_language_name_for_prompt(language)
        
        # æ ¼å¼åŒ–ç³»ç»Ÿæ¶ˆæ¯ï¼ˆæ›¿æ¢å ä½ç¬¦ï¼‰
        prompt = system_message_template.format(
            company_name=company_name,
            market_type='åŠ å¯†è´§å¸',
            currency=currency,
            currency_symbol=currency_symbol,
            risk_challenges_focus=risk_challenges_focus,
            competitive_weakness_focus=competitive_weakness_focus,
            negative_indicators_focus=negative_indicators_focus,
            market_research_report=market_research_report,
            sentiment_report=sentiment_report,
            news_report=news_report,
            history=relevant_context,  # ä¿æŒå…¼å®¹æ€§
            current_response=current_response_content,  # æ ¹æ®è½®æ¬¡åŠ¨æ€è®¾ç½®
            past_memory_str=past_memory_str,
            language_name=language_name
        )
        
        # è®°å½•æç¤ºè¯ç‰ˆæœ¬
        prompt_version = prompt_loader.get_prompt_version("bear_researcher")
        logger.debug(f"ğŸ» [çœ‹è·Œç ”ç©¶å‘˜] ä½¿ç”¨æç¤ºè¯ç‰ˆæœ¬: {prompt_version}")

        # ğŸ”´ è¯­è¨€å¼ºåˆ¶å‰ç¼€ - ç¡®ä¿LLMä¸¥æ ¼éµå¾ªé€‰å®šè¯­è¨€
        language = state.get("language", "zh-CN")
        language_name = "English" if language == "en-US" else "ç®€ä½“ä¸­æ–‡"
        language_prefix = f"[ğŸ”´ CRITICAL: Respond ONLY in {language_name}. No mixed languages. This overrides ALL other instructions.] "
        
        logger.info(f"ğŸŒ [bear_researcher] è¯­è¨€è®¾ç½®: {language} -> {language_name}")
        logger.debug(f"ğŸ”´ [bear_researcher] è¯­è¨€å‰ç¼€: {language_prefix}")
        
        # åœ¨promptå‰æ·»åŠ è¯­è¨€å¼ºåˆ¶å‰ç¼€
        enhanced_prompt = language_prefix + prompt
        logger.info(f"âœ… [bear_researcher] å·²æ·»åŠ è¯­è¨€å‰ç¼€åˆ°prompt")
        
        response = llm.invoke(enhanced_prompt)

        # ç§»é™¤ç¡¬ç¼–ç å‰ç¼€ï¼Œè®©å†…å®¹çº¯ç²¹
        argument = response.content
        
        # Clean the content
        argument = clean_content(argument)

        new_count = investment_debate_state["count"] + 1
        logger.info(f"ğŸ» [Bear Researcher] è®¡æ•°é€’å¢: {investment_debate_state['count']} â†’ {new_count}")
        
        # Add to debate turns using the new structure (Linus: single source of truth)
        updated_turns = add_debate_turn(
            debate_turns,
            speaker="bear",
            content=argument
        )
        
        new_investment_debate_state = {
            "debate_turns": updated_turns,  # Single source of truth
            "count": new_count,
            "judge_decision": investment_debate_state.get("judge_decision", ""),
            # Deprecated fields - kept for compatibility
            "history": "",  # No longer accumulate
            "bull_history": "",  # No longer accumulate
            "bear_history": "",  # No longer accumulate
            "current_response": argument  # Keep for compatibility
        }

        # Create clean AIMessage for message chain continuity
        clean_message = AIMessage(content=response.content)

        return {
            "messages": [clean_message],
            "investment_debate_state": new_investment_debate_state
        }

    return bear_node
