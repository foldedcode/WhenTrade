/**
 * LLMæä¾›å•†è‡ªåŠ¨æ£€æµ‹å’Œæ¨¡å‹è·å–æœåŠ¡
 * åŸºäºç¯å¢ƒå˜é‡API keyè‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„LLMæä¾›å•†ï¼Œå¹¶åŠ¨æ€è·å–æ¨¡å‹åˆ—è¡¨
 */

import { createI18n } from 'vue-i18n'

// å¯¼å…¥ç¿»è¯‘æ–‡ä»¶
import zhProviders from '@/locales/zh-CN/providers.json'
import enProviders from '@/locales/en-US/providers.json'

// åˆ›å»ºä¸“ç”¨çš„ i18n å®ä¾‹
const providerI18n = createI18n({
  locale: localStorage.getItem('when-trade-locale') || 'zh-CN',
  fallbackLocale: 'zh-CN',
  missingWarn: false, // ç¦ç”¨ç¼ºå¤±ç¿»è¯‘è­¦å‘Š
  fallbackWarn: false, // ç¦ç”¨fallbackè­¦å‘Š
  messages: {
    'zh-CN': { providers: zhProviders },
    'zh': { providers: zhProviders },
    'en-US': { providers: enProviders },
    'en': { providers: enProviders }
  }
})

// ç±»å‹å®šä¹‰
export interface LLMProvider {
  id: string
  name: string
  description: string
  logo: string
  apiKeyEnvName: string
  available: boolean
  models: LLMModel[]
  baseUrl?: string
}

export interface LLMModel {
  id: string
  name: string
  description: string
  contextWindow: number
  pricing?: {
    input: number    // per 1K tokens
    output: number   // per 1K tokens
  }
  capabilities: string[]
  recommended?: boolean
}

// è·å–ç¿»è¯‘æ–‡æœ¬çš„è¾…åŠ©å‡½æ•°
const getProviderTranslation = (providerId: string, key: 'name' | 'description'): string => {
  try {
    const locale = localStorage.getItem('when-trade-locale') || 'zh-CN'
    // åŠ¨æ€æ›´æ–°i18nå®ä¾‹çš„locale
    providerI18n.global.locale = locale as 'zh-CN' | 'en-US'
    const t = providerI18n.global.t
    const translationKey = `providers.${providerId}.${key}`
    const result = t(translationKey) as string
    
    // å¦‚æœç¿»è¯‘é”®ä¸å­˜åœ¨ï¼Œè¿”å›é”®æœ¬èº«ï¼Œé¿å…è¿”å›è‹±æ–‡fallback
    if (result === translationKey) {
      // æä¾›åŸºæœ¬çš„fallbackæè¿°
      const fallbackDescriptions: Record<string, Record<'name' | 'description', string>> = {
        openai: { name: 'OpenAI', description: 'é¢†å…ˆçš„AIç ”ç©¶å…¬å¸ï¼ŒGPTç³»åˆ—æ¨¡å‹' },
        google: { name: 'Google', description: 'Google AIæœåŠ¡ï¼ŒGeminiæ¨¡å‹' },
        deepseek: { name: 'DeepSeek', description: 'DeepSeek AIï¼Œé«˜æ€§ä»·æ¯”æ¨ç†æ¨¡å‹' },
        kimi: { name: 'Moonshot Kimi', description: 'æœˆä¹‹æš—é¢ï¼Œè¶…é•¿ä¸Šä¸‹æ–‡æ¨¡å‹' }
      }
      
      if (locale === 'en-US') {
        const enFallbacks: Record<string, Record<'name' | 'description', string>> = {
          openai: { name: 'OpenAI', description: 'Leading AI research company, GPT models' },
          google: { name: 'Google', description: 'Google AI services, Gemini models' },
          deepseek: { name: 'DeepSeek', description: 'DeepSeek AI, cost-effective reasoning models' },
          kimi: { name: 'Moonshot Kimi', description: 'Moonshot AI, ultra-long context models' }
        }
        return enFallbacks[providerId]?.[key] || fallbackDescriptions[providerId]?.[key] || result
      }
      
      return fallbackDescriptions[providerId]?.[key] || result
    }
    
    return result
  } catch (error) {
    console.warn(`è·å–æä¾›å•†ç¿»è¯‘å¤±è´¥: ${providerId}.${key}`, error)
    // è¿”å›åŸºæœ¬ä¿¡æ¯
    return providerId
  }
}

// è·å–æ¨¡å‹æè¿°ç¿»è¯‘çš„è¾…åŠ©å‡½æ•°
const getModelTranslation = (providerId: string, modelId: string): string => {
  const locale = localStorage.getItem('when-trade-locale') || 'zh-CN'
  
  // ç›´æ¥ä»ç¿»è¯‘æ•°æ®ä¸­è·å–ï¼Œé¿å…è§¦å‘Vue i18nçš„fallbackæœºåˆ¶
  const isEnglish = locale.startsWith('en')
  const providers = isEnglish ? enProviders : zhProviders
  
  const modelTranslation = providers[providerId as keyof typeof providers]?.models?.[modelId as any]
  return modelTranslation || modelId
}

// LLMæä¾›å•†é…ç½®
const LLM_PROVIDERS_CONFIG: Record<string, Omit<LLMProvider, 'available' | 'models' | 'description'> & { getDescription: () => string }> = {
  openai: {
    id: 'openai',
    name: 'OpenAI',
    logo: 'openai',
    apiKeyEnvName: 'OPENAI_API_KEY',
    baseUrl: 'https://api.openai.com/v1',
    getDescription: () => getProviderTranslation('openai', 'description')
  },
  google: {
    id: 'google',
    name: 'Google',
    logo: 'google',
    apiKeyEnvName: 'GOOGLE_API_KEY',
    baseUrl: 'https://generativelanguage.googleapis.com/v1',
    getDescription: () => getProviderTranslation('google', 'description')
  },
  deepseek: {
    id: 'deepseek',
    name: 'DeepSeek',
    logo: 'deepseek',
    apiKeyEnvName: 'DEEPSEEK_API_KEY',
    baseUrl: 'https://api.deepseek.com/v1',
    getDescription: () => getProviderTranslation('deepseek', 'description')
  },
  kimi: {
    id: 'kimi',
    name: 'Moonshot Kimi',
    logo: 'kimi',
    apiKeyEnvName: 'KIMI_API_KEY',
    baseUrl: 'https://api.moonshot.cn/v1',
    getDescription: () => getProviderTranslation('kimi', 'description')
  }
}

// é»˜è®¤æ¨¡å‹é…ç½®ç”Ÿæˆå‡½æ•°ï¼ˆå½“APIè°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
const getDefaultModels = (): Record<string, LLMModel[]> => {
  return {
  openai: [
    {
      id: 'gpt-4o',
      name: 'GPT-4o',
      description: getModelTranslation('openai', 'gpt-4o'),
      contextWindow: 128000,
      pricing: { input: 0.005, output: 0.015 },
      capabilities: ['æ–‡æœ¬ç”Ÿæˆ', 'ä»£ç ç”Ÿæˆ', 'åˆ†ææ¨ç†', 'å¤šæ¨¡æ€'],
      recommended: true
    },
    {
      id: 'gpt-4o-mini',
      name: 'GPT-4o Mini',
      description: getModelTranslation('openai', 'gpt-4o-mini'),
      contextWindow: 128000,
      pricing: { input: 0.00015, output: 0.0006 },
      capabilities: ['æ–‡æœ¬ç”Ÿæˆ', 'ä»£ç ç”Ÿæˆ', 'å¿«é€Ÿåˆ†æ']
    },
    {
      id: 'gpt-4-turbo',
      name: 'GPT-4 Turbo',
      description: getModelTranslation('openai', 'gpt-4-turbo'),
      contextWindow: 128000,
      pricing: { input: 0.01, output: 0.03 },
      capabilities: ['æ–‡æœ¬ç”Ÿæˆ', 'ä»£ç ç”Ÿæˆ', 'åˆ†ææ¨ç†']
    }
  ],
  google: [
    {
      id: 'gemini-1.5-pro',
      name: 'Gemini 1.5 Pro',
      description: getModelTranslation('google', 'gemini-1.5-pro'),
      contextWindow: 1048576,
      pricing: { input: 0.00125, output: 0.005 },
      capabilities: ['æ–‡æœ¬ç”Ÿæˆ', 'å¤šæ¨¡æ€', 'åˆ†ææ¨ç†', 'è¶…é•¿æ–‡æœ¬'],
      recommended: true
    },
    {
      id: 'gemini-1.5-flash',
      name: 'Gemini 1.5 Flash',
      description: getModelTranslation('google', 'gemini-1.5-flash'),
      contextWindow: 1048576,
      pricing: { input: 0.00025, output: 0.001 },
      capabilities: ['æ–‡æœ¬ç”Ÿæˆ', 'å¿«é€Ÿåˆ†æ', 'å¤šæ¨¡æ€']
    }
  ],
  deepseek: [
    {
      id: 'deepseek-chat',
      name: 'DeepSeek Chat',
      description: getModelTranslation('deepseek', 'deepseek-chat'),
      contextWindow: 32768,
      pricing: { input: 0.0014, output: 0.0028 },
      capabilities: ['æ–‡æœ¬ç”Ÿæˆ', 'ä»£ç ç”Ÿæˆ', 'åˆ†ææ¨ç†'],
      recommended: true
    },
    {
      id: 'deepseek-coder',
      name: 'DeepSeek Coder',
      description: getModelTranslation('deepseek', 'deepseek-coder'),
      contextWindow: 16384,
      pricing: { input: 0.0014, output: 0.0028 },
      capabilities: ['ä»£ç ç”Ÿæˆ', 'ä»£ç åˆ†æ', 'æŠ€æœ¯æ–‡æ¡£']
    }
  ],
  kimi: [
    {
      id: 'moonshot-v1-8k',
      name: 'Moonshot v1 8K',
      description: getModelTranslation('kimi', 'moonshot-v1-8k'),
      contextWindow: 8192,
      pricing: { input: 0.012, output: 0.012 },
      capabilities: ['æ–‡æœ¬ç”Ÿæˆ', 'å¯¹è¯', 'åˆ†æ']
    },
    {
      id: 'moonshot-v1-32k',
      name: 'Moonshot v1 32K',
      description: getModelTranslation('kimi', 'moonshot-v1-32k'),
      contextWindow: 32768,
      pricing: { input: 0.024, output: 0.024 },
      capabilities: ['æ–‡æœ¬ç”Ÿæˆ', 'é•¿æ–‡æœ¬', 'åˆ†æ']
    },
    {
      id: 'moonshot-v1-128k',
      name: 'Moonshot v1 128K',
      description: getModelTranslation('kimi', 'moonshot-v1-128k'),
      contextWindow: 131072,
      pricing: { input: 0.06, output: 0.06 },
      capabilities: ['æ–‡æœ¬ç”Ÿæˆ', 'è¶…é•¿æ–‡æœ¬', 'æ·±åº¦åˆ†æ'],
      recommended: true
    }
  ]
  }
}

export class LLMDetectionService {
  private static instance: LLMDetectionService
  private providers: LLMProvider[] = []
  private initialized = false

  static getInstance(): LLMDetectionService {
    if (!this.instance) {
      this.instance = new LLMDetectionService()
    }
    return this.instance
  }

  /**
   * åˆå§‹åŒ–LLMæ£€æµ‹æœåŠ¡
   * æ£€æµ‹ç¯å¢ƒå˜é‡ä¸­çš„API keyï¼Œç¡®å®šå¯ç”¨çš„æä¾›å•†
   */
  async initialize(): Promise<void> {
    if (this.initialized) return

    // console.log('ğŸ” å¼€å§‹æ£€æµ‹å¯ç”¨çš„LLMæä¾›å•†...')

    // é€šè¿‡åç«¯APIæ£€æµ‹ç¯å¢ƒå˜é‡ä¸­çš„API key
    try {
      const response = await fetch(`${import.meta.env.VITE_API_BASE_URL}/api/v1/llm/providers`, {
        method: 'GET',
        headers: {
          'Content-Type': 'application/json',
        }
      })

      if (response.ok) {
        const responseData = await response.json()
        // ä¿®å¤ï¼šæ­£ç¡®æå–availableå­—æ®µ
        const availableProviders = responseData.available || {}
        this.providers = await this.buildProvidersList(availableProviders)
      } else {
        // åç«¯ä¸å¯ç”¨æ—¶çš„é™çº§å¤„ç†
        console.warn('âš ï¸ åç«¯LLMæ£€æµ‹APIä¸å¯ç”¨ï¼Œä½¿ç”¨æœ¬åœ°æ£€æµ‹')
        this.providers = await this.fallbackDetection()
      }
    } catch (error) {
      console.warn('âš ï¸ LLMæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®:', error)
      this.providers = await this.fallbackDetection()
    }

    this.initialized = true
    // console.log('âœ… LLMæ£€æµ‹å®Œæˆï¼Œå¯ç”¨æä¾›å•†:', this.providers.map(p => p.name))
  }

  /**
   * è·å–æ‰€æœ‰å¯ç”¨çš„LLMæä¾›å•†
   */
  async getAvailableProviders(): Promise<LLMProvider[]> {
    if (!this.initialized) {
      await this.initialize()
    }
    return this.providers.filter(p => p.available)
  }

  /**
   * è·å–æŒ‡å®šæä¾›å•†çš„æ¨¡å‹åˆ—è¡¨
   */
  async getModelsForProvider(providerId: string): Promise<LLMModel[]> {
    const provider = this.providers.find(p => p.id === providerId)
    if (!provider || !provider.available) {
      return []
    }

    // å¦‚æœå·²æœ‰æ¨¡å‹æ•°æ®ï¼Œç›´æ¥è¿”å›
    if (provider.models && provider.models.length > 0) {
      return provider.models
    }

    // åŠ¨æ€è·å–æ¨¡å‹åˆ—è¡¨
    try {
      const models = await this.fetchModelsFromAPI(providerId)
      provider.models = models
      return models
    } catch (error) {
      console.warn(`âš ï¸ æ— æ³•è·å–${provider.name}çš„æ¨¡å‹åˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®:`, error)
      const defaultModels = getDefaultModels()[providerId] || []
      provider.models = defaultModels
      return defaultModels
    }
  }

  /**
   * è·å–æ¨èçš„é»˜è®¤é…ç½®
   */
  async getRecommendedConfig(): Promise<{ providerId: string; modelId: string } | null> {
    const providers = await this.getAvailableProviders()
    
    // ä¼˜å…ˆçº§ï¼šKimi > DeepSeek > OpenAI > Google
    const priorityOrder = ['kimi', 'deepseek', 'openai', 'google']
    
    for (const providerId of priorityOrder) {
      const provider = providers.find(p => p.id === providerId)
      if (provider) {
        const models = await this.getModelsForProvider(providerId)
        const recommendedModel = models.find(m => m.recommended) || models[0]
        
        if (recommendedModel) {
          return {
            providerId,
            modelId: recommendedModel.id
          }
        }
      }
    }

    return null
  }

  /**
   * æ„å»ºæä¾›å•†åˆ—è¡¨
   */
  private async buildProvidersList(availableProviders: Record<string, boolean>): Promise<LLMProvider[]> {
    const providers: LLMProvider[] = []

    for (const [providerId, config] of Object.entries(LLM_PROVIDERS_CONFIG)) {
      const available = availableProviders[providerId] || false
      
      providers.push({
        id: config.id,
        name: config.name,
        description: config.getDescription(), // ä½¿ç”¨åŠ¨æ€ç¿»è¯‘
        logo: config.logo,
        apiKeyEnvName: config.apiKeyEnvName,
        baseUrl: config.baseUrl,
        available,
        models: available ? getDefaultModels()[providerId] || [] : []
      })
    }

    return providers
  }

  /**
   * é™çº§æ£€æµ‹ï¼ˆå½“åç«¯ä¸å¯ç”¨æ—¶ï¼‰
   */
  private async fallbackDetection(): Promise<LLMProvider[]> {
    // åœ¨å‰ç«¯æ— æ³•ç›´æ¥è®¿é—®ç¯å¢ƒå˜é‡ï¼Œæ‰€ä»¥å‡è®¾æ‰€æœ‰æä¾›å•†éƒ½å¯ç”¨
    // å®é™…ä½¿ç”¨æ—¶ä¼šåœ¨è°ƒç”¨APIæ—¶éªŒè¯
    return Object.entries(LLM_PROVIDERS_CONFIG).map(([providerId, config]) => ({
      id: config.id,
      name: config.name,
      description: config.getDescription(), // ä½¿ç”¨åŠ¨æ€ç¿»è¯‘
      logo: config.logo,
      apiKeyEnvName: config.apiKeyEnvName,
      baseUrl: config.baseUrl,
      available: true, // ä¹è§‚å‡è®¾
      models: getDefaultModels()[providerId] || []
    }))
  }

  /**
   * ä»APIåŠ¨æ€è·å–æ¨¡å‹åˆ—è¡¨
   */
  private async fetchModelsFromAPI(providerId: string): Promise<LLMModel[]> {
    try {
      const response = await fetch(`${import.meta.env.VITE_API_BASE_URL}/api/v1/llm/providers/${providerId}/models`, {
        method: 'GET',
        headers: {
          'Content-Type': 'application/json',
        }
      })

      if (response.ok) {
        const models = await response.json()
        return models.map((model: any) => ({
          id: model.id,
          name: model.name || model.id,
          description: model.description || `${providerId}æ¨¡å‹`,
          contextWindow: model.context_length || 4096,
          pricing: model.pricing ? {
            input: model.pricing.prompt,
            output: model.pricing.completion
          } : undefined,
          capabilities: model.capabilities || ['æ–‡æœ¬ç”Ÿæˆ'],
          recommended: model.recommended || false
        }))
      }
    } catch (error) {
      console.warn(`è·å–${providerId}æ¨¡å‹åˆ—è¡¨å¤±è´¥:`, error)
    }

    // è¿”å›é»˜è®¤é…ç½®
    return getDefaultModels()[providerId] || []
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const llmDetectionService = LLMDetectionService.getInstance()

// ä¾¿æ·å‡½æ•°
export async function getAvailableLLMProviders(): Promise<LLMProvider[]> {
  return await llmDetectionService.getAvailableProviders()
}

export async function getModelsForProvider(providerId: string): Promise<LLMModel[]> {
  return await llmDetectionService.getModelsForProvider(providerId)
}

export async function getRecommendedLLMConfig(): Promise<{ providerId: string; modelId: string } | null> {
  return await llmDetectionService.getRecommendedConfig()
}